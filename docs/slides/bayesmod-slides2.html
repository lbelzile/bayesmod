<!DOCTYPE html>
<html lang="en"><head>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-2bb0ec5e928ee8c40b12725cb7836c35.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.1">

  <meta name="author" content="Léo Belzile, HEC Montréal">
  <title>Bayesian modelling</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto-da069d641d4916e8549bf8dc2b95f825.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-color="#ff585d" class="quarto-title-block center">
  <h1 class="title">Bayesian modelling</h1>
  <p class="subtitle">Bayesics</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Léo Belzile, HEC Montréal 
</div>
</div>
</div>

  <p class="date">Last compiled Monday Jan 27, 2025</p>
</section>
<section id="probability-vs-frequency" class="slide level2">
<h2>Probability vs frequency</h2>
<p>In frequentist statistic, “probability” is synonym for</p>
<div class="columns">
<div class="column" style="width:60%;">
<blockquote>
<p>long-term frequency under repeated sampling</p>
</blockquote>
</div><div class="column" style="width:40%;">
<p><img data-src="fig/dice.png"></p>
</div></div>
</section>
<section id="what-is-probability" class="slide level2">
<h2>What is probability?</h2>
<p>Probability reflects incomplete information.</p>
<p>Quoting <span class="citation" data-cites="deFinetti:1974">Finetti (<a href="#/references" role="doc-biblioref" onclick="">1974</a>)</span></p>
<blockquote>
<p>Probabilistic reasoning — always to be understood as subjective — merely stems from our being uncertain about something.</p>
</blockquote>
</section>
<section id="why-opt-for-the-bayesian-paradigm" class="slide level2">
<h2>Why opt for the Bayesian paradigm?</h2>
<ul>
<li>Satisfies the likelihood principle</li>
<li>Generative approach naturally extends to complex settings (hierarchical models)</li>
<li>Uncertainty quantification and natural framework for prediction</li>
<li>Capability to incorporate subject-matter expertise</li>
</ul>
</section>
<section id="bayesian-versus-frequentist" class="slide level2">
<h2>Bayesian versus frequentist</h2>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="frequentist">Frequentist</h3>
<ul>
<li>Parameters treated as fixed, data as random
<ul>
<li>true value of parameter <span class="math inline">\(\boldsymbol{\theta}\)</span> is unknown.</li>
</ul></li>
<li>Target is point estimator</li>
</ul>
</div><div class="column" style="width:50%;">
<h3 id="bayesian">Bayesian</h3>
<ul>
<li><strong>Both</strong> parameters and data are random
<ul>
<li>inference is conditional on observed data</li>
</ul></li>
<li>Target is a distribution</li>
</ul>
</div></div>
</section>
<section id="joint-and-marginal-distribution" class="slide level2">
<h2>Joint and marginal distribution</h2>
<p>The joint density of data <span class="math inline">\(\boldsymbol{Y}\)</span> and parameters <span class="math inline">\(\boldsymbol{\theta}\)</span> is</p>
<p><span class="math display">\[\begin{align*}
p(\boldsymbol{Y}, \boldsymbol{\theta}) = p(\boldsymbol{Y} \mid \boldsymbol{\theta}) p(\boldsymbol{\theta}) =  p(\boldsymbol{\theta} \mid \boldsymbol{Y}) p(\boldsymbol{Y})
\end{align*}\]</span> where the marginal <span class="math inline">\(p(\boldsymbol{Y}) = \int_{\boldsymbol{\Theta}} p(\boldsymbol{Y}, \boldsymbol{\theta}) \mathrm{d} \boldsymbol{\theta}\)</span>.</p>
</section>
<section id="posterior" class="slide level2">
<h2>Posterior</h2>
<p>Using Bayes’ theorem, the posterior density is</p>
<p><span class="math display">\[\begin{align*}
\color{#D55E00}{p(\boldsymbol{\theta} \mid \boldsymbol{Y})} = \frac{\color{#0072B2}{p(\boldsymbol{Y} \mid \boldsymbol{\theta})} \times  \color{#56B4E9}{p(\boldsymbol{\theta})}}{\color{#E69F00}{\int p(\boldsymbol{Y} \mid \boldsymbol{\theta}) p(\boldsymbol{\theta})\mathrm{d} \boldsymbol{\theta}}},
\end{align*}\]</span></p>
<p>meaning that <span class="math display">\[\color{#D55E00}{\text{posterior}} \propto \color{#0072B2}{\text{likelihood}} \times \color{#56B4E9}{\text{prior}}\]</span></p>
<div style="font-size: 65%;">
<p>Evaluating the <strong>marginal likelihood</strong> <span class="math inline">\(\color{#E69F00}{p(\boldsymbol{Y})}\)</span>, is challenging when <span class="math inline">\(\boldsymbol{\theta}\)</span> is high-dimensional.</p>
</div>
<!--
## Statistical inference {.smaller}


:::: {.columns}

::: {.column width="50%"}

### Frequentist

- Testing relies on asymptotic theory (NHST)
- Unintuitive formulation 
   - (frequency-based)
   - e.g., "in repeated samples, 95% of the intervals would contain the true value"

:::

::: {.column width="50%"}

### Bayesian 

- Comparison in terms of models
- Any summary of the posterior distribution can be queried
   - e.g., credible intervals, posterior mean

:::

::::

But Bayesian inference is often much more work than numerical optimization!

-->
</section>
<section id="updating-beliefs-and-sequentiality" class="slide level2">
<h2>Updating beliefs and sequentiality</h2>
<p>By Bayes’ rule, we can consider <em>updating</em> the posterior by adding terms to the likelihood, noting that for independent <span class="math inline">\(\boldsymbol{y}_1\)</span> and <span class="math inline">\(\boldsymbol{y}_2\)</span>, <span class="math display">\[\begin{align*}
p(\boldsymbol{\theta} \mid \boldsymbol{y}_1, \boldsymbol{y}_2) \propto p(\boldsymbol{y}_2 \mid \boldsymbol{\theta}) p(\boldsymbol{\theta} \mid \boldsymbol{y}_1)
\end{align*}\]</span> The posterior is be updated in light of new information.</p>
</section>
<section id="binomial-distribution" class="slide level2">
<h2>Binomial distribution</h2>
<p>A binomial variable with probability of success <span class="math inline">\(\theta \in [0,1]\)</span> has mass function <span class="math display">\[\begin{align*}
f(y; \theta) = \binom{n}{y} \theta^y (1-\theta)^{n-y}, \qquad y = 0, \ldots, n.
\end{align*}\]</span> Moments of the number of successes out of <span class="math inline">\(n\)</span> trials are <span class="math display">\[\mathsf{E}(Y \mid \theta) = n \theta, \quad \mathsf{Va}(Y \mid \theta) = n \theta(1-\theta).\]</span></p>
<div style="font-size: 65%;">
<p>The binomial coefficient <span class="math inline">\(\binom{n}{y}=n!/\{(n-y)!y!\}\)</span>, where <span class="math inline">\(n!=\Gamma(n+1)\)</span>.</p>
</div>
</section>
<section id="beta-distribution" class="slide level2">
<h2>Beta distribution</h2>
<p>The beta distribution with shapes <span class="math inline">\(\alpha&gt;0\)</span> and <span class="math inline">\(\beta&gt;0\)</span>, denoted <span class="math inline">\(\mathsf{beta}(\alpha,\beta)\)</span>, has density <span class="math display">\[f(y) = \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}y^{\alpha - 1}(1-y)^{\beta - 1}, \qquad y \in [0,1]\]</span></p>
<ul>
<li>expectation: <span class="math inline">\(\alpha/(\alpha+\beta)\)</span>;</li>
<li>mode <span class="math inline">\((\alpha-1)/(\alpha+\beta-2)\)</span> if <span class="math inline">\(\alpha, \beta&gt;1\)</span>, else, <span class="math inline">\(0\)</span>, <span class="math inline">\(1\)</span> or none;</li>
<li>variance: <span class="math inline">\(\alpha\beta/\{(\alpha+\beta)^2(\alpha+\beta+1)\}\)</span>.</li>
</ul>
<aside class="notes">
<p>It is a continuous distribution over the unit interval.</p>
<p>The uniform is a special case when both shapes are unity.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="beta-binomial-example" class="slide level2">
<h2>Beta-binomial example</h2>
<p>We write <span class="math inline">\(Y \sim \mathsf{binom}(n, \theta)\)</span> for <span class="math inline">\(\theta \in [0,1]\)</span>; the likelihood is <span class="math display">\[L(\theta; y) = \binom{n}{y} \theta^y(1-\theta)^{n-y}.\]</span></p>
<p>Consider a beta prior, <span class="math inline">\(\theta \sim \mathsf{beta}(\alpha, \beta)\)</span>, with density <span class="math display">\[
p(\theta) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta) }\theta^{\alpha-1}(1-\theta)^{\beta - 1}.
\]</span></p>
</section>
<section id="density-versus-likelihood" class="slide level2 smaller">
<h2>Density versus likelihood</h2>
<p>The binomial distribution is discrete with support <span class="math inline">\(0, \ldots, n\)</span>, whereas the likelihood is continuous over <span class="math inline">\(\theta \in [0,1]\)</span>.</p>

<img data-src="bayesmod-slides2_files/figure-revealjs/fig-binom-massvslik-1.png" style="width:70.0%" class="r-stretch quarto-figure-center" id="fig-binom-massvslik"><p class="caption">
Figure&nbsp;1: Binomial density function (left) and scaled likelihood function (right).
</p><div style="font-size: 65%;">
<p>If the density or mass function integrates to 1 over the range of <span class="math inline">\(Y\)</span>, the integral of the likelihood over <span class="math inline">\(\theta\)</span> does not.</p>
</div>
</section>
<section id="posterior-density-and-proportionality" class="slide level2">
<h2>Posterior density and proportionality</h2>
<p>Any term not a function of <span class="math inline">\(\theta\)</span> can be dropped, since it will absorbed by the normalizing constant. The posterior density is proportional to</p>
<p><span class="math display">\[\begin{align*}
L(\theta; y)p(\theta) &amp; \stackrel{\theta}{\propto} \theta^{y}(1-\theta)^{n-y} \times \theta^{\alpha-1} (1-\theta)^{\beta-1}
\\&amp; =\theta^{y + \alpha - 1}(1-\theta)^{n-y + \beta - 1}
\end{align*}\]</span> the kernel of a beta density with shape parameters <span class="math inline">\(y + \alpha\)</span> and <span class="math inline">\(n-y + \beta\)</span>.</p>
<div style="font-size: 65%;">
<p>The symbol <span class="math inline">\(\propto\)</span>, for proportionality, means dropping all terms not an argument of the left hand side.</p>
</div>
</section>
<section id="marginal-likelihood" class="slide level2">
<h2>Marginal likelihood</h2>
<p>The marginal likelihood for the <span class="math inline">\(Y \mid P=p \sim \mathsf{binom}(n,p)\)</span> model with prior <span class="math inline">\(P \sim \mathsf{beta}(\alpha, \beta)\)</span> is <span class="math display">\[\begin{align*}
p_{Y}(y) = \binom{n}{y} \frac{\mathrm{beta}(\alpha + y, \beta + n - y)}{\mathrm{beta}(\alpha, \beta)}, \quad y \in\{0, \ldots,n\}.
\end{align*}\]</span> where <span class="math inline">\(\mathrm{beta}(\alpha, \beta) = \Gamma(\alpha)\Gamma(\beta)/\Gamma(\alpha+\beta)\)</span> is the beta function.</p>
</section>
<section id="experiments-and-likelihoods" class="slide level2 smaller">
<h2>Experiments and likelihoods</h2>
<p>Consider the following sampling mechanism, which lead to <span class="math inline">\(k\)</span> successes out of <span class="math inline">\(n\)</span> independent trials, with the same probability of success <span class="math inline">\(\theta\)</span>.</p>
<ol type="1">
<li>Bernoulli: sample fixed number of observations with <span class="math inline">\(L(\theta; y) =\theta^k(1-\theta)^{n-k}\)</span></li>
<li>binomial: same, but record only total number of successes so <span class="math inline">\(L(\theta; y) =\binom{n}{k}\theta^k(1-\theta)^{n-k}\)</span></li>
<li>negative binomial: sample data until you obtain a predetermined number of successes, whence <span class="math inline">\(L(\theta; y) =\binom{n-1}{k-1}\theta^k(1-\theta)^{n-k}\)</span></li>
</ol>
</section>
<section id="likelihood-principle" class="slide level2">
<h2>Likelihood principle</h2>
<p>Two likelihoods that are proportional, up to a constant not depending on unknown parameters, yield the same evidence.</p>
<p>In all cases, <span class="math inline">\(L(\theta; y) \stackrel{\theta}{\propto} \theta^k(1-\theta)^{n-k}\)</span>, so these yield the same inference for Bayesian.</p>
<div style="font-size: 65%;">
<p>For a more in-depth discussion, see Section 6.3.2 of <span class="citation" data-cites="Casella.Berger:2002">Casella &amp; Berger (<a href="#/references" role="doc-biblioref" onclick="">2002</a>)</span></p>
</div>
</section>
<section id="integration" class="slide level2">
<h2>Integration</h2>
<p>We could approximate the <span class="math inline">\(\color{#E69F00}{\text{marginal likelihood}}\)</span> through either</p>
<ul>
<li>numerical integration (cubature)</li>
<li>Monte Carlo simulations</li>
</ul>
<p>In more complicated models, we will try to sample observations by bypassing completely this calculation.</p>
<div style="font-size: 65%;">
<p>The likelihood terms can be small (always less than one and decreasing for discrete data), so watch out for numerical overflow when evaluating normalizing constants.</p>
</div>
</section>
<section id="numerical-example-of-monte-carlo-integration" class="slide level2">
<h2>Numerical example of (Monte Carlo) integration</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a></a>y <span class="ot">&lt;-</span> <span class="dv">6</span>L <span class="co"># number of successes </span></span>
<span id="cb1-2"><a></a>n <span class="ot">&lt;-</span> <span class="dv">14</span>L <span class="co"># number of trials</span></span>
<span id="cb1-3"><a></a>alpha <span class="ot">&lt;-</span> beta <span class="ot">&lt;-</span> <span class="fl">1.5</span> <span class="co"># prior parameters</span></span>
<span id="cb1-4"><a></a>unnormalized_posterior <span class="ot">&lt;-</span> <span class="cf">function</span>(theta){</span>
<span id="cb1-5"><a></a>  theta<span class="sc">^</span>(y<span class="sc">+</span>alpha<span class="dv">-1</span>) <span class="sc">*</span> (<span class="dv">1</span><span class="sc">-</span>theta)<span class="sc">^</span>(n<span class="sc">-</span>y <span class="sc">+</span> beta <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb1-6"><a></a>}</span>
<span id="cb1-7"><a></a><span class="fu">integrate</span>(<span class="at">f =</span> unnormalized_posterior,</span>
<span id="cb1-8"><a></a>          <span class="at">lower =</span> <span class="dv">0</span>,</span>
<span id="cb1-9"><a></a>          <span class="at">upper =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.066906e-05 with absolute error &lt; 1e-12</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a></a><span class="co"># Compare with known constant</span></span>
<span id="cb3-2"><a></a><span class="fu">beta</span>(y <span class="sc">+</span> alpha, n <span class="sc">-</span> y <span class="sc">+</span> beta)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.066906e-05</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a></a><span class="co"># Monte Carlo integration</span></span>
<span id="cb5-2"><a></a><span class="fu">mean</span>(<span class="fu">unnormalized_posterior</span>(<span class="fu">runif</span>(<span class="fl">1e5</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.061693e-05</code></pre>
</div>
</div>
</section>
<section id="marginal-posterior" class="slide level2">
<h2>Marginal posterior</h2>
<p>In multi-parameter models, additional integration is needed to get the marginal posterior</p>
<p><span class="math display">\[p(\theta_j \mid \boldsymbol{y}) = \int p(\boldsymbol{\theta} \mid \boldsymbol{y}) \mathrm{d} \boldsymbol{\theta}_{-j}.\]</span></p>
<div style="font-size: 65%;">
<p>Marginalization is trivial when we have a joint sample: simply keep the column corresponding to <span class="math inline">\(\theta_j\)</span>.</p>
</div>
</section>
<section id="prior-likelihood-and-posterior" class="slide level2">
<h2>Prior, likelihood and posterior</h2>

<img data-src="bayesmod-slides2_files/figure-revealjs/fig-betabinom-likpost-1.png" width="960" class="r-stretch quarto-figure-center" id="fig-betabinom-likpost"><p class="caption">
Figure&nbsp;2: Scaled Binomial likelihood for six successes out of 14 trials, <span class="math inline">\(\mathsf{beta}(3/2, 3/2)\)</span> prior and corresponding posterior distribution from a beta-binomial model.
</p></section>
<section id="proper-prior" class="slide level2">
<h2>Proper prior</h2>
<p>We could define the posterior simply as the normalized product of the likelihood and some prior function.</p>
<p>The prior function need not even be proportional to a density function (i.e., integrable as a function of <span class="math inline">\(\boldsymbol{\theta}\)</span>).</p>
<p>For example,</p>
<ul>
<li><span class="math inline">\(p(\theta) \propto \theta^{-1}(1-\theta)^{-1}\)</span> is improper because it is not integrable.</li>
<li><span class="math inline">\(p(\theta) \propto 1\)</span> is a proper prior over <span class="math inline">\([0,1]\)</span> (uniform).</li>
</ul>
</section>
<section id="validity-of-the-posterior" class="slide level2">
<h2>Validity of the posterior</h2>
<ul>
<li>The marginal likelihood does not depend on <span class="math inline">\(\boldsymbol{\theta}\)</span>
<ul>
<li>(a normalizing constant)</li>
</ul></li>
<li>For the posterior density to be <em>proper</em>,
<ul>
<li>the marginal likelihood must be a finite!</li>
<li>in continuous models, the posterior is proper whenever the prior function is proper.</li>
</ul></li>
</ul>
</section>
<section id="different-priors-give-different-posteriors" class="slide level2">
<h2>Different priors give different posteriors</h2>

<img data-src="bayesmod-slides2_files/figure-revealjs/fig-betabinom-1.png" width="960" class="r-stretch quarto-figure-center" id="fig-betabinom"><p class="caption">
Figure&nbsp;3: Scaled binomial likelihood for six successes out of 14 trials, with <span class="math inline">\(\mathsf{beta}(3/2, 3/2)\)</span> (left), <span class="math inline">\(\mathsf{beta}(1/4, 1/4)\)</span> (middle) and <span class="math inline">\(\mathsf{unif}[0,1/2]\)</span> (right) priors and posterior density.
</p></section>
<section id="role-of-the-prior" class="slide level2">
<h2>Role of the prior</h2>
<p>The posterior is beta, with expected value <span class="math display">\[\begin{align*}
\mathsf{E}(\theta \mid y) &amp;= w\frac{y}{n} + (1-w) \frac{\alpha}{\alpha + \beta}, \\ w&amp;=\frac{n}{n+\alpha+\beta}
\end{align*}\]</span> a weighted average of</p>
<ul>
<li>the maximum likelihood estimator and</li>
<li>the prior mean.</li>
</ul>
<aside class="notes">
<p>We can think of the parameter <span class="math inline">\(\alpha\)</span> (respectively <span class="math inline">\(\beta\)</span>) as representing the fixed prior number of success (resp. failures).</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="posterior-concentration" class="slide level2">
<h2>Posterior concentration</h2>
<p>Except for stubborn priors, the likelihood contribution dominates in large samples. The impact of the prior is then often negligible.</p>

<img data-src="bayesmod-slides2_files/figure-revealjs/fig-sequential-1.png" width="1152" class="r-stretch quarto-figure-center" id="fig-sequential"><p class="caption">
Figure&nbsp;4: Beta posterior and binomial likelihood with a uniform prior for increasing number of observations (from left to right).
</p></section>
<section id="model-comparison" class="slide level2">
<h2>Model comparison</h2>
<p>Suppose that we have models <span class="math inline">\(\mathcal{M}_m\)</span> <span class="math inline">\((m=1, \ldots, M)\)</span> to be compared, with parameter vectors <span class="math inline">\(\boldsymbol{\theta}^{(m)}\)</span> and data vector <span class="math inline">\(\boldsymbol{y}\)</span> and prior probability <span class="math inline">\(\Pr(\mathcal{M}_m)\)</span>.</p>
<p>The <span class="math inline">\(\color{#c38f16}{\text{posterior odds}}\)</span> for models <span class="math inline">\(\mathcal{M}_i\)</span> vs <span class="math inline">\(\mathcal{M}_j\)</span> is <span class="math display">\[\begin{align*}
\color{#c38f16}{\frac{\Pr(\mathcal{M}_i \mid \boldsymbol{y})}{\Pr(\mathcal{M}_j \mid \boldsymbol{y})}} =
\color{#6e948c}{\frac{p(\boldsymbol{y} \mid \mathcal{M}_i)}{p(\boldsymbol{y} \mid \mathcal{M}_j)}}
\color{#122c43}{\frac{\Pr(\mathcal{M}_i)}{\Pr(\mathcal{M}_j)}}
\end{align*}\]</span> equal to the <span class="math inline">\(\color{#6e948c}{\text{Bayes factor}}\)</span> <span class="math inline">\(\mathsf{BF}_{ij}\)</span> times the <span class="math inline">\(\color{#122c43}{\text{prior odds}}\)</span>.</p>
</section>
<section id="bayes-factors" class="slide level2">
<h2>Bayes factors</h2>
<p>The <span class="math inline">\(\color{#6e948c}{\text{Bayes factor}}\)</span> is the ratio of marginal likelihoods, as <span class="math display">\[\begin{align*}
p(\boldsymbol{y} \mid \mathcal{M}_i) = \int p(y \mid \boldsymbol{\theta}^{(i)}, \mathcal{M}_i) p( \boldsymbol{\theta}^{(i)} \mid \mathcal{M}_i) \mathrm{d}  \boldsymbol{\theta}^{(i)}.
\end{align*}\]</span> Values of <span class="math inline">\(\mathsf{BF}_{ij}&gt;1\)</span> correspond to model <span class="math inline">\(\mathcal{M}_i\)</span> being more likely than <span class="math inline">\(\mathcal{M}_j\)</span>.</p>
<ul>
<li>Strong dependence on the prior <span class="math inline">\(p(\boldsymbol{\theta}^{(i)} \mid \mathcal{M}_i)\)</span>.</li>
<li>Must use proper priors.</li>
</ul>
</section>
<section id="bayes-factor-for-the-binomial-model" class="slide level2">
<h2>Bayes factor for the binomial model</h2>
<p>Consider two models with <span class="math inline">\(Y \mid P^{(i)}=p \sim \mathsf{binom}(n, p)\)</span> and</p>
<ul>
<li><span class="math inline">\(P^{(1)}\sim \mathsf{unif}(0,1)\)</span></li>
<li><span class="math inline">\(P^{(2)}\sim \mathsf{1}_{p=0.5}\)</span>.</li>
</ul>

<img data-src="bayesmod-slides2_files/figure-revealjs/unnamed-chunk-7-1.png" class="quarto-figure quarto-figure-center r-stretch" width="960"></section>
<section id="summarizing-posterior-distributions" class="slide level2">
<h2>Summarizing posterior distributions</h2>
<!-- In frequentist statistics, we focus on a point estimator $\widehat{\boldsymbol{\theta}}$, such as the maximum likelihood estimator, and attempt to derive it's distribution, often relying on approximate large-sample distributions. In contrast, t -->
<p>The output of the Bayesian learning will be either of:</p>
<ol type="1">
<li>a fully characterized distribution (in toy examples).</li>
<li>a numerical approximation to the posterior distribution.</li>
<li>an exact or approximate sample drawn from the posterior distribution.</li>
</ol>
<aside class="notes">
<p>The first case, which we have already encountered, allows us to query moments (mean, median, mode) directly provided there are analytical expressions for the latter, or else we could simulate from the model.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="bayesian-inference-in-practice" class="slide level2 smaller">
<h2>Bayesian inference in practice</h2>
<p>Most of the field revolves around the creation of algorithms that either</p>
<ul>
<li>circumvent the calculation of the normalizing constant
<ul>
<li>(Monte Carlo and Markov chain Monte Carlo methods)</li>
</ul></li>
<li>provide accurate numerical approximation, including for marginalizing out all but one parameter.
<ul>
<li>(integrated nested Laplace approximations, variational inference, etc.)</li>
</ul></li>
</ul>
</section>
<section id="predictive-distributions" class="slide level2">
<h2>Predictive distributions</h2>
<p>Define the <span class="math inline">\(\color{#D55E00}{\text{posterior predictive}}\)</span>, <span class="math display">\[\begin{align*}
p(y_{\text{new}}\mid \boldsymbol{y}) = \int_{\boldsymbol{\Theta}} p(y_{\text{new}} \mid \boldsymbol{\theta}) \color{#D55E00}{p(\boldsymbol{\theta} \mid \boldsymbol{y})} \mathrm{d} \boldsymbol{\theta}
\end{align*}\]</span> and the <span class="math inline">\(\color{#56B4E9}{\text{prior predictive}}\)</span> <span class="math display">\[\begin{align*}
p(y_{\text{new}}) = \int_{\boldsymbol{\Theta}} p(y_{\text{new}} \mid \boldsymbol{\theta}) \color{#56B4E9}{p(\boldsymbol{\theta})} \mathrm{d} \boldsymbol{\theta}
\end{align*}\]</span> is useful for determining whether the prior is sensical.</p>
</section>
<section id="analytical-derivation-of-predictive-distribution" class="slide level2">
<h2>Analytical derivation of predictive distribution</h2>
<p>Given the <span class="math inline">\(\mathsf{beta}(a, b)\)</span> prior or posterior, the predictive for <span class="math inline">\(n_{\text{new}}\)</span> trials is beta-binomial with density <span class="math display">\[\begin{align*}
p(y_{\text{new}}\mid y) &amp;= \int_0^1 \binom{n_{\text{new}}}{y_{\text{new}}} \frac{\theta^{a + y_{\text{new}}-1}(1-\theta)^{b + n_{\text{new}} - y_{\text{new}}-1}}{
\mathrm{Be}(a, b)}\mathrm{d} \theta
\\&amp;= \binom{n_{\text{new}}}{y_{\text{new}}} \frac{\mathrm{Be}(a + y_{\text{new}}, b + n_{\text{new}} - y_{\text{new}})}{\mathrm{Be}(a, b)}
\end{align*}\]</span></p>
<p>Replace <span class="math inline">\(a=y + \alpha\)</span> and <span class="math inline">\(b=n-y + \beta\)</span> to get the posterior predictive distribution.</p>
</section>
<section id="posterior-predictive-distribution" class="slide level2">
<h2>Posterior predictive distribution</h2>

<img data-src="bayesmod-slides2_files/figure-revealjs/fig-betabinompostpred-1.png" width="960" class="r-stretch quarto-figure-center" id="fig-betabinompostpred"><p class="caption">
Figure&nbsp;5: Beta-binomial posterior predictive distribution with corresponding binomial mass function evaluated at the maximum likelihood estimator.
</p></section>
<section id="posterior-predictive-distribution-via-simulation" class="slide level2">
<h2>Posterior predictive distribution via simulation</h2>
<p>The posterior predictive carries over the parameter uncertainty so will typically be wider and overdispersed relative to the corresponding distribution.</p>
<p>Given a draw <span class="math inline">\(\theta^*\)</span> from the posterior, simulate a new observation from the distribution <span class="math inline">\(f(y_{\text{new}}; \theta^*)\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a></a>npost <span class="ot">&lt;-</span> <span class="fl">1e4</span>L</span>
<span id="cb7-2"><a></a><span class="co"># Sample draws from the posterior distribution</span></span>
<span id="cb7-3"><a></a>post_samp <span class="ot">&lt;-</span> <span class="fu">rbeta</span>(<span class="at">n =</span> npost, y <span class="sc">+</span> alpha, n <span class="sc">-</span> y <span class="sc">+</span> beta)</span>
<span id="cb7-4"><a></a><span class="co"># For each draw, sample new observation</span></span>
<span id="cb7-5"><a></a>post_pred <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="at">n =</span> npost, <span class="at">size =</span> n, <span class="at">prob =</span> post_samp)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div style="font-size: 65%;">
<p>The beta-binomial is used to model overdispersion in binary regression models.</p>
</div>
</section>
<section id="summarizing-posterior-distributions-1" class="slide level2">
<h2>Summarizing posterior distributions</h2>
<p>The output of a Bayesian procedure is a <strong>distribution</strong> for the parameters given the data.</p>
<p>We may wish to return different numerical summaries (expected value, variance, mode, quantiles, …)</p>
<p>The question: which point estimator to return?</p>
</section>
<section id="decision-theory-and-loss-functions" class="slide level2">
<h2>Decision theory and loss functions</h2>
<p>A loss function <span class="math inline">\(c(\boldsymbol{\theta}, \boldsymbol{\upsilon}): \boldsymbol{\Theta} \mapsto \mathbb{R}^k\)</span> assigns a weight to each value <span class="math inline">\(\boldsymbol{\theta}\)</span>, corresponding to the regret or loss.</p>
<p>The point estimator <span class="math inline">\(\widehat{\boldsymbol{\upsilon}}\)</span> is the minimizer of the expected loss <span class="math display">\[\begin{align*}
\widehat{\boldsymbol{\upsilon}} &amp;= \mathop{\mathrm{argmin}}_{\boldsymbol{\upsilon}}\mathsf{E}_{\boldsymbol{\Theta} \mid \boldsymbol{Y}}\{c(\boldsymbol{\theta}, \boldsymbol{v})\} \\&amp;=\mathop{\mathrm{argmin}}_{\boldsymbol{\upsilon}} \int_{\boldsymbol{\Theta}} c(\boldsymbol{\theta}, \boldsymbol{\upsilon})p(\boldsymbol{\theta} \mid \boldsymbol{y}) \mathrm{d} \boldsymbol{\theta}
\end{align*}\]</span></p>
</section>
<section id="point-estimators-and-loss-functions" class="slide level2">
<h2>Point estimators and loss functions</h2>
<p>In a univariate setting, the most widely used point estimators are</p>
<ul>
<li>mean: quadratic loss <span class="math inline">\(c(\theta, \upsilon) = (\theta-\upsilon)^2\)</span></li>
<li>median: absolute loss <span class="math inline">\(c(\theta, \upsilon)=|\theta - \upsilon|\)</span></li>
<li>mode: 0-1 loss <span class="math inline">\(c(\theta, \upsilon) = 1-\mathrm{I}(\upsilon = \theta)\)</span></li>
</ul>
<p>The posterior mode <span class="math inline">\(\boldsymbol{\theta}_{\mathrm{map}} = \mathrm{argmax}_{\boldsymbol{\theta}} p(\boldsymbol{\theta} \mid \boldsymbol{y})\)</span> is the <strong>maximum a posteriori</strong> or MAP estimator.</p>
</section>
<section id="measures-of-central-tendency" class="slide level2">
<h2>Measures of central tendency</h2>

<img data-src="bayesmod-slides2_files/figure-revealjs/fig-central-moments-1.png" width="960" class="r-stretch quarto-figure-center" id="fig-central-moments"><p class="caption">
Figure&nbsp;6: Point estimators from a right-skewed distribution (left) and from a multimodal distribution (right).
</p></section>
<section id="example-of-loss-functions" class="slide level2">
<h2>Example of loss functions</h2>

<img data-src="bayesmod-slides2_files/figure-revealjs/fig-losses-1.png" width="768" class="r-stretch quarto-figure-center" id="fig-losses"><p class="caption">
Figure&nbsp;7: Posterior density with mean, mode and median point estimators (left) and corresponding loss functions, scaled to have minimum value of zero (right).
</p></section>
<section id="credible-regions" class="slide level2">
<h2>Credible regions</h2>
<p>The freshman dream comes true!</p>
<p>A <span class="math inline">\(1-\alpha\)</span> credible region give a set of parameter values which contains the “true value” of the parameter <span class="math inline">\(\boldsymbol{\theta}\)</span> with probability <span class="math inline">\(1-\alpha\)</span>.</p>
<p>Caveat: <span class="citation" data-cites="McElreath:2020">McElreath (<a href="#/references" role="doc-biblioref" onclick="">2020</a>)</span> suggests the term ‘compatibility’, as it</p>
<blockquote>
<p>returns the range of parameter values compatible with the model and data.</p>
</blockquote>
</section>
<section id="which-credible-intervals" class="slide level2">
<h2>Which credible intervals?</h2>
<p>Multiple <span class="math inline">\(1-\alpha\)</span> intervals, most common are</p>
<ul>
<li>equitailed: region <span class="math inline">\(\alpha/2\)</span> and <span class="math inline">\(1-\alpha/2\)</span> quantiles and</li>
<li><strong>highest posterior density interval</strong> (HPDI), which gives the smallest interval <span class="math inline">\((1-\alpha)\)</span> probability</li>
</ul>
<div style="font-size: 65%;">
<p>If we accept to have more than a single interval, the highest posterior density region can be a set of disjoint intervals. The HDPI is more sensitive to the number of draws and more computationally intensive (see <strong>R</strong> package <code>HDinterval</code>). See <span class="citation" data-cites="Hyndman:1996">Hyndman (<a href="#/references" role="doc-biblioref" onclick="">1996</a>)</span> for computations.</p>
</div>
</section>
<section id="illustration-of-credible-regions" class="slide level2">
<h2>Illustration of credible regions</h2>

<img data-src="bayesmod-slides2_files/figure-revealjs/fig-credible-intervals-1.png" width="960" class="r-stretch quarto-figure-center" id="fig-credible-intervals"><p class="caption">
Figure&nbsp;8: Density plots with 89% (top) and 50% (bottom) equitailed or central credible (left) and highest posterior density (right) regions for two data sets, highlighted in grey.
</p></section>
<section id="computations-of-credible-intervals" class="slide level2">
<h2>Computations of credible intervals</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a></a><span class="fu">set.seed</span>(<span class="dv">2023</span>)</span>
<span id="cb8-2"><a></a>postsamp <span class="ot">&lt;-</span> <span class="fu">rbeta</span>(<span class="at">n =</span> <span class="dv">1000</span>, <span class="at">shape1 =</span> <span class="fl">0.5</span>, <span class="at">shape2 =</span> <span class="fl">0.2</span>)</span>
<span id="cb8-3"><a></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.11</span></span>
<span id="cb8-4"><a></a><span class="co"># Compute equitailed interval bounds</span></span>
<span id="cb8-5"><a></a><span class="fu">quantile</span>(postsamp, <span class="at">probs =</span> <span class="fu">c</span>(alpha<span class="sc">/</span><span class="dv">2</span>, <span class="dv">1</span><span class="sc">-</span>alpha<span class="sc">/</span><span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     5.5%     94.5% 
0.0246807 0.9999980 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a></a><span class="co"># Analytical (true) values</span></span>
<span id="cb10-2"><a></a><span class="fu">qbeta</span>(<span class="fu">c</span>(alpha<span class="sc">/</span><span class="dv">2</span>, <span class="dv">1</span><span class="sc">-</span>alpha<span class="sc">/</span><span class="dv">2</span>), <span class="at">shape1 =</span> <span class="fl">0.5</span>, <span class="at">shape2 =</span> <span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.02925205 0.99999844</code></pre>
</div>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a></a><span class="co"># Highest posterior density intervals - note values are outside of the support!</span></span>
<span id="cb12-2"><a></a>(hdiD <span class="ot">&lt;-</span> HDInterval<span class="sc">::</span><span class="fu">hdi</span>(<span class="fu">density</span>(postsamp), <span class="at">credMass =</span> <span class="dv">1</span><span class="sc">-</span>alpha, <span class="at">allowSplit =</span> <span class="cn">TRUE</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           begin       end
[1,] -0.04331573 0.2800577
[2,]  0.47816030 1.1423868
attr(,"credMass")
[1] 0.89
attr(,"height")
[1] 0.3898784</code></pre>
</div>
</div>
</section>
<section id="references" class="slide level2 smaller scrollable">
<h2>References</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-Casella.Berger:2002" class="csl-entry" role="listitem">
Casella, G., &amp; Berger, R. L. (2002). <em>Statistical inference</em> (2nd ed.). Duxbury.
</div>
<div id="ref-deFinetti:1974" class="csl-entry" role="listitem">
Finetti, B. de. (1974). <em>Theory of probability: A critical introductory treatment</em> (Vol. 1). Wiley.
</div>
<div id="ref-Hyndman:1996" class="csl-entry" role="listitem">
Hyndman, R. J. (1996). Computing and graphing highest density regions. <em>The American Statistician</em>, <em>50</em>(2), 120–126. <a href="https://doi.org/10.1080/00031305.1996.10474359">https://doi.org/10.1080/00031305.1996.10474359</a>
</div>
<div id="ref-McElreath:2020" class="csl-entry" role="listitem">
McElreath, R. (2020). <em>Statistical rethinking: A <span>B</span>ayesian course with examples in <span>R</span> and <span>STAN</span></em> (2nd ed.). Chapman; Hall/CRC.
</div>
</div>
</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="fig/logo_hec_montreal_bleu_web.png" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1200,

        height: 900,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp("https:\/\/lbelzile\.github\.io\/bayesmod");
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>