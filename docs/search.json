[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Outline",
    "section": "",
    "text": "Dr. Léo Belzile\n   4.850, Côte-Sainte-Catherine\n   leo.belzile@hec.ca\n\n\n\n\n\n   Winter 2025\n   Monday\n   15:30-18:30\n   CSC, Labid Aljundi"
  },
  {
    "objectID": "syllabus.html#textbooks",
    "href": "syllabus.html#textbooks",
    "title": "Outline",
    "section": "Textbooks",
    "text": "Textbooks\nCourse notes for the class can be found online\nAdditional references include Gelman et al. (2013), McElreath (2020) and Johnson et al. (2022).\n\nA. Gelman, J. Carlin, H. Stern, D. Dunson, A. Vehtari and D. Rubin (2013). Bayesian Data Analysis, 3rd edition, CRC press. doi: 10.1201/b16018\nR. McElreath (2020). Statistical Rethinking:A Bayesian Course with Examples in R and Stan, 2nd edition, CRC Press.\nA.A. Johnson, M.Q. Ott, and M. Dogucu (2022). Bayes Rules!An Introduction to Applied Bayesian Modeling, 1st edition, CRC Press. Free available online."
  },
  {
    "objectID": "syllabus.html#other-references",
    "href": "syllabus.html#other-references",
    "title": "Outline",
    "section": "Other references",
    "text": "Other references\nThere will occasionally be additional articles to read; links to these other resources will be included on the content page for that session."
  },
  {
    "objectID": "syllabus.html#weekly-check-in",
    "href": "syllabus.html#weekly-check-in",
    "title": "Outline",
    "section": "Weekly check-in",
    "text": "Weekly check-in\nEvery week, after you finish working through the content, I want to hear about what you learned and what questions you still have. To facilitate this, and to encourage engagement with the course content, you’ll need to write a small feedback in ZoneCours. This should be ~150 words.\nYou should answer the following three questions each week:\n\nWhat was the most exciting thing you learned from the session? Why?\nWhat was the muddiest thing from the session this week? What are you still wondering about?\nWhich activity did you find the most useful? What could have been skipped?\n\nThe weekly check-in is an occasion for you to ask for clarification, highlight areas or topics for which examples could be added, or list superfluous activities and content. I will grade these before class, answer individually through the feedback form or at the beginning of class.\nI will grade these check-ins using a check system:\n\n110%: Response shows phenomenal thought and engagement with the course content. I will not assign these often.\n100%: Response is thoughtful, well-written, and shows engagement with the course content. This is the expected level of performance.\n50%: Response is hastily composed, too short, and/or only cursorily engages with the course content. This grade signals that you need to improve next time. I will hopefully not assign these often.\n\nNotice that is essentially a pass/fail or completion-based system. I’m not grading your writing ability, I’m not counting the exact number of words you’re writing, and I’m not looking for encyclopedic citations of every single reading to prove that you did indeed read everything. I’m looking for thoughtful engagement, that’s all. Do good work and you’ll get a ✔.\n\n\n\n\n\n\n\n\n\nAssignment\nPoints\n\n\n\n\nWeekly check-in (10 × 0.5 pt)\n5\n\n\nAssignments\n30\n\n\nMidterm examination (30 pts)\n30\n\n\nFinal examination (35 pts)\n35\n\n\nTotal\n100"
  },
  {
    "objectID": "syllabus.html#student-hours",
    "href": "syllabus.html#student-hours",
    "title": "Outline",
    "section": "Student hours",
    "text": "Student hours\nMonday before class or by appointment. My office, 4.850, is located next to the southern elevators in Côte-Sainte-Catherine building.\nPlease watch this video:\n\n\nStudent hours are set times dedicated to all of you (most professors call these “office hours”; I don’t1). This means that I will be in my office waiting for you to come by if you want to talk to me in person (or remotely) with whatever questions you have. This is the best and easiest way to find me and the best chance for discussing class material and concerns."
  },
  {
    "objectID": "syllabus.html#intellectual-integrity",
    "href": "syllabus.html#intellectual-integrity",
    "title": "Outline",
    "section": "Intellectual integrity",
    "text": "Intellectual integrity\nPlease don’t cheat! The official policy lists the school rules regarding plagiarism and academic integrity."
  },
  {
    "objectID": "syllabus.html#student-services",
    "href": "syllabus.html#student-services",
    "title": "Outline",
    "section": "Student services",
    "text": "Student services\nStudents with special needs should feel free to approach me so we can best discuss accommodations. Do check out HEC Montréal’s disabled students and psychological support services."
  },
  {
    "objectID": "syllabus.html#harassment-and-sexual-violence",
    "href": "syllabus.html#harassment-and-sexual-violence",
    "title": "Outline",
    "section": "Harassment and sexual violence",
    "text": "Harassment and sexual violence\nThe Center for Harassment Intervention (BIMH) is the unique access point for all members of the community subject to harassment or sexual violence. You can reach them at 514 343-7020 or by email at harcelement@hec.ca from Monday until Friday, from 8:30 until 4:30pm.\nIf you are in an emergency situation or fear for your safety, call emergency services at 911, followed by HEC Montréal security services at 514 340-6611.\nCheck the school official policy on these matters for more details."
  },
  {
    "objectID": "syllabus.html#family-policy",
    "href": "syllabus.html#family-policy",
    "title": "Outline",
    "section": "Family policy",
    "text": "Family policy\nHEC now has an official family policy, but the following guidelines reflect my own beliefs and commitments towards parent students2\n\nBabies are welcome in class as often as necessary for support feeding relationship.\nYou are welcome to bring your child to class in order to cover unforeseeable gaps in childcare.\nIf you come with babies or toddler, I ask that you sit close to the door so that, in case your little one needs special attention and is disrupting the learning of other students, you may step outside of class until their needs are met. Seats close to the door are reserved for parents attending class with their child."
  },
  {
    "objectID": "syllabus.html#footnotes",
    "href": "syllabus.html#footnotes",
    "title": "Outline",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThere’s fairly widespread misunderstanding about what office hours actually are! Many students often think that they are the times I shouldn’t be disturbed, which is the exact opposite of what they’re for!↩︎\nShamelessly stolen/adapted from similar policy by Drs. Melissa Cheney, Guy Grossman and Rohan Alexander↩︎"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#outline",
    "href": "slides/bayesmod-slides6.html#outline",
    "title": "Bayesian modelling",
    "section": "Outline",
    "text": "Outline\nHow do we assess convergence of a MCMC algorithm?\n\nthe algorithm implementation must be correct,\nthe chain must have converged to the target posterior.\nthe effective sample size must be sufficiently large for inference."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#strategies",
    "href": "slides/bayesmod-slides6.html#strategies",
    "title": "Bayesian modelling",
    "section": "Strategies",
    "text": "Strategies\nMany diagnostics require running multiple chains\n\ncheck within vs between variance,\ndetermine whether they converge to the same target."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#correct-implementation",
    "href": "slides/bayesmod-slides6.html#correct-implementation",
    "title": "Bayesian modelling",
    "section": "Correct implementation",
    "text": "Correct implementation\nWe can generate artificial data to check the procedure.\nSimulation-based calibration (Talts et al., 2020) proceeds with, in order\n\n\\(\\boldsymbol{\\theta}_0 \\sim p(\\boldsymbol{\\theta}),\\)\n\\(\\boldsymbol{y}_0 \\sim p(\\boldsymbol{y} \\mid \\boldsymbol{\\theta}_0),\\)\n\\(\\boldsymbol{\\theta}_1, \\ldots, \\boldsymbol{\\theta}_B \\sim p(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}_0 ).\\)"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#simulation-based-calibration",
    "href": "slides/bayesmod-slides6.html#simulation-based-calibration",
    "title": "Bayesian modelling",
    "section": "Simulation-based calibration",
    "text": "Simulation-based calibration\n\nConditional on the simulated \\(\\boldsymbol{y}\\), the distribution of \\(\\boldsymbol{\\theta}_0\\) is the same as that of \\(\\boldsymbol{\\theta}_1, \\ldots, \\boldsymbol{\\theta}_B.\\)\nWe do a dimension reduction step taking the test function \\(t(\\cdot)\\) to get the rank of the prior draw among the posterior ones, breaking ties at random if any.\nThese steps are repeated \\(K\\) times, yielding \\(K\\) test functions \\(T_1, \\ldots, T_K.\\) We then test for uniformity using results from Säilynoja et al. (2022)."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#breaking-down-the-markov-chain",
    "href": "slides/bayesmod-slides6.html#breaking-down-the-markov-chain",
    "title": "Bayesian modelling",
    "section": "Breaking down the Markov chain",
    "text": "Breaking down the Markov chain\nWe distinguish between three phases\n\nburn in period: initial draws allowing the algorithm to converge to it’s stationary distribution (discarded)\nwarmup adaptation period: tuning period for the proposal std. deviation, etc. (discarded)\nsampling period: draws post burn in and warmup that are kept for inference\n\nWe can optionally thin by keeping one every \\(k\\) iterations from the sampling period to reduce the storage."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#visual-diagnostic-trace-plots",
    "href": "slides/bayesmod-slides6.html#visual-diagnostic-trace-plots",
    "title": "Bayesian modelling",
    "section": "Visual diagnostic: trace plots",
    "text": "Visual diagnostic: trace plots\nDisplay the Markov chain sample path as a function of the number of iterations.\n\nIdeally, run multiple chains to see if they converge to the same mode (for multimodal behaviour).\nMarkov chains should look like a fat hairy caterpillar!\nCheck the bayesplot and coda R packages (trace plot, trace rank, correlograms, marginal densities, etc.)"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#checking-convergence-with-multiple-chains",
    "href": "slides/bayesmod-slides6.html#checking-convergence-with-multiple-chains",
    "title": "Bayesian modelling",
    "section": "Checking convergence with multiple chains",
    "text": "Checking convergence with multiple chains\n\nFour healthy parallel chains for parameters."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#trace-rank-plot",
    "href": "slides/bayesmod-slides6.html#trace-rank-plot",
    "title": "Bayesian modelling",
    "section": "Trace rank plot",
    "text": "Trace rank plot\nA trace rank plot compares the rank of the values of the different chain at a given iteration.\n\nWith good mixing, the ranks should switch frequently and be distributed uniformly across integers."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#effective-sample-size",
    "href": "slides/bayesmod-slides6.html#effective-sample-size",
    "title": "Bayesian modelling",
    "section": "Effective sample size",
    "text": "Effective sample size\nAre my chains long enough to compute reliable summaries?\nCompute the sample size we would have with independent draws by taking \\[\n\\mathsf{ESS} = \\frac{B}{\\left\\{1+2\\sum_{t=1}^\\infty \\gamma_t\\right\\}}\n\\] where \\(\\gamma_t\\) is the lag \\(t\\) autocorrelation.\nThe relative effective sample size is simply \\(\\mathsf{ESS}/B\\): small values indicate pathological or inefficient samplers."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#how-many-samples",
    "href": "slides/bayesmod-slides6.html#how-many-samples",
    "title": "Bayesian modelling",
    "section": "How many samples?",
    "text": "How many samples?\nWe want our average estimate to be reliable!\n\nWe probably need \\(\\mathsf{ESS}\\) to be several hundred\nWe can estimate the variance of the target to know the precision\n(related question: how many significant digits to report?)"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#estimating-the-variance-block-method",
    "href": "slides/bayesmod-slides6.html#estimating-the-variance-block-method",
    "title": "Bayesian modelling",
    "section": "Estimating the variance (block method)",
    "text": "Estimating the variance (block method)\n\nBreak the chain of length \\(B\\) (after burn in) in \\(K\\) blocks of size \\(\\approx K/B\\).\nCompute the sample mean of each segment. These values form a Markov chain and should be approximately uncorrelated.\nCompute the standard deviation of the segments mean. Rescale by \\(K^{-1/2}\\) to get standard error of the global mean.\n\nMore efficient methods using overlapping blocks exists."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#block-means-in-pictures",
    "href": "slides/bayesmod-slides6.html#block-means-in-pictures",
    "title": "Bayesian modelling",
    "section": "Block means in pictures",
    "text": "Block means in pictures\n\n\nFigure 1: Calculation of the standard error of the posterior mean using the batch method."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#cautionary-warning-about-stationarity",
    "href": "slides/bayesmod-slides6.html#cautionary-warning-about-stationarity",
    "title": "Bayesian modelling",
    "section": "Cautionary warning about stationarity",
    "text": "Cautionary warning about stationarity\nBatch means only works if the chain is sampling from the stationary distribution!\nThe previous result (and any estimate) will be unreliable and biased if the chain is not (yet) sampling from the posterior."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#lack-of-stationarity",
    "href": "slides/bayesmod-slides6.html#lack-of-stationarity",
    "title": "Bayesian modelling",
    "section": "Lack of stationarity",
    "text": "Lack of stationarity\n\n\nFigure 2: Traceplots of three Markov chains for the same target with different initial values for the first 500 iterations (left) and trace rank plot after discarding these (right). The latter is indicative of the speed of mixing."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#gelmanrubin-diagnostic",
    "href": "slides/bayesmod-slides6.html#gelmanrubin-diagnostic",
    "title": "Bayesian modelling",
    "section": "Gelman–Rubin diagnostic",
    "text": "Gelman–Rubin diagnostic\nSuppose we run \\(M\\) chains for \\(B\\) iterations, post burn in.\nDenote by \\(\\theta_{bm}\\) the \\(b\\)th draw of the \\(m\\)th chain, we compute the global average \\[\\overline{\\theta} = \\frac{1}{BM}\\sum_{b=1}^B \\sum_{m=1}^m \\theta_{bm}\\] and similarly the chain-specific sample average and variances, respectively \\(\\overline{\\theta}_m\\) and \\(\\widehat{\\sigma}^2_m\\) (\\(m=1, \\ldots, M\\))."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#sum-of-square-decomposition",
    "href": "slides/bayesmod-slides6.html#sum-of-square-decomposition",
    "title": "Bayesian modelling",
    "section": "Sum of square decomposition",
    "text": "Sum of square decomposition\nThe between-chain variance and within-chain variance estimator are \\[\\begin{align*}\n\\mathsf{Va}_{\\text{between}} &= \\frac{B}{M-1}\\sum_{m=1}^M (\\overline{\\theta}_m - \\overline{\\theta})^2\\\\\n\\mathsf{Va}_{\\text{within}} &= \\frac{1}{M}\\sum_{m=1}^m \\widehat{\\sigma}^2_m\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#potential-scale-reduction-statistic",
    "href": "slides/bayesmod-slides6.html#potential-scale-reduction-statistic",
    "title": "Bayesian modelling",
    "section": "Potential scale reduction statistic",
    "text": "Potential scale reduction statistic\nThe Gelman–Rubin diagnostic, denoted \\(\\widehat{R}\\), is obtained by running multiple chains and considering the difference between within-chain and between-chains variances,\n\\[\\begin{align*}\n\\widehat{R} = \\left(\\frac{\\mathsf{Va}_{\\text{within}}(B-1) + \\mathsf{Va}_{\\text{between}}}{B\\mathsf{Va}_{\\text{within}}}\\right)^{1/2}\n\\end{align*}\\]\nAny value of \\(\\widehat{R}\\) larger 1 is indicative of problems of convergence."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#bad-chains",
    "href": "slides/bayesmod-slides6.html#bad-chains",
    "title": "Bayesian modelling",
    "section": "Bad chains",
    "text": "Bad chains\n\n\nFigure 3: Two pairs of Markov chains: the top ones seem stationary, but with different modes and \\(\\widehat{R} \\approx 3.4\\). The chains on the right hover around zero, but do not appear stable, with \\(\\widehat{R} \\approx 1.6\\)."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#one-chain-or-multiple-chains",
    "href": "slides/bayesmod-slides6.html#one-chain-or-multiple-chains",
    "title": "Bayesian modelling",
    "section": "One chain or multiple chains?",
    "text": "One chain or multiple chains?\nGenerally, it is preferable to run a single chain for a longer period than run multiple chains sequentially\n\nthere is a cost to initializing multiple times with different starting values since we must discard initial draws.\nbut with parallel computations, multiple chains are more frequent nowadays.\nmultiple diagnostics require running several chains."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#posterior-predictive-checks",
    "href": "slides/bayesmod-slides6.html#posterior-predictive-checks",
    "title": "Bayesian modelling",
    "section": "Posterior predictive checks",
    "text": "Posterior predictive checks\n\nFor each of the \\(B\\) draws from the posterior, simulate \\(n\\) observations from the posterior predictive \\(p(\\widetilde{\\boldsymbol{y}} \\mid \\boldsymbol{y})\\)\nFor each replicate, compute a summary statistics (median, quantiles, std. dev., etc.)\nCompare it with the same summary computed for the sample \\(\\boldsymbol{y}\\)."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#posterior-predictive-checks-1",
    "href": "slides/bayesmod-slides6.html#posterior-predictive-checks-1",
    "title": "Bayesian modelling",
    "section": "Posterior predictive checks",
    "text": "Posterior predictive checks\n\n\nFigure 4: Posterior predictive checks for the standard deviation (top) and density of posterior draws (bottom) for hierarchical Poisson model with individual effects (left) and simpler model with only conditions (right)."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#log-pointwise-predictive-density",
    "href": "slides/bayesmod-slides6.html#log-pointwise-predictive-density",
    "title": "Bayesian modelling",
    "section": "Log pointwise predictive density",
    "text": "Log pointwise predictive density\nConsider the expected value of the observation-wise log density with respect to the posterior distribution \\(p(\\boldsymbol{\\theta} \\mid \\boldsymbol{y})\\), \\[\\begin{align*}\n\\mathsf{LPPD}_i = \\mathsf{E}_{\\boldsymbol{\\theta} \\mid \\boldsymbol{y}} \\left\\{ \\log p(y_i \\mid \\boldsymbol{\\theta})\\right\\},\n\\end{align*}\\]\nThe higher the value of \\(\\mathsf{LPPD}_i\\), the better the fit for that observation."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#widely-available-information-criterion",
    "href": "slides/bayesmod-slides6.html#widely-available-information-criterion",
    "title": "Bayesian modelling",
    "section": "Widely available information criterion",
    "text": "Widely available information criterion\nTo build an information criterion, we add a penalization factor that approximates the effective number of parameters in the model, with \\[\\begin{align*}\nn\\mathsf{WAIC} = -\\sum_{i=1}^n \\mathsf{LPPD}_i + \\sum_{i=1}^n \\mathsf{Va}_{\\boldsymbol{\\theta} \\mid \\boldsymbol{y}}\\{\\log p(y_i \\mid \\boldsymbol{\\theta})\\}\n\\end{align*}\\] where we use again the empirical variance to compute the rightmost term.\nSmaller values of \\(\\mathsf{WAIC}\\) are better."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#pseudo-code-for-waic",
    "href": "slides/bayesmod-slides6.html#pseudo-code-for-waic",
    "title": "Bayesian modelling",
    "section": "Pseudo-code for WAIC",
    "text": "Pseudo-code for WAIC\nEvaluate the log likelihood for each posterior draw and each observation.\n\n#' WAIC\n#' @param loglik_pt B by n matrix of pointwise log likelihood\nWAIC &lt;- function(loglik_pt){\n  -mean(apply(loglik_pt, 2, mean)) +  mean(apply(loglik_pt, 2, var))\n}"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#bayesian-leave-one-out-cross-validation",
    "href": "slides/bayesmod-slides6.html#bayesian-leave-one-out-cross-validation",
    "title": "Bayesian modelling",
    "section": "Bayesian leave-one-out cross validation",
    "text": "Bayesian leave-one-out cross validation\nIn Bayesian setting, we can use the leave-one-out predictive density \\[p(y_i \\mid \\boldsymbol{y}_{-i})\\] as a measure of predictive accuracy.\nWe can use importance sampling to approximate the latter.\nRequirement: need to keep track of the log likelihood of each observation for each posterior draw (\\(B \\times n\\) values)."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#loo-cv-diagnostics",
    "href": "slides/bayesmod-slides6.html#loo-cv-diagnostics",
    "title": "Bayesian modelling",
    "section": "LOO-CV diagnostics",
    "text": "LOO-CV diagnostics\nWe can draw \\(B\\) samples from \\(p(\\widetilde{y} \\mid \\boldsymbol{y}_{-i})\\) and compute the rank of \\(y_i\\).\nUnder perfect calibration, ranks should be uniform."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#leave-one-out-with-quantile-quantile-plots",
    "href": "slides/bayesmod-slides6.html#leave-one-out-with-quantile-quantile-plots",
    "title": "Bayesian modelling",
    "section": "Leave-one-out with quantile-quantile plots",
    "text": "Leave-one-out with quantile-quantile plots\n\n\nFigure 5: Quantile-quantile plots based on leave-one-out cross validation for model for the hierarchical Poisson model fitted to the Upworthy data with the individual random effects (left) and without (right)."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#deviance-information-criterion",
    "href": "slides/bayesmod-slides6.html#deviance-information-criterion",
    "title": "Bayesian modelling",
    "section": "Deviance information criterion",
    "text": "Deviance information criterion\nThe deviance information criterion of Spiegelhalter et al. (2002) is \\[\\begin{align*}\n\\mathsf{DIC} = -2 \\ell(\\widetilde{\\boldsymbol{\\theta}}) + 2 p_D\n\\end{align*}\\] where \\(p_D\\) is the posterior expectation of the deviance relative to the point estimator of the parameter \\(\\widetilde{\\boldsymbol{\\theta}}\\) (e.g., the maximum a posteriori or the posterior mean) \\[\\begin{align*}\np_D = \\mathsf{E}\\{D(\\boldsymbol{\\theta}, \\widetilde{\\boldsymbol{\\theta}}) \\mid \\boldsymbol{y}\\}= \\int 2 \\{ \\ell(\\widetilde{\\boldsymbol{\\theta}}) - \\ell(\\boldsymbol{\\theta})\\} p(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}) \\mathrm{d} \\boldsymbol{\\theta}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#criticism-of-dic",
    "href": "slides/bayesmod-slides6.html#criticism-of-dic",
    "title": "Bayesian modelling",
    "section": "Criticism of DIC",
    "text": "Criticism of DIC\n\nThe DIC can be easily evaluated by keeping track of the log likelihood evaluated at each posterior draw from a Markov chain Monte Carlo algorithm.\nThe penalty term \\(p_D\\) is however not invariant to reparametrizations.\nA Gaussian approximation to the MLE under suitable regularity conditions shows that the \\(\\mathsf{DIC}\\) is equivalent in large samples to \\(\\mathsf{AIC}.\\)"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#sources-of-poor-mixing",
    "href": "slides/bayesmod-slides6.html#sources-of-poor-mixing",
    "title": "Bayesian modelling",
    "section": "Sources of poor mixing",
    "text": "Sources of poor mixing\nSlow mixing can be due to the following:\n\npoor proposals\nstrong correlation between posterior parameters\noverparametrization and lack of identifiability"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#computational-strategies-1",
    "href": "slides/bayesmod-slides6.html#computational-strategies-1",
    "title": "Bayesian modelling",
    "section": "Computational strategies",
    "text": "Computational strategies\nThese problems can be addressed using one of the following:\n\nremoving redundant parameters or pinning some using sharp priors\nreparametrization\nclever proposals (adaptive MCMC), see Andrieu & Thoms (2008) and Rosenthal (2011).\nmarginalization\nblocking"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#removing-redundant-parameters",
    "href": "slides/bayesmod-slides6.html#removing-redundant-parameters",
    "title": "Bayesian modelling",
    "section": "Removing redundant parameters",
    "text": "Removing redundant parameters\nConsider a one-way ANOVA with \\(K\\) categories, with observation \\(i\\) from group \\(k\\) having \\[\\begin{align*}\nY_{i,k} &\\sim \\mathsf{Gauss}(\\mu + \\alpha_k, \\sigma^2_y) \\\\\n\\alpha_k &\\sim \\mathsf{Gauss}(0, \\sigma^2_\\alpha)\n\\end{align*}\\] and an improper prior for the mean \\(p(\\mu) \\propto 1.\\)\nThere are \\(K+1\\) mean parameters for the groups, so we can enforce a sum-to-zero constraint for \\(\\sum_{k=1}^K \\alpha_k=0\\) and sample \\(K-1\\) parameters for the difference to the global mean."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#parameter-expansion",
    "href": "slides/bayesmod-slides6.html#parameter-expansion",
    "title": "Bayesian modelling",
    "section": "Parameter expansion",
    "text": "Parameter expansion\nAdd redundant parameter to improve mixing by decorrelating (Liu et al., 1998)\n\\[\\begin{align*}\nY_{i,k} &\\sim \\mathsf{Gauss}(\\mu + \\xi\\eta_k, \\sigma^2_y) \\\\\n\\eta_k &\\sim \\mathsf{Gauss}(0, \\sigma^2_\\eta)\n\\end{align*}\\] so that \\(\\sigma_\\alpha = |\\xi|\\sigma_\\eta.\\)"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#marginalization",
    "href": "slides/bayesmod-slides6.html#marginalization",
    "title": "Bayesian modelling",
    "section": "Marginalization",
    "text": "Marginalization\nGiven a model \\(p(\\boldsymbol{\\theta}, \\boldsymbol{Z})\\), reduce the dependance by sampling from the marginal\n\\[\np(\\boldsymbol{\\theta})= \\int p(\\boldsymbol{\\theta}, \\boldsymbol{z}) \\mathrm{d} \\boldsymbol{z}.\n\\]\nThis happens for data augmentation, etc., and reduces dependency between parameters, but typically the likelihood becomes more expensive to compute"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#gaussian-model-with-random-effects",
    "href": "slides/bayesmod-slides6.html#gaussian-model-with-random-effects",
    "title": "Bayesian modelling",
    "section": "Gaussian model with random effects",
    "text": "Gaussian model with random effects\nConsider a hierarchical Gaussian model of the form \\[\\begin{align*}\n\\boldsymbol{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{Z}\\boldsymbol{B} + \\boldsymbol{\\varepsilon}\n\\end{align*}\\] where\n\n\\(\\mathbf{X}\\) is an \\(n \\times p\\) design matrix with centered inputs,\n\\(\\boldsymbol{\\beta} \\sim \\mathsf{Gauss}(\\boldsymbol{0}_p, \\sigma^2\\mathbf{I}_p),\\)\n\\(\\boldsymbol{B}\\sim \\mathsf{Gauss}_q(\\boldsymbol{0}_q, \\boldsymbol{\\Omega})\\) are random effects and\n\\(\\boldsymbol{\\varepsilon} \\sim \\mathsf{Gauss}_n(\\boldsymbol{0}_n, \\kappa^2\\mathbf{I}_n)\\) are independent white noise."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#marginalization-of-gaussian-models",
    "href": "slides/bayesmod-slides6.html#marginalization-of-gaussian-models",
    "title": "Bayesian modelling",
    "section": "Marginalization of Gaussian models",
    "text": "Marginalization of Gaussian models\nWe can write \\[\\begin{align*}\n\\boldsymbol{Y} \\mid \\boldsymbol{\\beta}, \\boldsymbol{B}, \\sigma^2 &\\sim \\mathsf{Gauss}_n(\\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{Z}\\boldsymbol{B},  \\sigma^2\\mathbf{I}_p)\\\\\n\\boldsymbol{Y} \\mid \\boldsymbol{\\beta} &\\sim \\mathsf{Gauss}_n(\\mathbf{X}\\boldsymbol{\\beta}, \\mathbf{Q}^{-1}),\n\\end{align*}\\] where the second line corresponds to marginalizing out the random effects \\(\\boldsymbol{B}.\\)"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#efficient-calculations-for-gaussian-models",
    "href": "slides/bayesmod-slides6.html#efficient-calculations-for-gaussian-models",
    "title": "Bayesian modelling",
    "section": "Efficient calculations for Gaussian models",
    "text": "Efficient calculations for Gaussian models\nIf, as is often the case, \\(\\boldsymbol{\\Omega}^{-1}\\) and \\(\\mathbf{Z}\\) are sparse matrices, the full precision matrix can be efficiently computed using Shermann–Morisson–Woodbury identity as \\[\\begin{align*}\n\\mathbf{Q}^{-1} &=   \\mathbf{Z}\\boldsymbol{\\Omega}^{-1}\\mathbf{Z}^\\top + \\kappa^2 \\mathbf{I}_n,\\\\\n\\kappa^2\\mathbf{Q} & = \\mathbf{I}_n - \\mathbf{Z} \\boldsymbol{G}^{-1} \\mathbf{Z}^\\top,\\\\\n\\boldsymbol{G} &= \\mathbf{Z}^\\top\\mathbf{Z} + \\kappa^2 \\boldsymbol{\\Omega}^{-1}\n\\end{align*}\\] Section 3.1 of Nychka et al. (2015) details efficient ways of calculating the quadratic form involving \\(\\mathbf{Q}\\) and it’s determinant."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#blocking",
    "href": "slides/bayesmod-slides6.html#blocking",
    "title": "Bayesian modelling",
    "section": "Blocking",
    "text": "Blocking\nIdentify groups of strongly correlated parameters and propose a joint update for these.\n\nThe more parameters we propose at the same time, the lower the chance of acceptance\nOften ways to sample these efficiently"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#tokyo-rainfall",
    "href": "slides/bayesmod-slides6.html#tokyo-rainfall",
    "title": "Bayesian modelling",
    "section": "Tokyo rainfall",
    "text": "Tokyo rainfall\nWe consider data from Kitagawa (1987) that provide a binomial time series giving the number of days in years 1983 and 1984 (a leap year) in which there was more than 1mm of rain in Tokyo; see section 4.3.4 of Rue & Held (2005).\nWe have \\(T=366\\) days and \\(n_t \\in \\{1,2\\}\\) \\((t=1, \\ldots, T)\\) the number of observations in day \\(t\\) and \\(y_t=\\{0,\\ldots, n_t\\}\\) the number of days with rain."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#smoothing-probabilities",
    "href": "slides/bayesmod-slides6.html#smoothing-probabilities",
    "title": "Bayesian modelling",
    "section": "Smoothing probabilities",
    "text": "Smoothing probabilities\nThe objective is to obtain a smoothed probability of rain. The underlying probit model considered takes \\(Y_t \\mid n_t, p_t \\sim \\mathsf{binom}(n_t, p_t)\\) and \\(p_t = \\Phi(\\beta_t).\\)\nWe specify the random effects \\(\\boldsymbol{\\beta} \\sim \\mathsf{Gauss}_{T}(\\boldsymbol{0}, \\tau^{-1}\\mathbf{Q}^{-1}),\\) where \\(\\mathbf{Q}\\) is a \\(T \\times T\\) precision matrix that encodes the local dependence.\nA circular random walk structure of order 2 is used to model the smooth curves by smoothing over neighbors, and enforces small second derivative. This is a suitable prior because it enforces no constraint on the mean structure."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#random-walk-prior",
    "href": "slides/bayesmod-slides6.html#random-walk-prior",
    "title": "Bayesian modelling",
    "section": "Random walk prior",
    "text": "Random walk prior\nThis amounts to specifying the process with for \\(t \\in \\mathbb{N} \\mod 366 + 1\\) \\[\\begin{align*}\n\\Delta^2\\beta_t &= (\\beta_{t+1} - \\beta_t) - (\\beta_t - \\beta_{t-1})\n\\\\&=-\\beta_{t-1} +2 \\beta_t - \\beta_{t+1} \\sim \\mathsf{Gauss}(0, \\tau^{-1}).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#circulant-precision-matrix",
    "href": "slides/bayesmod-slides6.html#circulant-precision-matrix",
    "title": "Bayesian modelling",
    "section": "Circulant precision matrix",
    "text": "Circulant precision matrix\nThis yields an intrinsic Gaussian Markov random field with a circulant precision matrix \\(\\tau\\mathbf{Q}\\) of rank \\(T-1,\\) where \\[\\begin{align*}\n\\mathbf{Q} &=\n\\begin{pmatrix}\n6 & -4 & 1 & 0 & \\cdots & 1 & -4\\\\\n-4 & 6 & -4 & 1 & \\ddots & 0 & 1 \\\\\n1 & -4 & 6 & -4 & \\ddots & 0 & 0 \\\\\n\\vdots & \\ddots & \\ddots  & \\ddots  & \\ddots  & \\ddots & \\vdots \\\\\n-4 & 1 & 0 & 0 & \\cdots & -4 & 6\n\\end{pmatrix}.\n\\end{align*}\\] Because of the linear dependency, the determinant of \\(\\mathbf{Q}\\) is zero."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#prior-draws",
    "href": "slides/bayesmod-slides6.html#prior-draws",
    "title": "Bayesian modelling",
    "section": "Prior draws",
    "text": "Prior draws\n\n\nFigure 6: Five realizations from the cyclical random walk Gaussian prior of order 2."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#gibbs-sampling-for-tokyo-data",
    "href": "slides/bayesmod-slides6.html#gibbs-sampling-for-tokyo-data",
    "title": "Bayesian modelling",
    "section": "Gibbs sampling for Tokyo data",
    "text": "Gibbs sampling for Tokyo data\nWe can perform data augmentation by imputing Gaussian variables, say \\(\\{z_{t,i}\\}\\) from truncated Gaussian, where \\(z_{t,i} = \\beta_t + \\varepsilon_{t,i}\\) and \\(\\varepsilon_{t,i} \\sim \\mathsf{Gauss}(0,1)\\) are independent standard Gaussian and \\[\\begin{align*}\nz_{t,i} \\mid  y_{t,i}, \\beta_t \\sim\n\\begin{cases}\n\\mathsf{trunc. Gauss}(\\beta_t, 1, -\\infty, 0) & y_{t,i} = 0 \\\\\n\\mathsf{trunc. Gauss}(\\beta_t, 1,  0, \\infty) & y_{t,i} =1\n\\end{cases}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#posterior-for-tokyo-data",
    "href": "slides/bayesmod-slides6.html#posterior-for-tokyo-data",
    "title": "Bayesian modelling",
    "section": "Posterior for Tokyo data",
    "text": "Posterior for Tokyo data\nThe posterior is proportional to \\[\\begin{align*}\np(\\boldsymbol{\\beta} \\mid \\tau)p(\\tau)\\prod_{t=1}^{T}\\prod_{i=1}^{n_t}p(y_{t,i} \\mid z_{t,i}) p(z_{t,i} \\mid \\beta_t)\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#data-augmentation-for-tokyo-data",
    "href": "slides/bayesmod-slides6.html#data-augmentation-for-tokyo-data",
    "title": "Bayesian modelling",
    "section": "Data augmentation for Tokyo data",
    "text": "Data augmentation for Tokyo data\nOnce we have imputed the Gaussian latent vectors, we can work directly with the values of \\(z_t = \\sum_{i=1}^{n_t} z_{i,t}\\) \\[\\begin{align*}\np(\\boldsymbol{\\beta}, \\tau) &\\propto \\tau^{(T-1)/2}\\exp \\left( - \\frac{\\tau}{2} \\boldsymbol{\\beta}^\\top \\mathbf{Q} \\boldsymbol{\\beta}\\right)\n\\\\& \\times \\exp\\left\\{ - \\frac{1}{2} (\\boldsymbol{z} - \\boldsymbol{\\beta})^\\top \\mathrm{diag}(\\boldsymbol{n})(\\boldsymbol{z} - \\boldsymbol{\\beta})\\right\\}\n\\\\& \\times \\tau^{a-1}\\exp(-\\tau b)\n\\end{align*}\\] where \\(\\boldsymbol{z} = (z_1, \\ldots, z_T).\\)"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#gibbs-for-tokyo-data---conditionals",
    "href": "slides/bayesmod-slides6.html#gibbs-for-tokyo-data---conditionals",
    "title": "Bayesian modelling",
    "section": "Gibbs for Tokyo data - conditionals",
    "text": "Gibbs for Tokyo data - conditionals\nCompleting the quadratic form shows that \\[\\begin{align*}\n\\boldsymbol{\\beta} \\mid \\boldsymbol{z}, \\tau &\\sim \\mathsf{Gauss}_T\\left(\\mathbf{Q}^{\\star -1} \\boldsymbol{z}, \\mathbf{Q}^{\\star -1}\\right)\\\\\n\\tau \\mid \\boldsymbol{\\beta} & \\sim \\mathsf{gamma}\\left( \\frac{T-1}{2} + a, \\frac{\\boldsymbol{\\beta}^\\top \\mathbf{Q}\\boldsymbol{\\beta}}{2} + b \\right),\\\\\n\\mathbf{Q}^{\\star} &= \\left\\{\\tau \\mathbf{Q} + \\mathrm{diag}(\\boldsymbol{n})\\right\\}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#posterior-prediction-for-probability-of-rainfall",
    "href": "slides/bayesmod-slides6.html#posterior-prediction-for-probability-of-rainfall",
    "title": "Bayesian modelling",
    "section": "Posterior prediction for probability of rainfall",
    "text": "Posterior prediction for probability of rainfall\n\nPosterior prediction for probability of rainfall"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#blocking-vs-joint-update",
    "href": "slides/bayesmod-slides6.html#blocking-vs-joint-update",
    "title": "Bayesian modelling",
    "section": "Blocking vs joint update",
    "text": "Blocking vs joint update\nCompare the following two stategies\n\njoint update: given \\(\\boldsymbol{z}\\) and \\(\\tau\\), simulate \\(\\boldsymbol{\\beta}\\) jointly\none-parameter at a time: starting from \\(i \\sim \\mathsf{unif}(\\{1, \\ldots, 366\\}),\\) get index \\(t= i \\mod 366 + 1\\) and simulate \\(\\beta_i \\mid \\boldsymbol{\\beta}_{-i}, \\boldsymbol{z}, \\tau\\) one at a time."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#blocking-strategy",
    "href": "slides/bayesmod-slides6.html#blocking-strategy",
    "title": "Bayesian modelling",
    "section": "Blocking strategy",
    "text": "Blocking strategy\n\nTrace plots for Tokyo with blocking of random effects"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#individual-update-strategy",
    "href": "slides/bayesmod-slides6.html#individual-update-strategy",
    "title": "Bayesian modelling",
    "section": "Individual update strategy",
    "text": "Individual update strategy\n\nTrace plots for Tokyo with random scan Gibbs for random effects"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#lessons-from-the-tokyo-example",
    "href": "slides/bayesmod-slides6.html#lessons-from-the-tokyo-example",
    "title": "Bayesian modelling",
    "section": "Lessons from the Tokyo example",
    "text": "Lessons from the Tokyo example\nWhat happened?\n\nthere is lower autocorrelation with the joint update (also faster here!) for the \\(\\boldsymbol{\\beta}\\)\nin both cases, \\(\\tau \\mid \\cdot\\) mixes poorly because the values of \\(\\boldsymbol{\\beta}\\) were sampled conditional on the previous value.\n\nA better avenue would be to use a Metropolis random walk for \\(\\tau^{\\star}\\), simulate \\(\\boldsymbol{\\beta} \\mid \\tau^{\\star}\\) and propose the joint vector \\((\\tau^{\\star}, \\boldsymbol{\\beta}^{\\star})\\) simultaneously."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#one-step-further",
    "href": "slides/bayesmod-slides6.html#one-step-further",
    "title": "Bayesian modelling",
    "section": "One step further",
    "text": "One step further\nWe could also remove the data augmentation step and propose from a Gaussian approximation of the log likelihood, using a Taylor series expansion of the log likelihood about \\(\\boldsymbol{\\beta}_{t-1}\\) \\[\\begin{align*}\n\\log p(\\boldsymbol{\\beta} \\mid \\boldsymbol{y}) \\stackrel{\\boldsymbol{\\beta}}{\\propto} - \\frac{\\tau}{2} \\boldsymbol{\\beta}^\\top \\mathbf{Q} \\boldsymbol{\\beta} + \\sum_{t=1}^T \\log f(y_t \\mid \\beta_t)\n\\end{align*}\\] and the \\(y_t\\) are conditionally independent in the likelihood. Refer to Section 4.4.1 of Rue & Held (2005) for more details."
  },
  {
    "objectID": "slides/bayesmod-slides6.html#technical-aside-in-sparsity-we-trust",
    "href": "slides/bayesmod-slides6.html#technical-aside-in-sparsity-we-trust",
    "title": "Bayesian modelling",
    "section": "Technical aside: in sparsity we trust!",
    "text": "Technical aside: in sparsity we trust!\nIt is crucial to exploit the sparsity structure of \\(\\mathbf{Q}\\) for efficient calculations of the likelihood\n\ntypically requires re-ordering elements to get a banded precision matrix\nprecompute the sparse Cholesky\ncompute inverse by solving systems of linear equations; there are dedicated algorithms"
  },
  {
    "objectID": "slides/bayesmod-slides6.html#references",
    "href": "slides/bayesmod-slides6.html#references",
    "title": "Bayesian modelling",
    "section": "References",
    "text": "References\n\n\n\n\nAndrieu, C., & Thoms, J. (2008). A tutorial on adaptive MCMC. Statistics and Computing, 18(4), 343–373. https://doi.org/10.1007/s11222-008-9110-y\n\n\nKitagawa, G. (1987). Non-Gaussian state–space modeling of nonstationary time series. Journal of the American Statistical Association, 82(400), 1032–1041. https://doi.org/10.1080/01621459.1987.10478534\n\n\nLiu, C., Rubin, D. B., & Wu, Y. N. (1998). Parameter expansion to accelerate EM: The PX-EM algorithm. Biometrika, 85(4), 755–770. https://doi.org/10.1093/biomet/85.4.755\n\n\nNychka, D., Bandyopadhyay, S., Hammerling, D., Lindgren, F., & Sain, S. (2015). A multiresolution Gaussian process model for the analysis of large spatial datasets. Journal of Computational and Graphical Statistics, 24(2), 579–599.\n\n\nRosenthal, J. (2011). Optimal proposal distributions and adaptive MCMC. In S. Brooks, A. Gelman, G. Jones, & X. L. Meng (Eds.), Handbook of Markov chain Monte Carlo (pp. 93–112). CRC Press. https://doi.org/10.1201/b10905-5\n\n\nRue, H., & Held, L. (2005). Gaussian Markov random fields: Theory and applications (p. 280). CRC Press.\n\n\nSäilynoja, T., Bürkner, P.-C., & Vehtari, A. (2022). Graphical test for discrete uniformity and its applications in goodness-of-fit evaluation and multiple sample comparison. Statistics and Computing, 32(2), 32. https://doi.org/10.1007/s11222-022-10090-6\n\n\nSpiegelhalter, D. J., Best, N. G., Carlin, B. P., & Van Der Linde, A. (2002). Bayesian measures of model complexity and fit. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 64(4), 583–639. https://doi.org/10.1111/1467-9868.00353\n\n\nTalts, S., Betancourt, M., Simpson, D., Vehtari, A., & Gelman, A. (2020). Validating Bayesian inference algorithms with simulation-based calibration. https://doi.org/10.48550/arXiv.1804.06788"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#bayesian-inference-beyond-conjugate-models",
    "href": "slides/bayesmod-slides4.html#bayesian-inference-beyond-conjugate-models",
    "title": "Bayesian modelling",
    "section": "Bayesian inference beyond conjugate models",
    "text": "Bayesian inference beyond conjugate models\nHow to circumvent the problem of intractable posteriors?\n\nsimulation-based methods: accept-reject, Markov chain Monte Carlo, particle filters, etc.\ndeterministic methods: (integrated nested) Laplace approximations, variational Bayes, expectation propagation, etc.\n\nWe focus on Monte Carlo methods."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#simulation-algorithms-inversion-method",
    "href": "slides/bayesmod-slides4.html#simulation-algorithms-inversion-method",
    "title": "Bayesian modelling",
    "section": "Simulation algorithms: inversion method",
    "text": "Simulation algorithms: inversion method\nIf \\(F\\) is an absolutely continuous distribution function, then \\[F(X) \\sim \\mathsf{unif}(0,1).\\] The inversion method consists in applying the quantile function \\(F^{-1}\\) to \\(U \\sim \\mathsf{unif}(0,1)\\), viz. \\[F^{-1}(U) \\sim X.\\]"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#inversion-method-for-truncated-distributions",
    "href": "slides/bayesmod-slides4.html#inversion-method-for-truncated-distributions",
    "title": "Bayesian modelling",
    "section": "Inversion method for truncated distributions",
    "text": "Inversion method for truncated distributions\nConsider a random variable \\(Y\\) with distribution function \\(F\\).\nIf \\(X\\) follows the same distribution as \\(Y\\), but restricted over the interval \\([a,b]\\), then \\[\\Pr(X \\leq x) = \\frac{F(x) - F(a)}{F(b)-F(a)}, \\qquad a \\leq x \\leq b,\\]\nTherefore, \\[F^{-1}[F(a) + \\{F(b)-F(a)\\}U] \\sim X.\\]"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#fundamental-theorem-of-simulation",
    "href": "slides/bayesmod-slides4.html#fundamental-theorem-of-simulation",
    "title": "Bayesian modelling",
    "section": "Fundamental theorem of simulation",
    "text": "Fundamental theorem of simulation\nConsider a \\(d\\)-variate random vector \\(\\boldsymbol{X},\\) independent of \\(U \\sim \\mathsf{unif}(0,1)\\) and \\(c&gt;0\\). If \\((\\boldsymbol{X}, U)\\) is uniformly distributed on the set \\[\\begin{align*}\n\\mathcal{A}_{f}=\\{(\\boldsymbol{x}, u): 0 \\leq u \\leq  c f(\\boldsymbol{x})\\},\n\\end{align*}\\] then \\(\\boldsymbol{X}\\) has density \\(f(\\boldsymbol{x}).\\) \n\n\\(f\\) is the marginal density of \\(\\boldsymbol{X}\\) since \\(f(\\boldsymbol{x}) = \\int_0^{f(\\boldsymbol{x})} \\mathrm{d} u.\\)\nIf we can simulate uniformly from \\(\\mathcal{A}_{f},\\) then, we can discard the auxiliary variable \\(u.\\) See Devroye (1986), Theorem 3.1."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#fundamental-theorem-of-simulation-in-picture",
    "href": "slides/bayesmod-slides4.html#fundamental-theorem-of-simulation-in-picture",
    "title": "Bayesian modelling",
    "section": "Fundamental theorem of simulation in picture",
    "text": "Fundamental theorem of simulation in picture\n\n\nFigure 1: Illustration of the fundamental theorem of simulation. All points in blue below the density curve belong to \\(\\mathcal{A}_f.\\)"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#simulation-algorithms-accept-reject",
    "href": "slides/bayesmod-slides4.html#simulation-algorithms-accept-reject",
    "title": "Bayesian modelling",
    "section": "Simulation algorithms: accept-reject",
    "text": "Simulation algorithms: accept-reject\n\nTarget: sample from density \\(p(x)\\) (hard to sample from)\nProposal: find a density \\(q(x)\\) with nested support, \\(\\mathrm{supp}(p) \\subseteq \\mathrm{supp}(q)\\), such that for all \\(x \\in \\mathrm{supp}(p)\\), \\[\\frac{p(x)}{q(x)} \\leq C, \\quad C \\geq 1.\\] Uses the fundamental theorem of simulation by finding an enveloppe \\(Cq(x)\\) that is over the density \\(p(x).\\)"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#rejection-sampling-algorithm",
    "href": "slides/bayesmod-slides4.html#rejection-sampling-algorithm",
    "title": "Bayesian modelling",
    "section": "Rejection sampling algorithm",
    "text": "Rejection sampling algorithm\n\nGenerate \\(X\\) from proposal with density \\(q(x)\\).\nCompute the ratio \\(R \\gets p(X)/ q(X)\\).\nIf \\(CU \\leq R\\) for \\(U \\sim \\mathsf{unif}(0,1)\\), return \\(X\\), else go back to step 1."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#accept-reject-illustration",
    "href": "slides/bayesmod-slides4.html#accept-reject-illustration",
    "title": "Bayesian modelling",
    "section": "Accept-reject illustration",
    "text": "Accept-reject illustration\n\n\nFigure 2: Target density (full) and scaled proposal density (dashed): the vertical segment at \\(x=1\\) shows the percentage of acceptance for a uniform slice under the scaled proposal, giving an acceptance ratio of 0.58."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#remarks-on-rejection-sampling",
    "href": "slides/bayesmod-slides4.html#remarks-on-rejection-sampling",
    "title": "Bayesian modelling",
    "section": "Remarks on rejection sampling",
    "text": "Remarks on rejection sampling\n\nAcceptance rate is \\(1/C\\):\n\nwe need on average \\(C\\) draws from \\(q\\) to get one from \\(p\\).\n\n\\(q\\) must be more heavy-tailed than \\(p\\)\n\ne.g., \\(q(x)\\) Student-\\(t\\) for \\(p(x)\\) Gaussian.\n\n\\(q\\) should be cheap and easy to sample from!"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#designing-a-good-proposal-density",
    "href": "slides/bayesmod-slides4.html#designing-a-good-proposal-density",
    "title": "Bayesian modelling",
    "section": "Designing a good proposal density",
    "text": "Designing a good proposal density\nGood choices must satisfy the following constraints:\n\npick a family \\(q(x)\\) so that \\[C = \\mathrm{argmax}_x \\frac{p(x)}{q(x)}\\] is as close to 1 as possible.\nyou can use numerical optimization with target \\[f(x) =\\log p(x) - \\log q(x)\\] to find the mode \\(x^\\star\\) and the upper bound \\(C = \\exp f(x^\\star).\\)"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#truncated-gaussian-via-accept-reject",
    "href": "slides/bayesmod-slides4.html#truncated-gaussian-via-accept-reject",
    "title": "Bayesian modelling",
    "section": "Truncated Gaussian via accept-reject",
    "text": "Truncated Gaussian via accept-reject\nConsider sampling \\(Y \\sim \\mathsf{Gauss}(\\mu, \\sigma^2)\\), but truncated in the interval \\((a, b)\\). The target density is \\[\\begin{align*}\np(x; \\mu, \\sigma, a, b) = \\frac{1}{\\sigma}\\frac{\\phi\\left(\\frac{x-\\mu}{\\sigma}\\right)}{\\Phi(\\beta)-\\Phi(\\alpha)}.\n\\end{align*}\\] for \\(\\alpha= (a-\\mu)/\\sigma\\) and \\(\\beta = (b-\\mu)/\\sigma\\). where \\(\\phi(\\cdot), \\Phi(\\cdot)\\) are respectively the density and distribution function of the standard Gaussian distribution."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#accept-reject-crude-version",
    "href": "slides/bayesmod-slides4.html#accept-reject-crude-version",
    "title": "Bayesian modelling",
    "section": "Accept-reject (crude version)",
    "text": "Accept-reject (crude version)\n\nSimulate \\(X \\sim \\mathsf{Gauss}(\\mu, \\sigma^2)\\)\nreject any draw if \\(X &lt; a\\) or \\(X&gt; b\\).\n\nThe acceptance rate is \\(C^{-1} = \\{\\Phi(\\beta) - \\Phi(\\alpha)\\}\\)\n\n# Standard Gaussian truncated on [0,1]\ncandidate &lt;- rnorm(1e5)\ntrunc_samp &lt;- candidate[candidate &gt;= 0 & candidate &lt;= 1]\n# Acceptance rate\nlength(trunc_samp)/1e5\n\n[1] 0.34289\n\n# Theoretical acceptance rate\npnorm(1)-pnorm(0)\n\n[1] 0.3413447"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#accept-reject-for-truncated-gaussian",
    "href": "slides/bayesmod-slides4.html#accept-reject-for-truncated-gaussian",
    "title": "Bayesian modelling",
    "section": "Accept-reject for truncated Gaussian",
    "text": "Accept-reject for truncated Gaussian\nSince the Gaussian is a location scale family, the inversion method gives \\[\\begin{align*}\nX \\sim \\mu + \\sigma\\Phi^{-1}\\left[\\Phi(\\alpha) + \\{\\Phi(\\beta)-\\Phi(\\alpha)\\}U\\right]\n\\end{align*}\\]\nWe however need to evaluate \\(\\Phi\\) numerically (no closed-form expression).\nThe method fails for rare event simulation because the computer returns\n\n\\(\\Phi(x) = 0\\) for \\(x \\leq -39\\)\n\\(\\Phi(x)=1\\) for \\(x \\geq 8.3\\),\n\nimplying that \\(a \\leq 8.3\\) for this approach to work (Botev & L’Écuyer, 2017)."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#simulating-tails-of-gaussian-variables",
    "href": "slides/bayesmod-slides4.html#simulating-tails-of-gaussian-variables",
    "title": "Bayesian modelling",
    "section": "Simulating tails of Gaussian variables",
    "text": "Simulating tails of Gaussian variables\nWe consider simulation from a standard Gaussian truncated above \\(a&gt;0\\)\nWrite the density of the truncated Gaussian as (Devroye, 1986, p. 381)\\[f(x) = \\frac{\\exp(-x^2/2)}{\\int_{a}^{\\infty}\\exp(-z^2/2)\\mathrm{d} z}  =\\frac{\\exp(-x^2/2)}{c_1}.\\]\nNote that, for \\(x \\geq a\\), \\[c_1f(x) \\leq \\frac{x}{a}\\exp\\left(-\\frac{x^2}{2}\\right)= a^{-1}\\exp\\left(-\\frac{a^2}{2}\\right)g(x);\\] where \\(g(x)\\) is the density of a Rayleigh variable shifted by \\(a\\).\n\nThe constant \\(C= \\exp(-a^2/2)(c_1a)^{-1}\\) approaches 1 quickly as \\(a \\to \\infty\\) (asymptotically optimality)."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#accept-reject-truncated-gaussian-with-rayleigh",
    "href": "slides/bayesmod-slides4.html#accept-reject-truncated-gaussian-with-rayleigh",
    "title": "Bayesian modelling",
    "section": "Accept-reject: truncated Gaussian with Rayleigh",
    "text": "Accept-reject: truncated Gaussian with Rayleigh\nThe shifted Rayleigh has distribution function \\[G(x) = 1-\\exp\\{(a^2-x^2)/2\\}, x \\geq a.\\]\n\n\n\n\n\n\nMarsaglia algorithm\n\n\n\nGenerate a shifted Rayleigh above \\(a\\), \\(X \\gets  \\{a^2 - 2\\log(U)\\}^{1/2}\\) for \\(U \\sim \\mathsf{unif}(0,1)\\)\nAccept \\(X\\) if \\(XV \\leq a\\), where \\(V \\sim \\mathsf{unif}(0,1)\\).\n\n\n\n\nFor sampling on \\([a,b]\\) with \\(a\\) very large, propose from a Rayleigh truncated above at \\(b\\) (Botev & L’Écuyer, 2017).\n\na &lt;- 8.3\nniter &lt;- 1000L\nX &lt;- sqrt(a^2 + 2*rexp(niter))\nsamp &lt;- X[runif(niter)*X &lt;= a]"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#markov-chains",
    "href": "slides/bayesmod-slides4.html#markov-chains",
    "title": "Bayesian modelling",
    "section": "Markov chains",
    "text": "Markov chains\nPlain ordinary Monte Carlo is great, but few algorithms are generic enough to be useful in complex high-dimensional problems.\nWe will instead typically build Markov chains that target an invariant stationary distribution."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#caveats",
    "href": "slides/bayesmod-slides4.html#caveats",
    "title": "Bayesian modelling",
    "section": "Caveats?",
    "text": "Caveats?\nMarkov chain Monte Carlo methods generate correlated draws.\nQuestions:\n\ncan we use them as ordinary independent samples?\nwhat is the price to pay?\n\nWe need to do a little theoretical detour to answer these questions."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#stationarity-and-markov-property",
    "href": "slides/bayesmod-slides4.html#stationarity-and-markov-property",
    "title": "Bayesian modelling",
    "section": "Stationarity and Markov property",
    "text": "Stationarity and Markov property\nA stochastic process is\n\n(strongly) stationary if the distribution of \\(\\{X_1, \\ldots, X_t\\}\\) is the same as that of \\(\\{X_{n+1}, \\ldots X_{t+n}\\}\\) for any value of \\(n\\) and given \\(t\\).\nweakly stationary if \\(\\mathsf{E}(X_t) = \\mu\\) for all \\(t\\), and \\(\\mathsf{Cov}(X_t, X_{t+h}) = \\gamma_h\\) does not depend on \\(t\\).\nMarkov if it satisfies the Markov property: given the current state of the chain, the future only depends on the current state and not on the past.\n\n\nStrong stationarity implies weak stationarity."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#autoregressive-process-of-order-1",
    "href": "slides/bayesmod-slides4.html#autoregressive-process-of-order-1",
    "title": "Bayesian modelling",
    "section": "Autoregressive process of order 1",
    "text": "Autoregressive process of order 1\nConsider a first-order autoregressive process, or \\(\\mathsf{AR}(1)\\),\n\\[Y_t = \\mu + \\phi(Y_{t-1} - \\mu) + \\varepsilon_t,\\] where\n\n\\(\\phi\\) is the lag-one correlation,\n\\(\\mu\\) the global mean\n\\(\\varepsilon_t\\) is an iid innovation with mean zero and variance \\(\\sigma^2\\)\n\nIf \\(|\\phi| &lt; 1\\), the process is stationary, otherwise the variance increases with \\(t\\)."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#unconditional-moments-via-tower-law",
    "href": "slides/bayesmod-slides4.html#unconditional-moments-via-tower-law",
    "title": "Bayesian modelling",
    "section": "Unconditional moments via tower law",
    "text": "Unconditional moments via tower law\nIf the process is weakly stationary, then \\(\\mathsf{E}_{Y_{t}}(Y_t)=\\mathsf{E}_{Y_{t-1}}(Y_{t-1})\\) \\[\\begin{align*}\n\\mathsf{E}_{Y_{t}}(Y_t) &= \\mathsf{E}_{Y_{t-1}}\\left\\{\\mathsf{E}_{Y_{t} \\mid Y_{t-1}}(Y_t)\\right\\}\n\\\\&= \\mu(1-\\phi) + \\phi\\mathsf{E}_{Y_{t-1}}(Y_{t-1})\n\\end{align*}\\] and so the unconditional mean is \\(\\mu\\). For the variance, we have \\[\\begin{align*}\n\\mathsf{Va}_{Y_{t}}(Y_t) &= \\mathsf{E}_{Y_{t-1}}\\left\\{\\mathsf{Va}_{Y_{t} \\mid Y_{t-1}}(Y_t)\\right\\} + \\mathsf{Va}_{Y_{t-1}}\\left\\{\\mathsf{E}_{Y_{t} \\mid Y_{t-1}}(Y_t)\\right\\}\\\\\n& = \\sigma^2 + \\mathsf{Va}_{Y_{t-1}}\\left\\{\\mu + \\phi(Y_{t-1} - \\mu)\\right\\}\n\\\\&= \\sigma^2 + \\phi^2 \\mathsf{Va}_{Y_{t-1}}(Y_{t-1}).\n\\end{align*}\\] and the unconditional variance is \\(\\mathsf{Va}_{Y_t}(Y_t) = \\sigma^2/(1-\\phi^2).\\)"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#autocovariance-and-markov-property",
    "href": "slides/bayesmod-slides4.html#autocovariance-and-markov-property",
    "title": "Bayesian modelling",
    "section": "Autocovariance and Markov property",
    "text": "Autocovariance and Markov property\nThe covariance at lag \\(k\\), in terms of innovations, gives \\[\\begin{align*}\n\\gamma_k = \\mathsf{Co}(Y_t, Y_{t-k}) = \\mathsf{Va}(\\phi Y_{t-1}, Y_{t-k}) + \\mathsf{Va}(\\varepsilon_t, Y_{t-k}) = \\phi \\gamma_{k-1}\n\\end{align*}\\] since \\(\\varepsilon_t\\) is independent of the past. We thus find \\[\\gamma_k = \\phi^k\\mathsf{Va}(Y_t).\\]\nThe \\(\\mathsf{AR}(1)\\) process is first-order Markov since the conditional distribution \\(p(Y_t \\mid Y_{t-1}, \\ldots, Y_{t-p})\\) equals \\(p(Y_t \\mid Y_{t-1}).\\)"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#variance-of-sample-average",
    "href": "slides/bayesmod-slides4.html#variance-of-sample-average",
    "title": "Bayesian modelling",
    "section": "Variance of sample average",
    "text": "Variance of sample average\nIntuitively, a sample of correlated observations carries less information than an independent sample of draws.\nThe variance of the sample average is \\[\\begin{align*}\n\\mathsf{Va}\\left(\\overline{Y}_T\\right) &= \\frac{1}{T^2}\\sum_{t=1}^T \\sum_{s=1}^T \\mathsf{Co}(Y_t, Y_s)\n\\\\&= \\frac{1}{T^2}\\sum_{t=1}^T \\mathsf{Va}(Y_t) + \\frac{2}{T^2} \\sum_{t=1}^{T-1}\\sum_{s = t+1}^T \\mathsf{Co}(Y_t, Y_s).\n\\end{align*}\\] Under independence and assuming stationarity, we get \\(\\mathsf{Va}\\left(\\overline{Y}_T\\right)=\\sigma^2/T.\\)"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#variance-of-sample-average-redux",
    "href": "slides/bayesmod-slides4.html#variance-of-sample-average-redux",
    "title": "Bayesian modelling",
    "section": "Variance of sample average, redux",
    "text": "Variance of sample average, redux\nIf the second moments are finite, the scaled limiting variance of the sample mean simplifies to \\[\\begin{align*}\n\\lim_{T \\to \\infty} T\\mathsf{Va}\\left(\\overline{Y}_T\\right) = \\tau^2 \\left\\{1+2\\sum_{t=1}^\\infty \\rho_t\\right\\}.\n\\end{align*}\\] which is a function of\n\nthe unconditional variance \\(\\tau^2\\)\nthe lag-\\(k\\) autocorrelation, \\(\\mathsf{Cor}(Y_{t}, Y_{t+k})=\\rho_k.\\)"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#effective-sample-size",
    "href": "slides/bayesmod-slides4.html#effective-sample-size",
    "title": "Bayesian modelling",
    "section": "Effective sample size",
    "text": "Effective sample size\nThe effective sample size is, loosely speaking, the equivalent number of observations if the \\(B\\) marginal posterior draws where independent and more formally \\[\n\\mathsf{ESS} = \\frac{B}{\\left\\{1+2\\sum_{t=1}^\\infty \\rho_t\\right\\}}\n\\] where \\(\\rho_t\\) is the lag \\(t\\) correlation."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#effective-sample-size-for-ar1",
    "href": "slides/bayesmod-slides4.html#effective-sample-size-for-ar1",
    "title": "Bayesian modelling",
    "section": "Effective sample size for AR(1)",
    "text": "Effective sample size for AR(1)\nThe lag-\\(k\\) correlation of the stationary autoregressive process of order 1 is \\(\\phi^k\\), so \\[1+2\\sum_{t=1}^\\infty \\rho_t = 1 + 2 \\left(\\frac{1}{1-\\phi}-1\\right) = \\frac{1+\\phi}{1-\\phi}.\\]"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#inefficiency-curve-for-ar1",
    "href": "slides/bayesmod-slides4.html#inefficiency-curve-for-ar1",
    "title": "Bayesian modelling",
    "section": "Inefficiency curve for AR(1)",
    "text": "Inefficiency curve for AR(1)\n\n\nFigure 3: Left: scaled asymptotic variance of the sample mean for AR(1) (full line) and independent observations with unit marginal variance (dashed). Right: variance ratio for positive correlations for selected range.\nTo get the same precision for the mean of \\(\\mathsf{AR}(1)\\) process with \\(\\phi \\approx 0.75\\) than with i.i.d. data, we would need 7 times as many observations."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#morale-of-the-story",
    "href": "slides/bayesmod-slides4.html#morale-of-the-story",
    "title": "Bayesian modelling",
    "section": "Morale of the story",
    "text": "Morale of the story\nThe price to pay for having correlated samples is\n\ninefficiency\n\nThe higher the autocorrelation, the larger the variability of our estimators."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#correlogram",
    "href": "slides/bayesmod-slides4.html#correlogram",
    "title": "Bayesian modelling",
    "section": "Correlogram",
    "text": "Correlogram\nWe can look at the autocorrelation function to check the efficiency.\n\n\nFigure 4: Correlogram of two Markov chains. These plots, often called acf or autocorrelation functions, show the lag-k sample autocorrelation against lag number."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#convergence-of-markov-chains",
    "href": "slides/bayesmod-slides4.html#convergence-of-markov-chains",
    "title": "Bayesian modelling",
    "section": "Convergence of Markov chains",
    "text": "Convergence of Markov chains\nIf a Markov chain is irreducible and acyclic, it has a unique stationary distribution.\n\nirreducibility: means that the chain can move from anywhere to anywhere, so it doesn’t get stuck in part of the space forever.\nacyclic: cyclical chains loop around and visit periodically a state"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#examples-of-cyclical-or-reducible-chains",
    "href": "slides/bayesmod-slides4.html#examples-of-cyclical-or-reducible-chains",
    "title": "Bayesian modelling",
    "section": "Examples of cyclical or reducible chains",
    "text": "Examples of cyclical or reducible chains\nConsider discrete Markov chains over the integers \\(1, 2, 3\\) with transition matrices\n\\[\nP_1 = \\begin{pmatrix}\n0.5 & 0.3 & 0.2 \\\\\n0 & 0.4 & 0.6 \\\\\n0 & 0.5 & 0.5\n\\end{pmatrix},\n\\quad\nP_2 = \\begin{pmatrix}\n0 & 0 & 1 \\\\\n1 & 0 & 0 \\\\\n0 & 1 & 0\n\\end{pmatrix}.\n\\] Chain 1 is reducible to \\(\\{2, 3\\}\\), chain 2 is cyclical."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#law-of-large-number-ergodic-theorem",
    "href": "slides/bayesmod-slides4.html#law-of-large-number-ergodic-theorem",
    "title": "Bayesian modelling",
    "section": "Law of large number (ergodic theorem)",
    "text": "Law of large number (ergodic theorem)\nErgodicity means that two segments of a time series far enough apart act as independent.\nLet \\(\\{Y_t\\}\\) is a weakly stationary sequence with mean \\(\\mathsf{E}(Y_t)=\\mu\\) and \\(\\gamma_h = \\mathsf{Cov}(Y_t, Y_{t+h})\\). Then, if the autocovariance series is convergent, meaning \\[\\sum_{t=0}^\\infty |\\gamma_h| &lt; \\infty,\\] then \\(\\{Y_t\\}\\) is ergodic for the mean and \\(\\overline{Y} \\stackrel{\\mathrm{p}}{\\to} \\mu\\)."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#ergodicity-and-transformations",
    "href": "slides/bayesmod-slides4.html#ergodicity-and-transformations",
    "title": "Bayesian modelling",
    "section": "Ergodicity and transformations",
    "text": "Ergodicity and transformations\nThe ergodic theorem is a law of large numbers for stochastic processes that allows for serial dependence between observations, provided the latter is not too large.\nAny transformation \\(g(\\cdot)\\) of a stationary and ergodic process \\(\\{Y_t\\}\\) retains the properties, so \\(\\overline{g} = T^{-1} \\sum_{t=1}^T g(Y_t) \\to \\mathsf{E}\\{g(Y_t)\\}\\) as \\(T \\to \\infty.\\)\nThe ergodic theorem holds even if the chain is cyclical."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#convergence-and-stationary-distribution",
    "href": "slides/bayesmod-slides4.html#convergence-and-stationary-distribution",
    "title": "Bayesian modelling",
    "section": "Convergence and stationary distribution",
    "text": "Convergence and stationary distribution\nConsider a transition \\(P\\) on \\(1, \\ldots, 5\\) defined as \\[\nP = \\begin{pmatrix}\n\\frac{2}{3} & \\frac{1}{3} &  0 & 0 & 0 \\\\\n\\frac{1}{6} & \\frac{2}{3} & \\frac{1}{6} & 0 & 0 \\\\\n0 & \\frac{1}{6} & \\frac{2}{3} & \\frac{1}{6} & 0 \\\\\n0 & 0 & \\frac{1}{6} & \\frac{2}{3} & \\frac{1}{6} \\\\\n0 & 0 & 0 &  \\frac{1}{3}  & \\frac{2}{3} \\\\\n\\end{pmatrix}\n\\] The stationary distribution is the value of the row vector \\(\\boldsymbol{p},\\) such that \\(\\boldsymbol{p} = \\boldsymbol{p}\\mathbf{P}\\) for transition matrix \\(\\mathbf{P}\\): we get \\(\\boldsymbol{p}=(1,2,2,2,1)/8.\\)"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#convergence-of-markov-chains-1",
    "href": "slides/bayesmod-slides4.html#convergence-of-markov-chains-1",
    "title": "Bayesian modelling",
    "section": "Convergence of Markov chains",
    "text": "Convergence of Markov chains\n\n\nFigure 5: Discrete Markov chain on integers from 1 to 5, with traceplot of 1000 first iterations (left) and running mean plots of sample proportion of each state visited (right)."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#markov-chain-monte-carlo",
    "href": "slides/bayesmod-slides4.html#markov-chain-monte-carlo",
    "title": "Bayesian modelling",
    "section": "Markov chain Monte Carlo",
    "text": "Markov chain Monte Carlo\nWe consider simulating from a distribution with associated density function proportional to \\(p(\\cdot)\\)\n\nusing an algorithm that generates a Markov chain ,\nwithout requiring knowledge of the normalizing factor.\n\nWe use a conditional density \\(q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}^{\\text{cur}})\\) to generate proposals from the current value \\(\\boldsymbol{\\theta}^{\\text{cur}}.\\)"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#metropolishastings-algorithm",
    "href": "slides/bayesmod-slides4.html#metropolishastings-algorithm",
    "title": "Bayesian modelling",
    "section": "Metropolis–Hastings algorithm",
    "text": "Metropolis–Hastings algorithm\nStarting from an initial value \\(\\boldsymbol{\\theta}_0\\): for \\(t=1, \\ldots, T\\)\n\ndraw a proposal value \\(\\boldsymbol{\\theta}_t^{\\star} \\sim q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}_{t-1})\\).\nCompute the acceptance ratio \\[\nR = \\frac{p(\\boldsymbol{\\theta}_t^{\\star})}{p(\\boldsymbol{\\theta}_{t-1})}\\frac{q(\\boldsymbol{\\theta}_{t-1} \\mid \\boldsymbol{\\theta}_t^{\\star} )}{q(\\boldsymbol{\\theta}_t^{\\star} \\mid \\boldsymbol{\\theta}_{t-1})}\n\\]\nWith probability \\(\\alpha=\\min\\{R, 1\\}\\), accept the proposal and set \\(\\boldsymbol{\\theta}_t \\gets \\boldsymbol{\\theta}_t^{\\star}\\), otherwise set the value to the previous state, \\(\\boldsymbol{\\theta}_t \\gets \\boldsymbol{\\theta}_{t-1}\\)."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#theory",
    "href": "slides/bayesmod-slides4.html#theory",
    "title": "Bayesian modelling",
    "section": "Theory",
    "text": "Theory\nThe Metropolis–Hastings algorithm satisfies a technical condition (detailed balance) that ensures that the Markov chain generated is reversible.\n\nThus, any draw from the posterior will generate a new realization from the posterior.\nProvided the starting value has non-zero probability under the posterior, the chain will converge to the stationarity distribution (albeit perhaps slowly)."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#interpretation",
    "href": "slides/bayesmod-slides4.html#interpretation",
    "title": "Bayesian modelling",
    "section": "Interpretation",
    "text": "Interpretation\n\nIf \\(R&gt;1\\), the proposal has higher density and we always accept the move.\nIf we reject the move, the Markov chain stays at the current value, which induces autocorrelation.\nSince the acceptance probability depends only on the density through ratios, normalizing factors of \\(p\\) and \\(q\\) cancel out."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#symmetric-proposals-and-random-walk",
    "href": "slides/bayesmod-slides4.html#symmetric-proposals-and-random-walk",
    "title": "Bayesian modelling",
    "section": "Symmetric proposals and random walk",
    "text": "Symmetric proposals and random walk\nIf the proposal is symmetric, the ratio of proposal densities is \\[q(\\boldsymbol{\\theta}_{t-1} \\mid \\boldsymbol{\\theta}_t^{\\star} ) / q(\\boldsymbol{\\theta}_t^{\\star} \\mid \\boldsymbol{\\theta}_{t-1}) = 1.\\]\nCommon examples include random walk proposals \\[\\boldsymbol{\\theta}_t^{\\star} \\gets \\boldsymbol{\\theta}_{t-1} + \\tau Z,\\] where \\(Z \\sim \\mathsf{Gauss}(0,1).\\)"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#independent-proposals",
    "href": "slides/bayesmod-slides4.html#independent-proposals",
    "title": "Bayesian modelling",
    "section": "Independent proposals",
    "text": "Independent proposals\n\nIf we pick instead a global proposal, we must ensure that \\(q\\) samples in far regions (recall rejection sampling), otherwise …\nGood proposals include heavy tailed distribution such as Student-\\(t\\) with small degrees of freedom,\ncentered at the maximum a posteriori \\(\\widehat{\\boldsymbol{\\theta}}\\) and\nwith scale matrix proportional to \\(-\\mathbf{H}^{-1}(\\boldsymbol{\\theta}_t^{\\star})\\), where \\(\\mathbf{H}(\\cdot)\\) is the Hessian of the (unnormalized) log posterior."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#upworthy-data-example",
    "href": "slides/bayesmod-slides4.html#upworthy-data-example",
    "title": "Bayesian modelling",
    "section": "Upworthy data example",
    "text": "Upworthy data example\nWe model the Poisson rates for headlines with questions or not. Our model is \\[\\begin{align*}\nY_{i} &\\sim \\mathsf{Poisson}(n_i\\lambda_i), \\qquad (i=1,2)\\\\\n\\lambda_1 &= \\exp(\\beta + \\kappa) \\\\\n\\lambda_2 &= \\exp(\\beta) \\\\\n\\beta & \\sim \\mathsf{Gauss}(\\log 0.01, 1.5) \\\\\n\\kappa &\\sim \\mathsf{Gauss}(0, 1)\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#implementation-details-data-and-containers",
    "href": "slides/bayesmod-slides4.html#implementation-details-data-and-containers",
    "title": "Bayesian modelling",
    "section": "Implementation details: data and containers",
    "text": "Implementation details: data and containers\nIn regression models, scale inputs if possible.\n\ndata(upworthy_question, package = \"hecbayes\")\n# Compute sufficient statistics\ndata &lt;- upworthy_question |&gt;\n  dplyr::group_by(question) |&gt;\n  dplyr::summarize(ntot = sum(impressions),\n                   y = sum(clicks))\n# Create containers for MCMC\nniter &lt;- 1e4L\nchain &lt;- matrix(0, nrow = niter, ncol = 2L)\ncolnames(chain) &lt;- c(\"beta\",\"kappa\")"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#implementation-details-log-posterior-function",
    "href": "slides/bayesmod-slides4.html#implementation-details-log-posterior-function",
    "title": "Bayesian modelling",
    "section": "Implementation details: log posterior function",
    "text": "Implementation details: log posterior function\nPerform all calculations on the log scale to avoid numerical overflow!\n\n# Code log posterior as sum of log likelihood and log prior\nloglik &lt;- function(par, counts = data$y, offset = data$ntot, ...){\n  lambda &lt;- exp(c(par[1] + log(offset[1]), par[1] + par[2] + log(offset[2])))\n sum(dpois(x = counts, lambda = lambda, log = TRUE))\n}\n# Note common signature of function\nlogprior &lt;- function(par, ...){\n  dnorm(x = par[1], mean = log(0.01), sd = 1.5, log = TRUE) +\n    dnorm(x = par[2], log = TRUE)\n}\nlogpost &lt;- function(par, ...){\n  loglik(par, ...) + logprior(par, ...)\n}"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#implementation-details-proposals",
    "href": "slides/bayesmod-slides4.html#implementation-details-proposals",
    "title": "Bayesian modelling",
    "section": "Implementation details: proposals",
    "text": "Implementation details: proposals\nUse good starting values for your Markov chains, such as maximum a posteriori.\n\n# Compute maximum a posteriori (MAP)\nmap &lt;- optim(\n  par = c(-4, 0.07),\n  fn = logpost,\n  control = list(fnscale = -1),\n  offset = data$ntot,\n  counts = data$y,\n  hessian = TRUE)\n# Use MAP as starting value\ncur &lt;- map$par\n# Compute logpost_cur - we can keep track of this to reduce calculations\nlogpost_cur &lt;- logpost(cur)\n# Proposal covariance\ncov_map &lt;- -2*solve(map$hessian)\nchol &lt;- chol(cov_map)"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#implementation-details-metropolishastings-algorithm",
    "href": "slides/bayesmod-slides4.html#implementation-details-metropolishastings-algorithm",
    "title": "Bayesian modelling",
    "section": "Implementation details: Metropolis–Hastings algorithm",
    "text": "Implementation details: Metropolis–Hastings algorithm\nUse seed for reproducibility, do not compute posterior twice, compute log of acceptance ratio.\n\nset.seed(80601)\nnaccept &lt;- 0L\nfor(i in seq_len(niter)){\n  # Multivariate normal proposal - symmetric random walk\n  prop &lt;- c(rnorm(n = 2) %*% chol + cur)\n  logpost_prop &lt;- logpost(prop)\n  logR &lt;- logpost_prop - logpost_cur\n  if(logR &gt; -rexp(1)){\n    cur &lt;- prop\n    logpost_cur &lt;- logpost_prop\n    naccept &lt;- naccept + 1L\n  }\n  chain[i,] &lt;- cur\n}"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#implementation-details-analysis-of-output",
    "href": "slides/bayesmod-slides4.html#implementation-details-analysis-of-output",
    "title": "Bayesian modelling",
    "section": "Implementation details: analysis of output",
    "text": "Implementation details: analysis of output\n\n# Posterior summaries\nsummary(coda::as.mcmc(chain))\n# Computing standard errors using batch means\nsqrt(diag(mcmc::olbm(chain, batch.length = niter/40)))\n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean       SD  Naive SE Time-series SE\nbeta  -4.51268 0.001697 1.697e-05      6.176e-05\nkappa  0.07075 0.002033 2.033e-05      9.741e-05\n\n2. Quantiles for each variable:\n\n          2.5%      25%      50%      75%    97.5%\nbeta  -4.51591 -4.51385 -4.51273 -4.51154 -4.50929\nkappa  0.06673  0.06933  0.07077  0.07212  0.07463"
  },
  {
    "objectID": "slides/bayesmod-slides4.html#standard-errors-for-posterior-means-batch-means",
    "href": "slides/bayesmod-slides4.html#standard-errors-for-posterior-means-batch-means",
    "title": "Bayesian modelling",
    "section": "Standard errors for posterior means – batch means",
    "text": "Standard errors for posterior means – batch means\nGeyer (2011) recommends to segment the time series into batches\n\nBreak the chain of length \\(B\\) (after burn in) in \\(K\\) blocks of size \\(\\approx K/B.\\)\nCompute the sample mean of each segment.\nCompute the standard deviation of the segments mean.\nRescale by \\(K^{-1/2}\\) to get standard error of the global mean."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#illustration-of-batch-means",
    "href": "slides/bayesmod-slides4.html#illustration-of-batch-means",
    "title": "Bayesian modelling",
    "section": "Illustration of batch means",
    "text": "Illustration of batch means\n\n\nFigure 6: Calculation of the standard error of the posterior mean using the batch method."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#standard-errors-for-posterior-means-autoregressive",
    "href": "slides/bayesmod-slides4.html#standard-errors-for-posterior-means-autoregressive",
    "title": "Bayesian modelling",
    "section": "Standard errors for posterior means – autoregressive",
    "text": "Standard errors for posterior means – autoregressive\nWe can also fit an high-order autoregressive process \\(\\mathsf{AR}(p)\\) and approximate the unconditional variance by that, and divide by \\(\\sqrt{T}\\).\n\nStandard methods (Yule–Walker equations, maximum likelihood, spectral estimation) apply."
  },
  {
    "objectID": "slides/bayesmod-slides4.html#references",
    "href": "slides/bayesmod-slides4.html#references",
    "title": "Bayesian modelling",
    "section": "References",
    "text": "References\n\n\n\n\nBotev, Z., & L’Écuyer, P. (2017). Simulation from the normal distribution truncated to an interval in the tail. Proceedings of the 10th EAI International Conference on Performance Evaluation Methodologies and Tools on 10th EAI International Conference on Performance Evaluation Methodologies and Tools, 23–29. https://doi.org/10.4108/eai.25-10-2016.2266879\n\n\nDevroye, L. (1986). Non-uniform random variate generation. Springer. http://www.nrbook.com/devroye/\n\n\nGeyer, C. J. (2011). Introduction to Markov chain Monte Carlo. In S. Brooks, A. Gelman, G. Jones, & X. L. Meng (Eds.), Handbook of Markov chain Monte Carlo (pp. 3–48). CRC Press. https://doi.org/10.1201/b10905"
  },
  {
    "objectID": "slides/bayesmod-slides2.html#probability-vs-frequency",
    "href": "slides/bayesmod-slides2.html#probability-vs-frequency",
    "title": "Bayesian modelling",
    "section": "Probability vs frequency",
    "text": "Probability vs frequency\nIn frequentist statistic, “probability” is synonym for\n\n\n\nlong-term frequency under repeated sampling"
  },
  {
    "objectID": "slides/bayesmod-slides2.html#what-is-probability",
    "href": "slides/bayesmod-slides2.html#what-is-probability",
    "title": "Bayesian modelling",
    "section": "What is probability?",
    "text": "What is probability?\nProbability reflects incomplete information.\nQuoting Finetti (1974)\n\nProbabilistic reasoning — always to be understood as subjective — merely stems from our being uncertain about something."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#why-opt-for-the-bayesian-paradigm",
    "href": "slides/bayesmod-slides2.html#why-opt-for-the-bayesian-paradigm",
    "title": "Bayesian modelling",
    "section": "Why opt for the Bayesian paradigm?",
    "text": "Why opt for the Bayesian paradigm?\n\nSatisfies the likelihood principle\nGenerative approach naturally extends to complex settings (hierarchical models)\nUncertainty quantification and natural framework for prediction\nCapability to incorporate subject-matter expertise"
  },
  {
    "objectID": "slides/bayesmod-slides2.html#bayesian-versus-frequentist",
    "href": "slides/bayesmod-slides2.html#bayesian-versus-frequentist",
    "title": "Bayesian modelling",
    "section": "Bayesian versus frequentist",
    "text": "Bayesian versus frequentist\n\n\nFrequentist\n\nParameters treated as fixed, data as random\n\ntrue value of parameter \\(\\boldsymbol{\\theta}\\) is unknown.\n\nTarget is point estimator\n\n\nBayesian\n\nBoth parameters and data are random\n\ninference is conditional on observed data\n\nTarget is a distribution"
  },
  {
    "objectID": "slides/bayesmod-slides2.html#joint-and-marginal-distribution",
    "href": "slides/bayesmod-slides2.html#joint-and-marginal-distribution",
    "title": "Bayesian modelling",
    "section": "Joint and marginal distribution",
    "text": "Joint and marginal distribution\nThe joint density of data \\(\\boldsymbol{Y}\\) and parameters \\(\\boldsymbol{\\theta}\\) is\n\\[\\begin{align*}\np(\\boldsymbol{Y}, \\boldsymbol{\\theta}) = p(\\boldsymbol{Y} \\mid \\boldsymbol{\\theta}) p(\\boldsymbol{\\theta}) =  p(\\boldsymbol{\\theta} \\mid \\boldsymbol{Y}) p(\\boldsymbol{Y})\n\\end{align*}\\] where the marginal \\(p(\\boldsymbol{Y}) = \\int_{\\boldsymbol{\\Theta}} p(\\boldsymbol{Y}, \\boldsymbol{\\theta}) \\mathrm{d} \\boldsymbol{\\theta}\\)."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#posterior",
    "href": "slides/bayesmod-slides2.html#posterior",
    "title": "Bayesian modelling",
    "section": "Posterior",
    "text": "Posterior\nUsing Bayes’ theorem, the posterior density is\n\\[\\begin{align*}\n\\color{#D55E00}{p(\\boldsymbol{\\theta} \\mid \\boldsymbol{Y})} = \\frac{\\color{#0072B2}{p(\\boldsymbol{Y} \\mid \\boldsymbol{\\theta})} \\times  \\color{#56B4E9}{p(\\boldsymbol{\\theta})}}{\\color{#E69F00}{\\int p(\\boldsymbol{Y} \\mid \\boldsymbol{\\theta}) p(\\boldsymbol{\\theta})\\mathrm{d} \\boldsymbol{\\theta}}},\n\\end{align*}\\]\nmeaning that \\[\\color{#D55E00}{\\text{posterior}} \\propto \\color{#0072B2}{\\text{likelihood}} \\times \\color{#56B4E9}{\\text{prior}}\\]\n\nEvaluating the marginal likelihood \\(\\color{#E69F00}{p(\\boldsymbol{Y})}\\), is challenging when \\(\\boldsymbol{\\theta}\\) is high-dimensional."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#updating-beliefs-and-sequentiality",
    "href": "slides/bayesmod-slides2.html#updating-beliefs-and-sequentiality",
    "title": "Bayesian modelling",
    "section": "Updating beliefs and sequentiality",
    "text": "Updating beliefs and sequentiality\nBy Bayes’ rule, we can consider updating the posterior by adding terms to the likelihood, noting that for independent \\(\\boldsymbol{y}_1\\) and \\(\\boldsymbol{y}_2\\), \\[\\begin{align*}\np(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}_1, \\boldsymbol{y}_2) \\propto p(\\boldsymbol{y}_2 \\mid \\boldsymbol{\\theta}) p(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}_1)\n\\end{align*}\\] The posterior is be updated in light of new information."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#binomial-distribution",
    "href": "slides/bayesmod-slides2.html#binomial-distribution",
    "title": "Bayesian modelling",
    "section": "Binomial distribution",
    "text": "Binomial distribution\nA binomial variable with probability of success \\(\\theta \\in [0,1]\\) has mass function \\[\\begin{align*}\nf(y; \\theta) = \\binom{n}{y} \\theta^y (1-\\theta)^{n-y}, \\qquad y = 0, \\ldots, n.\n\\end{align*}\\] Moments of the number of successes out of \\(n\\) trials are \\[\\mathsf{E}(Y \\mid \\theta) = n \\theta, \\quad \\mathsf{Va}(Y \\mid \\theta) = n \\theta(1-\\theta).\\]\n\nThe binomial coefficient \\(\\binom{n}{y}=n!/\\{(n-y)!y!\\}\\), where \\(n!=\\Gamma(n+1)\\)."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#beta-distribution",
    "href": "slides/bayesmod-slides2.html#beta-distribution",
    "title": "Bayesian modelling",
    "section": "Beta distribution",
    "text": "Beta distribution\nThe beta distribution with shapes \\(\\alpha&gt;0\\) and \\(\\beta&gt;0\\), denoted \\(\\mathsf{beta}(\\alpha,\\beta)\\), has density \\[f(y) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}y^{\\alpha - 1}(1-y)^{\\beta - 1}, \\qquad y \\in [0,1]\\]\n\nexpectation: \\(\\alpha/(\\alpha+\\beta)\\);\nmode \\((\\alpha-1)/(\\alpha+\\beta-2)\\) if \\(\\alpha, \\beta&gt;1\\), else, \\(0\\), \\(1\\) or none;\nvariance: \\(\\alpha\\beta/\\{(\\alpha+\\beta)^2(\\alpha+\\beta+1)\\}\\).\n\n\nIt is a continuous distribution over the unit interval.\nThe uniform is a special case when both shapes are unity."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#beta-binomial-example",
    "href": "slides/bayesmod-slides2.html#beta-binomial-example",
    "title": "Bayesian modelling",
    "section": "Beta-binomial example",
    "text": "Beta-binomial example\nWe write \\(Y \\sim \\mathsf{binom}(n, \\theta)\\) for \\(\\theta \\in [0,1]\\); the likelihood is \\[L(\\theta; y) = \\binom{n}{y} \\theta^y(1-\\theta)^{n-y}.\\]\nConsider a beta prior, \\(\\theta \\sim \\mathsf{beta}(\\alpha, \\beta)\\), with density \\[\np(\\theta) = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta) }\\theta^{\\alpha-1}(1-\\theta)^{\\beta - 1}.\n\\]"
  },
  {
    "objectID": "slides/bayesmod-slides2.html#density-versus-likelihood",
    "href": "slides/bayesmod-slides2.html#density-versus-likelihood",
    "title": "Bayesian modelling",
    "section": "Density versus likelihood",
    "text": "Density versus likelihood\nThe binomial distribution is discrete with support \\(0, \\ldots, n\\), whereas the likelihood is continuous over \\(\\theta \\in [0,1]\\).\n\n\nFigure 1: Binomial density function (left) and scaled likelihood function (right).\n\nIf the density or mass function integrates to 1 over the range of \\(Y\\), the integral of the likelihood over \\(\\theta\\) does not."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#posterior-density-and-proportionality",
    "href": "slides/bayesmod-slides2.html#posterior-density-and-proportionality",
    "title": "Bayesian modelling",
    "section": "Posterior density and proportionality",
    "text": "Posterior density and proportionality\nAny term not a function of \\(\\theta\\) can be dropped, since it will absorbed by the normalizing constant. The posterior density is proportional to\n\\[\\begin{align*}\nL(\\theta; y)p(\\theta) & \\stackrel{\\theta}{\\propto} \\theta^{y}(1-\\theta)^{n-y} \\times \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}\n\\\\& =\\theta^{y + \\alpha - 1}(1-\\theta)^{n-y + \\beta - 1}\n\\end{align*}\\] the kernel of a beta density with shape parameters \\(y + \\alpha\\) and \\(n-y + \\beta\\).\n\nThe symbol \\(\\propto\\), for proportionality, means dropping all terms not an argument of the left hand side."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#marginal-likelihood",
    "href": "slides/bayesmod-slides2.html#marginal-likelihood",
    "title": "Bayesian modelling",
    "section": "Marginal likelihood",
    "text": "Marginal likelihood\nThe marginal likelihood for the \\(Y \\mid P=p \\sim \\mathsf{binom}(n,p)\\) model with prior \\(P \\sim \\mathsf{beta}(\\alpha, \\beta)\\) is \\[\\begin{align*}\np_{Y}(y) = \\binom{n}{y} \\frac{\\mathrm{beta}(\\alpha + y, \\beta + n - y)}{\\mathrm{beta}(\\alpha, \\beta)}, \\quad y \\in\\{0, \\ldots,n\\}.\n\\end{align*}\\] where \\(\\mathrm{beta}(\\alpha, \\beta) = \\Gamma(\\alpha)\\Gamma(\\beta)/\\Gamma(\\alpha+\\beta)\\) is the beta function."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#experiments-and-likelihoods",
    "href": "slides/bayesmod-slides2.html#experiments-and-likelihoods",
    "title": "Bayesian modelling",
    "section": "Experiments and likelihoods",
    "text": "Experiments and likelihoods\nConsider the following sampling mechanism, which lead to \\(k\\) successes out of \\(n\\) independent trials, with the same probability of success \\(\\theta\\).\n\nBernoulli: sample fixed number of observations with \\(L(\\theta; y) =\\theta^k(1-\\theta)^{n-k}\\)\nbinomial: same, but record only total number of successes so \\(L(\\theta; y) =\\binom{n}{k}\\theta^k(1-\\theta)^{n-k}\\)\nnegative binomial: sample data until you obtain a predetermined number of successes, whence \\(L(\\theta; y) =\\binom{n-1}{k-1}\\theta^k(1-\\theta)^{n-k}\\)"
  },
  {
    "objectID": "slides/bayesmod-slides2.html#likelihood-principle",
    "href": "slides/bayesmod-slides2.html#likelihood-principle",
    "title": "Bayesian modelling",
    "section": "Likelihood principle",
    "text": "Likelihood principle\nTwo likelihoods that are proportional, up to a constant not depending on unknown parameters, yield the same evidence.\nIn all cases, \\(L(\\theta; y) \\stackrel{\\theta}{\\propto} \\theta^k(1-\\theta)^{n-k}\\), so these yield the same inference for Bayesian.\n\nFor a more in-depth discussion, see Section 6.3.2 of Casella & Berger (2002)"
  },
  {
    "objectID": "slides/bayesmod-slides2.html#integration",
    "href": "slides/bayesmod-slides2.html#integration",
    "title": "Bayesian modelling",
    "section": "Integration",
    "text": "Integration\nWe could approximate the \\(\\color{#E69F00}{\\text{marginal likelihood}}\\) through either\n\nnumerical integration (cubature)\nMonte Carlo simulations\n\nIn more complicated models, we will try to sample observations by bypassing completely this calculation.\n\nThe likelihood terms can be small (always less than one and decreasing for discrete data), so watch out for numerical overflow when evaluating normalizing constants."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#numerical-example-of-monte-carlo-integration",
    "href": "slides/bayesmod-slides2.html#numerical-example-of-monte-carlo-integration",
    "title": "Bayesian modelling",
    "section": "Numerical example of (Monte Carlo) integration",
    "text": "Numerical example of (Monte Carlo) integration\n\ny &lt;- 6L # number of successes \nn &lt;- 14L # number of trials\nalpha &lt;- beta &lt;- 1.5 # prior parameters\nunnormalized_posterior &lt;- function(theta){\n  theta^(y+alpha-1) * (1-theta)^(n-y + beta - 1)\n}\nintegrate(f = unnormalized_posterior,\n          lower = 0,\n          upper = 1)\n\n1.066906e-05 with absolute error &lt; 1e-12\n\n# Compare with known constant\nbeta(y + alpha, n - y + beta)\n\n[1] 1.066906e-05\n\n# Monte Carlo integration\nmean(unnormalized_posterior(runif(1e5)))\n\n[1] 1.061693e-05"
  },
  {
    "objectID": "slides/bayesmod-slides2.html#marginal-posterior",
    "href": "slides/bayesmod-slides2.html#marginal-posterior",
    "title": "Bayesian modelling",
    "section": "Marginal posterior",
    "text": "Marginal posterior\nIn multi-parameter models, additional integration is needed to get the marginal posterior\n\\[p(\\theta_j \\mid \\boldsymbol{y}) = \\int p(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}) \\mathrm{d} \\boldsymbol{\\theta}_{-j}.\\]\n\nMarginalization is trivial when we have a joint sample: simply keep the column corresponding to \\(\\theta_j\\)."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#prior-likelihood-and-posterior",
    "href": "slides/bayesmod-slides2.html#prior-likelihood-and-posterior",
    "title": "Bayesian modelling",
    "section": "Prior, likelihood and posterior",
    "text": "Prior, likelihood and posterior\n\n\nFigure 2: Scaled Binomial likelihood for six successes out of 14 trials, \\(\\mathsf{beta}(3/2, 3/2)\\) prior and corresponding posterior distribution from a beta-binomial model."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#proper-prior",
    "href": "slides/bayesmod-slides2.html#proper-prior",
    "title": "Bayesian modelling",
    "section": "Proper prior",
    "text": "Proper prior\nWe could define the posterior simply as the normalized product of the likelihood and some prior function.\nThe prior function need not even be proportional to a density function (i.e., integrable as a function of \\(\\boldsymbol{\\theta}\\)).\nFor example,\n\n\\(p(\\theta) \\propto \\theta^{-1}(1-\\theta)^{-1}\\) is improper because it is not integrable.\n\\(p(\\theta) \\propto 1\\) is a proper prior over \\([0,1]\\) (uniform)."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#validity-of-the-posterior",
    "href": "slides/bayesmod-slides2.html#validity-of-the-posterior",
    "title": "Bayesian modelling",
    "section": "Validity of the posterior",
    "text": "Validity of the posterior\n\nThe marginal likelihood does not depend on \\(\\boldsymbol{\\theta}\\)\n\n(a normalizing constant)\n\nFor the posterior density to be proper,\n\nthe marginal likelihood must be a finite!\nin continuous models, the posterior is proper whenever the prior function is proper."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#different-priors-give-different-posteriors",
    "href": "slides/bayesmod-slides2.html#different-priors-give-different-posteriors",
    "title": "Bayesian modelling",
    "section": "Different priors give different posteriors",
    "text": "Different priors give different posteriors\n\n\nFigure 3: Scaled binomial likelihood for six successes out of 14 trials, with \\(\\mathsf{beta}(3/2, 3/2)\\) (left), \\(\\mathsf{beta}(1/4, 1/4)\\) (middle) and \\(\\mathsf{unif}[0,1/2]\\) (right) priors and posterior density."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#role-of-the-prior",
    "href": "slides/bayesmod-slides2.html#role-of-the-prior",
    "title": "Bayesian modelling",
    "section": "Role of the prior",
    "text": "Role of the prior\nThe posterior is beta, with expected value \\[\\begin{align*}\n\\mathsf{E}(\\theta \\mid y) &= w\\frac{y}{n} + (1-w) \\frac{\\alpha}{\\alpha + \\beta}, \\\\ w&=\\frac{n}{n+\\alpha+\\beta}\n\\end{align*}\\] a weighted average of\n\nthe maximum likelihood estimator and\nthe prior mean.\n\n\nWe can think of the parameter \\(\\alpha\\) (respectively \\(\\beta\\)) as representing the fixed prior number of success (resp. failures)."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#posterior-concentration",
    "href": "slides/bayesmod-slides2.html#posterior-concentration",
    "title": "Bayesian modelling",
    "section": "Posterior concentration",
    "text": "Posterior concentration\nExcept for stubborn priors, the likelihood contribution dominates in large samples. The impact of the prior is then often negligible.\n\n\nFigure 4: Beta posterior and binomial likelihood with a uniform prior for increasing number of observations (from left to right)."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#model-comparison",
    "href": "slides/bayesmod-slides2.html#model-comparison",
    "title": "Bayesian modelling",
    "section": "Model comparison",
    "text": "Model comparison\nSuppose that we have models \\(\\mathcal{M}_m\\) \\((m=1, \\ldots, M)\\) to be compared, with parameter vectors \\(\\boldsymbol{\\theta}^{(m)}\\) and data vector \\(\\boldsymbol{y}\\) and prior probability \\(\\Pr(\\mathcal{M}_m)\\).\nThe \\(\\color{#c38f16}{\\text{posterior odds}}\\) for models \\(\\mathcal{M}_i\\) vs \\(\\mathcal{M}_j\\) is \\[\\begin{align*}\n\\color{#c38f16}{\\frac{\\Pr(\\mathcal{M}_i \\mid \\boldsymbol{y})}{\\Pr(\\mathcal{M}_j \\mid \\boldsymbol{y})}} =\n\\color{#6e948c}{\\frac{p(\\boldsymbol{y} \\mid \\mathcal{M}_i)}{p(\\boldsymbol{y} \\mid \\mathcal{M}_j)}}\n\\color{#122c43}{\\frac{\\Pr(\\mathcal{M}_i)}{\\Pr(\\mathcal{M}_j)}}\n\\end{align*}\\] equal to the \\(\\color{#6e948c}{\\text{Bayes factor}}\\) \\(\\mathsf{BF}_{ij}\\) times the \\(\\color{#122c43}{\\text{prior odds}}\\)."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#bayes-factors",
    "href": "slides/bayesmod-slides2.html#bayes-factors",
    "title": "Bayesian modelling",
    "section": "Bayes factors",
    "text": "Bayes factors\nThe \\(\\color{#6e948c}{\\text{Bayes factor}}\\) is the ratio of marginal likelihoods, as \\[\\begin{align*}\np(\\boldsymbol{y} \\mid \\mathcal{M}_i) = \\int p(y \\mid \\boldsymbol{\\theta}^{(i)}, \\mathcal{M}_i) p( \\boldsymbol{\\theta}^{(i)} \\mid \\mathcal{M}_i) \\mathrm{d}  \\boldsymbol{\\theta}^{(i)}.\n\\end{align*}\\] Values of \\(\\mathsf{BF}_{ij}&gt;1\\) correspond to model \\(\\mathcal{M}_i\\) being more likely than \\(\\mathcal{M}_j\\).\n\nStrong dependence on the prior \\(p(\\boldsymbol{\\theta}^{(i)} \\mid \\mathcal{M}_i)\\).\nMust use proper priors."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#bayes-factor-for-the-binomial-model",
    "href": "slides/bayesmod-slides2.html#bayes-factor-for-the-binomial-model",
    "title": "Bayesian modelling",
    "section": "Bayes factor for the binomial model",
    "text": "Bayes factor for the binomial model\nConsider two models with \\(Y \\mid P^{(i)}=p \\sim \\mathsf{binom}(n, p)\\) and\n\n\\(P^{(1)}\\sim \\mathsf{unif}(0,1)\\)\n\\(P^{(2)}\\sim \\mathsf{1}_{p=0.5}\\)."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#summarizing-posterior-distributions",
    "href": "slides/bayesmod-slides2.html#summarizing-posterior-distributions",
    "title": "Bayesian modelling",
    "section": "Summarizing posterior distributions",
    "text": "Summarizing posterior distributions\n\nThe output of the Bayesian learning will be either of:\n\na fully characterized distribution (in toy examples).\na numerical approximation to the posterior distribution.\nan exact or approximate sample drawn from the posterior distribution.\n\n\nThe first case, which we have already encountered, allows us to query moments (mean, median, mode) directly provided there are analytical expressions for the latter, or else we could simulate from the model."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#bayesian-inference-in-practice",
    "href": "slides/bayesmod-slides2.html#bayesian-inference-in-practice",
    "title": "Bayesian modelling",
    "section": "Bayesian inference in practice",
    "text": "Bayesian inference in practice\nMost of the field revolves around the creation of algorithms that either\n\ncircumvent the calculation of the normalizing constant\n\n(Monte Carlo and Markov chain Monte Carlo methods)\n\nprovide accurate numerical approximation, including for marginalizing out all but one parameter.\n\n(integrated nested Laplace approximations, variational inference, etc.)"
  },
  {
    "objectID": "slides/bayesmod-slides2.html#predictive-distributions",
    "href": "slides/bayesmod-slides2.html#predictive-distributions",
    "title": "Bayesian modelling",
    "section": "Predictive distributions",
    "text": "Predictive distributions\nDefine the \\(\\color{#D55E00}{\\text{posterior predictive}}\\), \\[\\begin{align*}\np(y_{\\text{new}}\\mid \\boldsymbol{y}) = \\int_{\\boldsymbol{\\Theta}} p(y_{\\text{new}} \\mid \\boldsymbol{\\theta}) \\color{#D55E00}{p(\\boldsymbol{\\theta} \\mid \\boldsymbol{y})} \\mathrm{d} \\boldsymbol{\\theta}\n\\end{align*}\\] and the \\(\\color{#56B4E9}{\\text{prior predictive}}\\) \\[\\begin{align*}\np(y_{\\text{new}}) = \\int_{\\boldsymbol{\\Theta}} p(y_{\\text{new}} \\mid \\boldsymbol{\\theta}) \\color{#56B4E9}{p(\\boldsymbol{\\theta})} \\mathrm{d} \\boldsymbol{\\theta}\n\\end{align*}\\] is useful for determining whether the prior is sensical."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#analytical-derivation-of-predictive-distribution",
    "href": "slides/bayesmod-slides2.html#analytical-derivation-of-predictive-distribution",
    "title": "Bayesian modelling",
    "section": "Analytical derivation of predictive distribution",
    "text": "Analytical derivation of predictive distribution\nGiven the \\(\\mathsf{beta}(a, b)\\) prior or posterior, the predictive for \\(n_{\\text{new}}\\) trials is beta-binomial with density \\[\\begin{align*}\np(y_{\\text{new}}\\mid y) &= \\int_0^1 \\binom{n_{\\text{new}}}{y_{\\text{new}}} \\frac{\\theta^{a + y_{\\text{new}}-1}(1-\\theta)^{b + n_{\\text{new}} - y_{\\text{new}}-1}}{\n\\mathrm{Be}(a, b)}\\mathrm{d} \\theta\n\\\\&= \\binom{n_{\\text{new}}}{y_{\\text{new}}} \\frac{\\mathrm{Be}(a + y_{\\text{new}}, b + n_{\\text{new}} - y_{\\text{new}})}{\\mathrm{Be}(a, b)}\n\\end{align*}\\]\nReplace \\(a=y + \\alpha\\) and \\(b=n-y + \\beta\\) to get the posterior predictive distribution."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#posterior-predictive-distribution",
    "href": "slides/bayesmod-slides2.html#posterior-predictive-distribution",
    "title": "Bayesian modelling",
    "section": "Posterior predictive distribution",
    "text": "Posterior predictive distribution\n\n\nFigure 5: Beta-binomial posterior predictive distribution with corresponding binomial mass function evaluated at the maximum likelihood estimator."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#posterior-predictive-distribution-via-simulation",
    "href": "slides/bayesmod-slides2.html#posterior-predictive-distribution-via-simulation",
    "title": "Bayesian modelling",
    "section": "Posterior predictive distribution via simulation",
    "text": "Posterior predictive distribution via simulation\nThe posterior predictive carries over the parameter uncertainty so will typically be wider and overdispersed relative to the corresponding distribution.\nGiven a draw \\(\\theta^*\\) from the posterior, simulate a new observation from the distribution \\(f(y_{\\text{new}}; \\theta^*)\\).\n\nnpost &lt;- 1e4L\n# Sample draws from the posterior distribution\npost_samp &lt;- rbeta(n = npost, y + alpha, n - y + beta)\n# For each draw, sample new observation\npost_pred &lt;- rbinom(n = npost, size = n, prob = post_samp)\n\n\nThe beta-binomial is used to model overdispersion in binary regression models."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#summarizing-posterior-distributions-1",
    "href": "slides/bayesmod-slides2.html#summarizing-posterior-distributions-1",
    "title": "Bayesian modelling",
    "section": "Summarizing posterior distributions",
    "text": "Summarizing posterior distributions\nThe output of a Bayesian procedure is a distribution for the parameters given the data.\nWe may wish to return different numerical summaries (expected value, variance, mode, quantiles, …)\nThe question: which point estimator to return?"
  },
  {
    "objectID": "slides/bayesmod-slides2.html#decision-theory-and-loss-functions",
    "href": "slides/bayesmod-slides2.html#decision-theory-and-loss-functions",
    "title": "Bayesian modelling",
    "section": "Decision theory and loss functions",
    "text": "Decision theory and loss functions\nA loss function \\(c(\\boldsymbol{\\theta}, \\boldsymbol{\\upsilon}): \\boldsymbol{\\Theta} \\mapsto \\mathbb{R}^k\\) assigns a weight to each value \\(\\boldsymbol{\\theta}\\), corresponding to the regret or loss.\nThe point estimator \\(\\widehat{\\boldsymbol{\\upsilon}}\\) is the minimizer of the expected loss \\[\\begin{align*}\n\\widehat{\\boldsymbol{\\upsilon}} &= \\mathop{\\mathrm{argmin}}_{\\boldsymbol{\\upsilon}}\\mathsf{E}_{\\boldsymbol{\\Theta} \\mid \\boldsymbol{Y}}\\{c(\\boldsymbol{\\theta}, \\boldsymbol{v})\\} \\\\&=\\mathop{\\mathrm{argmin}}_{\\boldsymbol{\\upsilon}} \\int_{\\boldsymbol{\\Theta}} c(\\boldsymbol{\\theta}, \\boldsymbol{\\upsilon})p(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}) \\mathrm{d} \\boldsymbol{\\theta}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides2.html#point-estimators-and-loss-functions",
    "href": "slides/bayesmod-slides2.html#point-estimators-and-loss-functions",
    "title": "Bayesian modelling",
    "section": "Point estimators and loss functions",
    "text": "Point estimators and loss functions\nIn a univariate setting, the most widely used point estimators are\n\nmean: quadratic loss \\(c(\\theta, \\upsilon) = (\\theta-\\upsilon)^2\\)\nmedian: absolute loss \\(c(\\theta, \\upsilon)=|\\theta - \\upsilon|\\)\nmode: 0-1 loss \\(c(\\theta, \\upsilon) = 1-\\mathrm{I}(\\upsilon = \\theta)\\)\n\nThe posterior mode \\(\\boldsymbol{\\theta}_{\\mathrm{map}} = \\mathrm{argmax}_{\\boldsymbol{\\theta}} p(\\boldsymbol{\\theta} \\mid \\boldsymbol{y})\\) is the maximum a posteriori or MAP estimator."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#measures-of-central-tendency",
    "href": "slides/bayesmod-slides2.html#measures-of-central-tendency",
    "title": "Bayesian modelling",
    "section": "Measures of central tendency",
    "text": "Measures of central tendency\n\n\nFigure 6: Point estimators from a right-skewed distribution (left) and from a multimodal distribution (right)."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#example-of-loss-functions",
    "href": "slides/bayesmod-slides2.html#example-of-loss-functions",
    "title": "Bayesian modelling",
    "section": "Example of loss functions",
    "text": "Example of loss functions\n\n\nFigure 7: Posterior density with mean, mode and median point estimators (left) and corresponding loss functions, scaled to have minimum value of zero (right)."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#credible-regions",
    "href": "slides/bayesmod-slides2.html#credible-regions",
    "title": "Bayesian modelling",
    "section": "Credible regions",
    "text": "Credible regions\nThe freshman dream comes true!\nA \\(1-\\alpha\\) credible region give a set of parameter values which contains the “true value” of the parameter \\(\\boldsymbol{\\theta}\\) with probability \\(1-\\alpha\\).\nCaveat: McElreath (2020) suggests the term ‘compatibility’, as it\n\nreturns the range of parameter values compatible with the model and data."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#which-credible-intervals",
    "href": "slides/bayesmod-slides2.html#which-credible-intervals",
    "title": "Bayesian modelling",
    "section": "Which credible intervals?",
    "text": "Which credible intervals?\nMultiple \\(1-\\alpha\\) intervals, most common are\n\nequitailed: region \\(\\alpha/2\\) and \\(1-\\alpha/2\\) quantiles and\nhighest posterior density interval (HPDI), which gives the smallest interval \\((1-\\alpha)\\) probability\n\n\nIf we accept to have more than a single interval, the highest posterior density region can be a set of disjoint intervals. The HDPI is more sensitive to the number of draws and more computationally intensive (see R package HDinterval). See Hyndman (1996) for computations."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#illustration-of-credible-regions",
    "href": "slides/bayesmod-slides2.html#illustration-of-credible-regions",
    "title": "Bayesian modelling",
    "section": "Illustration of credible regions",
    "text": "Illustration of credible regions\n\n\nFigure 8: Density plots with 89% (top) and 50% (bottom) equitailed or central credible (left) and highest posterior density (right) regions for two data sets, highlighted in grey."
  },
  {
    "objectID": "slides/bayesmod-slides2.html#computations-of-credible-intervals",
    "href": "slides/bayesmod-slides2.html#computations-of-credible-intervals",
    "title": "Bayesian modelling",
    "section": "Computations of credible intervals",
    "text": "Computations of credible intervals\n\nset.seed(2023)\npostsamp &lt;- rbeta(n = 1000, shape1 = 0.5, shape2 = 0.2)\nalpha &lt;- 0.11\n# Compute equitailed interval bounds\nquantile(postsamp, probs = c(alpha/2, 1-alpha/2))\n\n     5.5%     94.5% \n0.0246807 0.9999980 \n\n# Analytical (true) values\nqbeta(c(alpha/2, 1-alpha/2), shape1 = 0.5, shape2 = 0.2)\n\n[1] 0.02925205 0.99999844\n\n# Highest posterior density intervals - note values are outside of the support!\n(hdiD &lt;- HDInterval::hdi(density(postsamp), credMass = 1-alpha, allowSplit = TRUE))\n\n           begin       end\n[1,] -0.04331573 0.2800577\n[2,]  0.47816030 1.1423868\nattr(,\"credMass\")\n[1] 0.89\nattr(,\"height\")\n[1] 0.3898784"
  },
  {
    "objectID": "slides/bayesmod-slides2.html#references",
    "href": "slides/bayesmod-slides2.html#references",
    "title": "Bayesian modelling",
    "section": "References",
    "text": "References\n\n\n\n\nCasella, G., & Berger, R. L. (2002). Statistical inference (2nd ed.). Duxbury.\n\n\nFinetti, B. de. (1974). Theory of probability: A critical introductory treatment (Vol. 1). Wiley.\n\n\nHyndman, R. J. (1996). Computing and graphing highest density regions. The American Statistician, 50(2), 120–126. https://doi.org/10.1080/00031305.1996.10474359\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and STAN (2nd ed.). Chapman; Hall/CRC."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            Bayesian modelling\n        ",
    "section": "",
    "text": "Hands on introduction to Bayesian data analysis. The course will cover the formulation, evaluation and comparison of Bayesian models through examples.\n        \n        \n            MATH 80601A, Winter 2025HEC Montréal\n        \n    \n    \n      \n        \n        \n        \n      \n    \n\n\n\n\n\n\n\nInstructor\n\n   Dr. Léo Belzile\n   4.850, Côte-Sainte-Catherine\n   leo.belzile@hec.ca\n\n\n\nCourse details\n\n   Winter 2025\n   Monday\n   15:30-18:30\n   CSC, Labid Aljundi\n\n\n\nContacting me\nPlease post course-related questions on Piazza. I am best reached by email."
  },
  {
    "objectID": "exercises/05-solution.html",
    "href": "exercises/05-solution.html",
    "title": "Solution 5",
    "section": "",
    "text": "The Pareto distribution with shape \\(\\alpha&gt;0\\) and scale \\(\\tau&gt;0\\) has density \\[\nf(x; \\alpha, \\tau) = \\alpha x^{-\\alpha-1}\\tau^\\alpha \\mathrm{I}(x &gt; \\tau).\n\\] It can be used to model power laws in insurance and finance, or in demography. The uscitypopn data set in the hecbayes package contains the population size of cities above 200K inhabitants in the United States, from the 2020 census.\n\nUsing improper priors \\(p(\\alpha, \\tau) \\propto 1,\\) write the joint posterior for a simple random sample of size \\(n\\) and derive the conditional distributions \\(p(\\alpha \\mid \\boldsymbol{y}, \\tau)\\) and \\(p(\\tau \\mid \\alpha, \\boldsymbol{y})\\).\nThe mononomial distribution \\(\\mathsf{Mono}(a,b)\\) has density \\(p(x) \\propto x^{a-1}\\mathrm{I}(0 \\leq x \\leq b)\\). Find the normalizing constant for the distribution and obtain the quantile function to derive a sampler.\nImplement Gibbs sampling for this problem for the uscitypopn data. Draw enough observations to obtain an effective sample size of at least 1000 observations. Calculate the accuracy of your estimates?\n\n\nSolution. With improper prior, the joint posterior is the product of the likelihood contributions so \\[\np(\\alpha, \\tau \\mid \\boldsymbol{y}) \\propto \\alpha^n \\left(\\prod_{i=1}^n y_i\\right)^{-\\alpha-1} \\tau^{n\\alpha} \\mathrm{I}(\\min_i y_i &gt; \\tau).\n\\] Using the hint, write the conditional density for \\(\\alpha\\) given the rest as \\[\\begin{align*}\np(\\alpha \\mid \\boldsymbol{y}, \\tau) \\propto \\alpha^n \\left( \\frac{\\prod_{i=1}^n y_i}{\\tau^n}\\right)^{-\\alpha} = \\alpha^{(n+1)-1} \\exp\\left\\{-\\alpha \\left(\\sum_{i=1}^n\\log y_i - n\\log \\tau\\right) \\right\\}\n\\end{align*}\\] which is \\(\\mathsf{Gamma}\\big(n+1, \\sum_{i=1}^n \\log y_i - n \\log \\tau \\big)\\). For the second, we have \\[\\begin{align*}\np(\\tau \\mid \\alpha, \\boldsymbol{y}) \\propto \\tau^{n\\alpha} \\mathrm{I}(\\min_{i} y_i &gt; \\tau),\n\\end{align*}\\] a mononomial distribution with parameters \\(a=n\\alpha+1\\) and \\(b = \\min_{i} y_i\\).\nTo find the normalizing constant of the mononomial distribution, we simply integrate the unnormalized density to obtain the reciprocal constant: if \\(c = \\int g(x) \\mathrm{d} x\\) for \\(c &lt; \\infty\\) and \\(g(x) \\geq 0\\) for all \\(x\\), then \\(g(x)/c\\) integrates to one and is a valid density. Thus, we find \\[c= \\int_0^b x^{a-1}\\mathrm{d} x = \\left[\\frac{x^{a}}{a}\\right]_{0}^b= \\frac{b^{a}}{a}.\\] The distribution function is \\(G(x) = (x/b)^{a}\\) for \\(x \\in [0,b]\\) and the quantile function \\(G^{-1}(u) = u^{1/a}b\\).\n\nqmono &lt;- function(u, a, b, log = FALSE){\n  stopifnot(isTRUE(all(a &gt; 0, b &gt; 0, u &gt;= 0, u &lt;= 1)))\n logq &lt;-   log(u)/(a+1) + log(b)\n if(log){ return(logq)} else { return(exp(logq)) }\n}\n\n\n# Load data\ndata(\"uscitypopn\", package = \"hecbayes\")\ny &lt;- uscitypopn$population\nn &lt;- length(y)\n# Summary statistics appearing in the posterior distribution\nsumlogy &lt;- sum(log(y))\nminy &lt;- min(y)\n# MCMC via Gibbs sampling\nB &lt;- 1e4L\nchains &lt;- matrix(0, nrow = B, ncol = 2)\ncolnames(chains) &lt;- c(\"alpha\", \"tau\")\ncurr &lt;- c(2, 2e5)\nfor(b in seq_len(B)){\n  chains[b,1] &lt;- curr[1] &lt;- rgamma(n = 1, shape = n+1, rate = sumlogy - n*log(curr[2]))\n  chains[b,2] &lt;- curr[2] &lt;- qmono(runif(1), a = n*curr[1]+1, b = miny)\n}\nchains &lt;- coda::as.mcmc(chains)\n# Compute effective sample size\ncoda::effectiveSize(chains)\n\n    alpha       tau \n 9718.142 10000.000 \n\nsummary(chains)\n\n\nIterations = 1:10000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 10000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n           Mean        SD  Naive SE Time-series SE\nalpha 1.391e+00    0.1306  0.001306       0.001324\ntau   1.991e+05 1247.1410 12.471410      12.471410\n\n2. Quantiles for each variable:\n\n           2.5%       25%       50%       75%     97.5%\nalpha 1.143e+00 1.303e+00 1.385e+00 1.476e+00 1.657e+00\ntau   1.958e+05 1.987e+05 1.995e+05 2.000e+05 2.004e+05\n\n\nWe can see that the autocorrelation is minimal, so the sampler is quite efficient.",
    "crumbs": [
      "Exercises",
      "Solutions",
      "5. Gibbs sampling"
    ]
  },
  {
    "objectID": "exercises/05-solution.html#exercise-5.1",
    "href": "exercises/05-solution.html#exercise-5.1",
    "title": "Solution 5",
    "section": "",
    "text": "The Pareto distribution with shape \\(\\alpha&gt;0\\) and scale \\(\\tau&gt;0\\) has density \\[\nf(x; \\alpha, \\tau) = \\alpha x^{-\\alpha-1}\\tau^\\alpha \\mathrm{I}(x &gt; \\tau).\n\\] It can be used to model power laws in insurance and finance, or in demography. The uscitypopn data set in the hecbayes package contains the population size of cities above 200K inhabitants in the United States, from the 2020 census.\n\nUsing improper priors \\(p(\\alpha, \\tau) \\propto 1,\\) write the joint posterior for a simple random sample of size \\(n\\) and derive the conditional distributions \\(p(\\alpha \\mid \\boldsymbol{y}, \\tau)\\) and \\(p(\\tau \\mid \\alpha, \\boldsymbol{y})\\).\nThe mononomial distribution \\(\\mathsf{Mono}(a,b)\\) has density \\(p(x) \\propto x^{a-1}\\mathrm{I}(0 \\leq x \\leq b)\\). Find the normalizing constant for the distribution and obtain the quantile function to derive a sampler.\nImplement Gibbs sampling for this problem for the uscitypopn data. Draw enough observations to obtain an effective sample size of at least 1000 observations. Calculate the accuracy of your estimates?\n\n\nSolution. With improper prior, the joint posterior is the product of the likelihood contributions so \\[\np(\\alpha, \\tau \\mid \\boldsymbol{y}) \\propto \\alpha^n \\left(\\prod_{i=1}^n y_i\\right)^{-\\alpha-1} \\tau^{n\\alpha} \\mathrm{I}(\\min_i y_i &gt; \\tau).\n\\] Using the hint, write the conditional density for \\(\\alpha\\) given the rest as \\[\\begin{align*}\np(\\alpha \\mid \\boldsymbol{y}, \\tau) \\propto \\alpha^n \\left( \\frac{\\prod_{i=1}^n y_i}{\\tau^n}\\right)^{-\\alpha} = \\alpha^{(n+1)-1} \\exp\\left\\{-\\alpha \\left(\\sum_{i=1}^n\\log y_i - n\\log \\tau\\right) \\right\\}\n\\end{align*}\\] which is \\(\\mathsf{Gamma}\\big(n+1, \\sum_{i=1}^n \\log y_i - n \\log \\tau \\big)\\). For the second, we have \\[\\begin{align*}\np(\\tau \\mid \\alpha, \\boldsymbol{y}) \\propto \\tau^{n\\alpha} \\mathrm{I}(\\min_{i} y_i &gt; \\tau),\n\\end{align*}\\] a mononomial distribution with parameters \\(a=n\\alpha+1\\) and \\(b = \\min_{i} y_i\\).\nTo find the normalizing constant of the mononomial distribution, we simply integrate the unnormalized density to obtain the reciprocal constant: if \\(c = \\int g(x) \\mathrm{d} x\\) for \\(c &lt; \\infty\\) and \\(g(x) \\geq 0\\) for all \\(x\\), then \\(g(x)/c\\) integrates to one and is a valid density. Thus, we find \\[c= \\int_0^b x^{a-1}\\mathrm{d} x = \\left[\\frac{x^{a}}{a}\\right]_{0}^b= \\frac{b^{a}}{a}.\\] The distribution function is \\(G(x) = (x/b)^{a}\\) for \\(x \\in [0,b]\\) and the quantile function \\(G^{-1}(u) = u^{1/a}b\\).\n\nqmono &lt;- function(u, a, b, log = FALSE){\n  stopifnot(isTRUE(all(a &gt; 0, b &gt; 0, u &gt;= 0, u &lt;= 1)))\n logq &lt;-   log(u)/(a+1) + log(b)\n if(log){ return(logq)} else { return(exp(logq)) }\n}\n\n\n# Load data\ndata(\"uscitypopn\", package = \"hecbayes\")\ny &lt;- uscitypopn$population\nn &lt;- length(y)\n# Summary statistics appearing in the posterior distribution\nsumlogy &lt;- sum(log(y))\nminy &lt;- min(y)\n# MCMC via Gibbs sampling\nB &lt;- 1e4L\nchains &lt;- matrix(0, nrow = B, ncol = 2)\ncolnames(chains) &lt;- c(\"alpha\", \"tau\")\ncurr &lt;- c(2, 2e5)\nfor(b in seq_len(B)){\n  chains[b,1] &lt;- curr[1] &lt;- rgamma(n = 1, shape = n+1, rate = sumlogy - n*log(curr[2]))\n  chains[b,2] &lt;- curr[2] &lt;- qmono(runif(1), a = n*curr[1]+1, b = miny)\n}\nchains &lt;- coda::as.mcmc(chains)\n# Compute effective sample size\ncoda::effectiveSize(chains)\n\n    alpha       tau \n 9718.142 10000.000 \n\nsummary(chains)\n\n\nIterations = 1:10000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 10000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n           Mean        SD  Naive SE Time-series SE\nalpha 1.391e+00    0.1306  0.001306       0.001324\ntau   1.991e+05 1247.1410 12.471410      12.471410\n\n2. Quantiles for each variable:\n\n           2.5%       25%       50%       75%     97.5%\nalpha 1.143e+00 1.303e+00 1.385e+00 1.476e+00 1.657e+00\ntau   1.958e+05 1.987e+05 1.995e+05 2.000e+05 2.004e+05\n\n\nWe can see that the autocorrelation is minimal, so the sampler is quite efficient.",
    "crumbs": [
      "Exercises",
      "Solutions",
      "5. Gibbs sampling"
    ]
  },
  {
    "objectID": "exercises/05-solution.html#exercise-5.2",
    "href": "exercises/05-solution.html#exercise-5.2",
    "title": "Solution 5",
    "section": "Exercise 5.2",
    "text": "Exercise 5.2\nImplement the Bayesian LASSO for the diabetes cancer surgery from package lars. Check Park & Casella (2008) for the details of the Gibbs sampling (p. 682, right column).\n\nFit the model for a range of values of \\(\\lambda\\) and produce parameter estimate paths to replicate Figure 2 of the paper.\nCheck the effective sample size and comment on the mixing. Is it impacted by the tuning parameter?\nImplement the method of section 3.1 from Park & Casella (2008) by adding \\(\\lambda\\) as a parameter.\nFor three models with different values of \\(\\lambda\\), compute the widely applicable information criterion (WAIC) and use it to assess predictive performance.\n\n\nSolution. We first setup a Gibbs sampler for a given value of \\(\\lambda\\), or using the empirical Bayes estimator provided in section 3.1. The effective sampling size for fixed \\(\\lambda\\) is good. If we let the parameter varies, the performance degrades and we obtain an effective size shy of 1000 for 10K iterations for \\(\\lambda\\), and comfortably above 5000 for others.\n\ndata(diabetes, package = \"lars\")\nbayeslasso &lt;- function(lambda = NULL, \n                       B = 1e4L,\n                       x = diabetes$x, \n                       y = diabetes$y){\n  stopifnot(is.matrix(x), is.vector(y))\n  # Scale inputs in case\n  x &lt;- scale(x, center = TRUE, scale = FALSE)\n  y &lt;- y - mean(y)\n  # Check method\n  if(is.null(lambda)){\n    method &lt;- \"empbayes\"\n  } else{\n    method &lt;- \"fixed\" \n  }\n  burnin &lt;- 250L\n  # Precompute quantities and dimensions\n  xtx &lt;- crossprod(x)\n  p &lt;- ncol(x)\n  n &lt;- nrow(x)\n  # Obtain initial estimates\n  linmod &lt;- lm(y ~ x - 1)\n  betaols &lt;- coef(linmod)\n  beta.curr &lt;- betaols\n  sigmasq.curr &lt;- mean(residuals(linmod)^2)\n  tausqinv.curr &lt;- rep(1, p)\n  # Value reported in the text for the optimal parameter: lambda = 0.237\n  beta.ind &lt;- 1:p\n  sigmasq.ind &lt;- p + 1L\n  tausq.ind &lt;- seq(from = p + 2L, length.out = p, by = 1L)\n  chains &lt;- matrix(0, nrow = B, ncol = p + 1 + p + \n                     ifelse(method == \"fixed\", 0,1))\n  if(method == \"fixed\"){\n    colnames(chains) &lt;- c(paste0(\"beta\", 1:p), \"sigmasq\",\n                          paste0(\"tausq\", 1:p))\n    lambdasq.curr &lt;- lambda[1]^2\n  } else{\n    colnames(chains) &lt;- c(paste0(\"beta\", 1:p), \"sigmasq\", \n                          paste0(\"tausq\", 1:p), \"lambda\")\n    lambdasq.curr &lt;- p*sqrt(sigmasq.curr)/sum(abs(betaols))\n    lambdasq.ind &lt;- ncol(chains)\n  }\n# MCMC loop\nfor(b in seq_len(B + burnin)){\n  ind &lt;- pmax(1, b-burnin)\n  Ainv &lt;- solve(xtx + diag(tausqinv.curr))\n  beta.curr &lt;- chains[ind,beta.ind] &lt;- as.numeric(\n    mvtnorm::rmvnorm(\n      n = 1, \n      mean = as.numeric(Ainv %*% t(x) %*% y), \n      sigma = sigmasq.curr*Ainv))\n  sigmasq.curr &lt;- chains[ind, sigmasq.ind] &lt;- 1/rgamma(\n    n = 1, \n    shape = (n-1+p)/2,\n    rate = sum((y-x %*% beta.curr)^2)/2 + \n      sum(beta.curr^2*tausqinv.curr)/2)\n  # Compute marginal posterior mean for lambda, using section 3.1\n  sumexpect &lt;- 0\n  for(j in 1:p){\n    tausqinv.curr[j] &lt;- actuar::rinvgauss(\n      n = 1, \n      mean = sqrt(lambdasq.curr*sigmasq.curr)/abs(beta.curr[j]),\n      dispersion = 1/lambdasq.curr)\n    if(method != \"fixed\"){\n    sumexpect &lt;- sumexpect + mean(1/actuar::rinvgauss(\n      n = 1000, \n      mean = sqrt(lambdasq.curr*sigmasq.curr)/abs(beta.curr[j]),\n      dispersion = 1/lambdasq.curr))\n    }\n  }\n  chains[ind, tausq.ind] &lt;- 1/tausqinv.curr\n  if(method != \"fixed\"){\n    lambdasq.curr &lt;- chains[ind, lambdasq.ind] &lt;- 2*p/sumexpect\n  }\n}\n  if(method != \"fixed\"){\n  chains[, lambdasq.ind] &lt;- sqrt(chains[, lambdasq.ind])\n}\n# Cast Markov chains to mcmc class object.\nchains.mcmc &lt;- coda::as.mcmc(chains)\n# Effective sample size\ness &lt;- as.integer(round(coda::effectiveSize(chains.mcmc), 0))\n\n# Compute WAIC from log pointwise density\nlppd &lt;- 0\npenalty &lt;- 0\nfor(i in seq_len(n)){\n  lppd_i &lt;- dnorm(\n    x = y[i], \n    mean = as.numeric(chains[,beta.ind] %*% c(x[i,])), \n    sd = sqrt(chains[,sigmasq.ind]), \n    log = TRUE)\n  lppd &lt;- lppd + mean(lppd_i)\n  penalty &lt;- penalty + var(lppd_i)\n}\nwaic &lt;- (-lppd + penalty)/n\nl1norm &lt;- mean(rowSums(abs(chains[,beta.ind])))\n\n# Parameter estimates and 95% equitailed credible intervals\nquant &lt;- t(apply(chains, 2, \n                quantile, prob = c(0.025, 0.5, 0.975)))\nregpar &lt;- as.data.frame(cbind(quant,\n                colMeans(chains),\n                coda::batchSE(chains.mcmc),\n                ess))\nregpar$pars &lt;- rownames(quant)\nrownames(regpar) &lt;- NULL\ncolnames(regpar) &lt;- c(\"lower\", \"median\", \"upper\", \n                      \"mean\", \"se\", \"ess\", \"par\")\nregpar &lt;- regpar[,c(7,4:5,1:3,6)]\nattr(regpar, \"waic\") &lt;- waic\nattr(regpar, \"l1norm\") &lt;- l1norm\n return(regpar)\n}\n\n# Call the MCMC sampler\nset.seed(2023)\nlasso_empbayes &lt;- bayeslasso(lambda = NULL)\n# Extract the value of WAIC\nwaic &lt;- attr(lasso_empbayes, \"waic\")\n\n\n\n\n\n\n\n\n\nFigure 1: Standardized median posterior estimates of the coefficients for the Bayesian LASSO with 95 percent equitailed credible intervals, with \\(\\lambda\\) estimated using empirical Bayes. Ordinary least square estimates are denoted by crosses.\n\n\n\n\n\nThe plot corresponds to Figure 2 of Park & Casella (2008) and the posterior summaries, reported in Table 1, are also in line with those of the paper.\n\n\n\n\nTable 1: Estimates posterior summaries from the Bayesian LASSO, based on 10K draws. Posterior means and adjusted standard errors, posterior median and equitailed 95 percent credible intervals, effective sample.\n\n\n\n\n\n\npar\nmean\nse\nlower\nmedian\nupper\ness\n\n\n\n\nbeta1\n-3.14\n0.58\n-112.92\n-2.34\n105.68\n10000\n\n\nbeta2\n-214.04\n0.58\n-331.89\n-213.49\n-97.58\n9012\n\n\nbeta3\n523.41\n0.76\n393.47\n523.87\n656.33\n9062\n\n\nbeta4\n307.64\n0.72\n177.38\n307.69\n439.33\n8957\n\n\nbeta5\n-187.12\n2.60\n-587.60\n-170.71\n125.58\n5089\n\n\nbeta6\n7.79\n1.92\n-272.14\n-1.62\n344.59\n6056\n\n\nbeta7\n-154.43\n1.62\n-385.12\n-153.23\n72.40\n5259\n\n\nbeta8\n96.44\n1.60\n-131.62\n87.10\n353.40\n6460\n\n\nbeta9\n524.09\n1.26\n331.93\n520.90\n727.05\n6630\n\n\nbeta10\n64.21\n0.69\n-49.05\n61.87\n188.78\n8897\n\n\nsigmasq\n2952.78\n2.00\n2585.93\n2945.02\n3370.20\n9511\n\n\ntausq1\n20.55\n0.26\n0.24\n11.13\n93.70\n10000\n\n\ntausq2\n34.75\n0.33\n3.42\n25.19\n122.06\n8868\n\n\ntausq3\n58.44\n0.36\n13.42\n49.09\n155.41\n9375\n\n\ntausq4\n41.99\n0.39\n6.09\n32.35\n133.19\n8972\n\n\ntausq5\n34.17\n0.45\n1.03\n24.45\n122.56\n5159\n\n\ntausq6\n26.82\n0.38\n0.57\n17.18\n105.39\n7441\n\n\ntausq7\n31.06\n0.35\n1.04\n21.46\n118.21\n8954\n\n\ntausq8\n27.47\n0.33\n0.56\n17.94\n107.05\n8551\n\n\ntausq9\n59.02\n0.47\n12.95\n49.73\n160.42\n7805\n\n\ntausq10\n23.35\n0.30\n0.40\n13.66\n102.21\n9703\n\n\nlambda\n0.24\n0.00\n0.21\n0.24\n0.26\n1038\n\n\n\n\n\n\n\n\nFor the last part, we can simply run the MCMC and find the value of \\(\\lambda\\) that yields the lowest value of WAIC.\n\nset.seed(2023)\nblasso1 &lt;- bayeslasso(lambda = 0.1)\nblasso2 &lt;- bayeslasso(lambda = 0.2)\nblasso3 &lt;- bayeslasso(lambda = 1)\n2*length(diabetes$y)*c(attr(blasso1, \"waic\"), attr(blasso2, \"waic\"), attr(blasso3, \"waic\"))\n\n[1] 4802.449 4801.923 4804.496",
    "crumbs": [
      "Exercises",
      "Solutions",
      "5. Gibbs sampling"
    ]
  },
  {
    "objectID": "exercises/04-solution.html",
    "href": "exercises/04-solution.html",
    "title": "Solution 4",
    "section": "",
    "text": "Consider the Laplace family of distribution, \\(\\mathsf{Laplace}(\\nu, \\tau)\\), with density \\[\\begin{align*}\ng(x; \\nu, \\tau) = \\frac{1}{2\\tau} \\exp\\left(- \\frac{|x-\\nu|}{\\tau}\\right), \\qquad \\nu \\in \\mathbb{R}, \\tau &gt; 0\n\\end{align*}\\] as a candidate distribution for rejection sampling from \\(\\mathsf{Gauss}(0,1)\\).\n\nProvide an inversion sampling algorithm to generate from \\(\\mathsf{Laplace}(\\nu, \\tau)\\).\nCan you use the proposal to generate from a standard Gaussian? for Student-\\(t\\) with 1 degree of freedom? Justify your answer.\nConsider as proposal a location-scale version of the Student-t with \\(3\\) degrees of freedom. Find the optimal location and scale parameters and the upper bound \\(C\\) for your choice.\nUse the accept-reject to simulate 1000 independent observations and compute the empirical acceptance rate.\n\n\nSolution. \n\nThe distribution function is \\[\\begin{align*}\nF(x) = \\begin{cases}\n\\frac{1}{2} \\exp\\left(\\frac{x-\\nu}{\\tau}\\right) & x \\leq \\nu\\\\\n1 - \\frac{1}{2} \\exp\\left(-\\frac{x-\\nu}{\\tau}\\right) & x &gt;\\nu\\\\\n\\end{cases}\n\\end{align*}\\] and using the quantile transform, set \\(X=\\nu + \\tau \\log(2U)\\) if \\(U \\leq 0.5\\) and \\(X=\\nu - \\tau\\log(2-2U)\\) if \\(U &gt; 0.5\\) for \\(U \\sim \\mathsf{unif}(0,1)\\).\nThe Gaussian has lighter tail than the Laplace, so this won’t work. The Cauchy distribution would be a suitable candidate, albeit too heavy tailed.\nThe optimal value for the location of the Student-\\(t\\) would be \\(\\nu\\) (e.g., zero for the standard Laplace). We compute the optimal scale via in the code below: \\[\n\\mathrm{argmin}_{\\sigma \\in \\mathbb{R}_{+}}\\mathrm{argmax}_{x \\in \\mathbb{R}} \\{\\log f(x) - \\log g(x; \\sigma)\\}\n\\]\n\n\n#' Laplace density\ndlaplace &lt;- function(x, loc = 0, scale = 1, log = FALSE){\n stopifnot(scale &gt; 0)\n logdens &lt;-  -log(2*scale) - abs(x-loc)/scale\n if(log){\n return(logdens)\n } else{\n return(exp(logdens))\n }\n}\ndstudent &lt;- function(x, loc = 0, scale = 1, df = 1, log = FALSE){\n  logdens &lt;- -log(scale) + dt(x = (x - loc)/scale, df = df, log = TRUE)\n   if(log){\n    return(logdens)\n   } else{\n   return(exp(logdens))\n   }\n}\n# For each value of the scale sigma,\n# find the minimum value of x (typically at zero)\nopt &lt;- optimize(f = function(sigma){\n  optimize(f = function(x){\n  dlaplace(x, log = TRUE) - \n    dstudent(x, scale = sigma, df = 3, log = TRUE)}, \n  maximum = TRUE, \n  interval = c(-100, 100))$objective\n}, interval = c(0.1,10))\n(C &lt;- exp(opt$objective))\n\n[1] 1.261368\n\n(sigma &lt;- opt$minimum)\n\n[1] 0.9272381\n\n# Simulate from accept-reject\nntrials &lt;- 1.1*C*1000\n# Simulate from location-scale student\ncandidate &lt;- sigma*rt(n = ntrials, df = 3)\n# Compute log of acceptance rate\nlogR &lt;- dlaplace(candidate, log = TRUE) - \n  dstudent(candidate, scale = sigma, df = 3, log = TRUE) \nsamp &lt;- candidate[logR &gt;= log(C) + -rexp(ntrials)]\n# Monte Carlo estimator of the acceptance rate\nntrials/length(samp)\n\n[1] 1.261368\n\n# Plot density\nlibrary(ggplot2)\nggplot(data = data.frame(x = samp),\n       mapping = aes(x = x)) +\n  geom_density() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nThe Monte Carlo acceptance rate is 1.26, compared with the analytical bound found via numerical optimization of 1.26, to two significant digits.",
    "crumbs": [
      "Exercises",
      "Solutions",
      "4. Monte Carlo methods"
    ]
  },
  {
    "objectID": "exercises/04-solution.html#exercise-4.1",
    "href": "exercises/04-solution.html#exercise-4.1",
    "title": "Solution 4",
    "section": "",
    "text": "Consider the Laplace family of distribution, \\(\\mathsf{Laplace}(\\nu, \\tau)\\), with density \\[\\begin{align*}\ng(x; \\nu, \\tau) = \\frac{1}{2\\tau} \\exp\\left(- \\frac{|x-\\nu|}{\\tau}\\right), \\qquad \\nu \\in \\mathbb{R}, \\tau &gt; 0\n\\end{align*}\\] as a candidate distribution for rejection sampling from \\(\\mathsf{Gauss}(0,1)\\).\n\nProvide an inversion sampling algorithm to generate from \\(\\mathsf{Laplace}(\\nu, \\tau)\\).\nCan you use the proposal to generate from a standard Gaussian? for Student-\\(t\\) with 1 degree of freedom? Justify your answer.\nConsider as proposal a location-scale version of the Student-t with \\(3\\) degrees of freedom. Find the optimal location and scale parameters and the upper bound \\(C\\) for your choice.\nUse the accept-reject to simulate 1000 independent observations and compute the empirical acceptance rate.\n\n\nSolution. \n\nThe distribution function is \\[\\begin{align*}\nF(x) = \\begin{cases}\n\\frac{1}{2} \\exp\\left(\\frac{x-\\nu}{\\tau}\\right) & x \\leq \\nu\\\\\n1 - \\frac{1}{2} \\exp\\left(-\\frac{x-\\nu}{\\tau}\\right) & x &gt;\\nu\\\\\n\\end{cases}\n\\end{align*}\\] and using the quantile transform, set \\(X=\\nu + \\tau \\log(2U)\\) if \\(U \\leq 0.5\\) and \\(X=\\nu - \\tau\\log(2-2U)\\) if \\(U &gt; 0.5\\) for \\(U \\sim \\mathsf{unif}(0,1)\\).\nThe Gaussian has lighter tail than the Laplace, so this won’t work. The Cauchy distribution would be a suitable candidate, albeit too heavy tailed.\nThe optimal value for the location of the Student-\\(t\\) would be \\(\\nu\\) (e.g., zero for the standard Laplace). We compute the optimal scale via in the code below: \\[\n\\mathrm{argmin}_{\\sigma \\in \\mathbb{R}_{+}}\\mathrm{argmax}_{x \\in \\mathbb{R}} \\{\\log f(x) - \\log g(x; \\sigma)\\}\n\\]\n\n\n#' Laplace density\ndlaplace &lt;- function(x, loc = 0, scale = 1, log = FALSE){\n stopifnot(scale &gt; 0)\n logdens &lt;-  -log(2*scale) - abs(x-loc)/scale\n if(log){\n return(logdens)\n } else{\n return(exp(logdens))\n }\n}\ndstudent &lt;- function(x, loc = 0, scale = 1, df = 1, log = FALSE){\n  logdens &lt;- -log(scale) + dt(x = (x - loc)/scale, df = df, log = TRUE)\n   if(log){\n    return(logdens)\n   } else{\n   return(exp(logdens))\n   }\n}\n# For each value of the scale sigma,\n# find the minimum value of x (typically at zero)\nopt &lt;- optimize(f = function(sigma){\n  optimize(f = function(x){\n  dlaplace(x, log = TRUE) - \n    dstudent(x, scale = sigma, df = 3, log = TRUE)}, \n  maximum = TRUE, \n  interval = c(-100, 100))$objective\n}, interval = c(0.1,10))\n(C &lt;- exp(opt$objective))\n\n[1] 1.261368\n\n(sigma &lt;- opt$minimum)\n\n[1] 0.9272381\n\n# Simulate from accept-reject\nntrials &lt;- 1.1*C*1000\n# Simulate from location-scale student\ncandidate &lt;- sigma*rt(n = ntrials, df = 3)\n# Compute log of acceptance rate\nlogR &lt;- dlaplace(candidate, log = TRUE) - \n  dstudent(candidate, scale = sigma, df = 3, log = TRUE) \nsamp &lt;- candidate[logR &gt;= log(C) + -rexp(ntrials)]\n# Monte Carlo estimator of the acceptance rate\nntrials/length(samp)\n\n[1] 1.261368\n\n# Plot density\nlibrary(ggplot2)\nggplot(data = data.frame(x = samp),\n       mapping = aes(x = x)) +\n  geom_density() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nThe Monte Carlo acceptance rate is 1.26, compared with the analytical bound found via numerical optimization of 1.26, to two significant digits.",
    "crumbs": [
      "Exercises",
      "Solutions",
      "4. Monte Carlo methods"
    ]
  },
  {
    "objectID": "exercises/04-solution.html#exercise-4.2",
    "href": "exercises/04-solution.html#exercise-4.2",
    "title": "Solution 4",
    "section": "Exercise 4.2",
    "text": "Exercise 4.2\nWe revisit Exercise 2.3, which used a half-Cauchy prior for the exponential waiting time of buses.\nThe ratio-of-uniform method, implemented in the rust R package, can be used to simulate independent draws from the posterior of the rate \\(\\lambda\\). The following code produces\n\nnobs &lt;- 10L # number of observations\nybar &lt;- 8   # average waiting time\nB &lt;- 1e4L  # number of draws\n# Un-normalized log posterior: scaled log likelihood + log prior\nupost &lt;- function(x){ \n  dgamma(x = x, shape = nobs + 1L, rate = nobs*ybar, log = TRUE) +\n    log(2) + dt(x = x, df = 1, log = TRUE)}\npost_samp &lt;- rust::ru(logf = upost, \n                      n = B, \n                      d = 1,  # dimension of parameter (scalar)\n                      init = nobs/ybar)$sim_vals # initial value of mode\n\nEstimate using the independent Monte Carlo samples:\n\nthe probability that the average waiting time \\(1/\\lambda\\) is between 3 and 15 minutes\nthe average waiting time\nthe standard deviation of the average waiting time.\n\nNext, implement a random walk Metropolis–Hastings algorithm to sample draws from the posterior and re-estimate the quantities. Compare the values.\n\nSolution. \n\n# Monte Carlo for waiting time\n# Lambda is the reciprocal mean (1/minute)\ntimes_mc &lt;- 1/post_samp\n# Mean of binary variables + std. error\np &lt;- mean(times_mc &gt; 3 & times_mc &lt; 15)\nc(est = p, se = sqrt(p*(1-p)/B))\n\n        est          se \n0.977900000 0.001470088 \n\n# Posterior mean with standard error\nc(est = mean(times_mc), se = sd(times_mc)/sqrt(length(post_samp)))\n\n       est         se \n8.02353960 0.02676175 \n\n# Metropolis-Hastings algorithm\nB &lt;- 1e4L\ncurr &lt;- 8/10 # prior mean\nchains &lt;- numeric(B) # container\nsd_prop &lt;- 0.1 # proposal standard deviation\nfor(b in seq_len(B)){\n  prop &lt;- rnorm(n = 1, mean = curr, sd = sd_prop)\n  if(upost(prop) - upost(curr) &gt; -rexp(1)){\n    curr &lt;- prop\n  }\n  chains[b] &lt;- curr\n}\n# Discard burn-in\ntimes &lt;- 1/chains[-(1:100)]\n# Estimate quantities using Monte Carlo\nmean(times &gt; 3 & times &lt; 15)\n\n[1] 0.9770707\n\nmean(times)\n\n[1] 8.074385\n\nsd(times)\n\n[1] 2.743424\n\n# Summary of MCMC\nmcmc &lt;- coda::mcmc(times)\nsummary(mcmc)\n\n\nIterations = 1:9900\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 9900 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean             SD       Naive SE Time-series SE \n       8.07439        2.74342        0.02757        0.05848 \n\n2. Quantiles for each variable:\n\n  2.5%    25%    50%    75%  97.5% \n 4.406  6.167  7.580  9.382 14.785 \n\n\nWe can see that the standard error for the mean is roughly twice as big. We would thus need to inflate the sample size by a factor four to get the same precision.",
    "crumbs": [
      "Exercises",
      "Solutions",
      "4. Monte Carlo methods"
    ]
  },
  {
    "objectID": "exercises/04-solution.html#solution-4.3",
    "href": "exercises/04-solution.html#solution-4.3",
    "title": "Solution 4",
    "section": "Solution 4.3",
    "text": "Solution 4.3\nConsider the following code which implements a Metropolis–Hastings algorithm to simulate observations from a \\(\\mathsf{beta}(0.5, 0.5)\\) density.\n\nlog_f &lt;- function(par){\n  dbeta(x = par, shape1 = 0.5, shape2 = 0.5, log = TRUE)\n}\nmetropo &lt;- function(B, sd_prop = 0.2){\n  chain &lt;- rep(0, B)\n  # Draw initial value\n  cur &lt;- runif(1)\n  for(b in seq_len(B)){\n    repeat {\n        # Simulate proposal from Gaussian random walk proposal\n        prop &lt;- cur + rnorm(1, sd = sd_prop)\n        # check admissibility for probability of success\n        if (prop &gt;= 0 & prop &lt;= 1)\n          break\n    }\n    # Compute (log) acceptance ratio\n    logR &lt;- log_f(prop) - log_f(cur) \n    # Accept the move if R &gt; u\n    if(isTRUE(logR &gt; log(runif(1)))){\n     cur &lt;- prop \n    }\n    chain[b] &lt;- cur\n  }\n  return(chain)\n}\n# Run MCMC for 10K iterations\nmc &lt;- metropo(1e4L)\n\nTo see if the algorithm works:\n\nPlot the density of the Markov chain draws along with the beta density curve.\nCheck that empirical moments match the theoretical ones\n\nIf the algorithm is incorrect, provide a fix and explain the reason for the problem.\n\nSolution. The sampler is incorrect because it tacitly draws from Gaussian variables that are restricted to \\([0,1]\\) via the accept-reject step. This means in particular that the acceptance ratio involves constants for the probability given a Gaussian centered at the current value or proposal truncated on the unit interval \\[\\frac{q(x^{\\text{cur}\\hphantom{c}} \\mid x^{\\text{prop}})}{q(x^{\\text{prop}} \\mid x^{\\text{cur}\\hphantom{c}})} = \\frac{\\Phi\\{(1-x^{\\text{cur}})/\\sigma^{\\text{prop}}\\} - \\Phi(-x^{\\text{cur}}/\\sigma^{\\text{prop}})}{\\Phi\\{(1-x^{\\text{prop}})/\\sigma^{\\text{prop}}\\} - \\Phi(-x^{\\text{prop}}/\\sigma^{\\text{prop}})}.\\]\nThis exercise was inspired by this blog post by Darren Wilkinson.\n\nlog_f &lt;- function(par){\n  dbeta(x = par, shape1 = 0.5, shape2 = 0.5, log = TRUE)\n}\nmetropo_fixed &lt;- function(B, sd_prop = 0.2){\n  chain &lt;- rep(0, B)\n  # Draw initial value\n  cur &lt;- runif(1)\n  for(b in seq_len(B)){\n    repeat {\n        # Simulate proposal from Gaussian random walk proposal\n        prop &lt;- cur + rnorm(1, sd = sd_prop)\n        # check admissibility for probability of success\n        if (prop &gt;= 0 & prop &lt;= 1)\n          break\n    }\n    # Compute (log) acceptance ratio\n    logR &lt;- log_f(prop) - log_f(cur) + \n      log(pnorm(1, mean = cur, sd = sd_prop) - pnorm(0, mean = cur, sd = sd_prop)) -\n      log(pnorm(1, mean = prop, sd = sd_prop) - pnorm(0, mean = prop, sd = sd_prop))\n    # Accept the move if R &gt; u\n    if(isTRUE(logR &gt; log(runif(1)))){\n     cur &lt;- prop \n    }\n    chain[b] &lt;- cur\n  }\n  return(chain)\n}\n# Run MCMC for 10K iterations\nmc2 &lt;- metropo_fixed(1e4L)\n\n\n\n\n\n\n\n\n\nFigure 1: Comparison of histogram for 10K draws from the incorrect sampler (left) and the correct sampler (right).",
    "crumbs": [
      "Exercises",
      "Solutions",
      "4. Monte Carlo methods"
    ]
  },
  {
    "objectID": "exercises/03-solution.html",
    "href": "exercises/03-solution.html",
    "title": "Solution 3",
    "section": "",
    "text": "Consider a simple random sample of size \\(n\\) from the Wald distribution, with density \\[\\begin{align*}\nf(y; \\nu, \\lambda) = \\left(\\frac{\\lambda}{2\\pi y^{3}}\\right)^{1/2} \\exp\\left\\{ - \\frac{\\lambda (y-\\nu)^2}{2\\nu^2y}\\right\\}\\mathrm{I}(y &gt; 0)\n\\end{align*}\\] for location \\(\\nu &gt;0\\) and shape \\(\\tau&gt;0\\).\n\nShow that the joint prior \\[ p(\\lambda) \\sim \\mathsf{gamma}(\\alpha, \\beta), \\quad p(1/\\nu \\mid \\lambda) \\sim  \\mathsf{Gauss}(\\mu, \\tau^{-1}\\lambda^{-1}),\\] the product of a gamma and a reciprocal Gaussian, is conjugate for the Wald distribution parameters.\nDerive the parameters of the posterior distribution and provide an interpretation of the prior parameters. Hint: write down the posterior parameters as a weighted average of data-dependent quantities and prior parameters.\nDerive the marginal posterior \\(p(\\lambda)\\).\n\n\nSolution. \n\nTo show conjugacy, we must prove that the posterior is of the same family. Multiplying the likelihood with the joint prior and expanding the squares in the exponential terms, we get \\[\\begin{align*}\np(\\lambda, \\nu \\mid \\boldsymbol{y}) &\\propto \\frac{\\lambda^{(n+1)/2+\\alpha-1}}{\\nu^2}\\exp(-\\lambda \\beta) \\exp\\left[ -\\frac{\\lambda}{2}\\left\\{\\frac{\\tau}{\\nu^{2}}-2\\frac{\\tau\\mu}{\\nu} + \\tau\\mu^2 +\\frac{t_1(\\boldsymbol{y})}{\\nu^2} -  \\frac{2n}{\\nu} + t_2(\\boldsymbol{y})\\right\\}\\right] \\\\& \\propto \\frac{\\lambda^{(n+1)/2+\\alpha-1}}{\\nu^2}\\exp(-\\lambda \\beta) \\exp\\left[ -\\frac{\\lambda}{2}\\left\\{\\frac{\\tau + t_1(\\boldsymbol{y})}{\\nu^2} - 2\\frac{\\tau\\mu+n}{\\nu} + \\tau\\mu^2 + t_2(\\boldsymbol{y})\\right\\} \\right]\n\\\\& \\propto \\frac{\\lambda^{(n+1)/2+\\alpha-1}}{\\nu^2}\\exp\\left[-\\lambda \\left\\{\\beta + \\frac{c_3-c_1c_2^2}{2}\\right\\}\\right] \\exp\\left\\{ -\\frac{\\lambda c_1}{2}\\left(\\nu^{-1} - c_2\\right)^2\\right\\}\n\\end{align*}\\] where \\(c_1=\\{\\tau + t_1(\\boldsymbol{y})\\}\\), \\(c_2 =(\\tau\\mu+n)/c_1\\) and \\(c_3 =\\tau\\mu^2 + t_2(\\boldsymbol{y})\\).\nWe see that the joint posterior as the product of two densities, say \\(q(\\lambda \\mid \\boldsymbol{y})p(1/\\nu \\mid \\lambda)\\); \\(q(\\lambda \\mid \\boldsymbol{y})\\) is the density of a gamma distribution with shape \\(a = (n+1)/2+\\alpha\\) and rate \\(b=\\beta + (c_3-c_1c_2^2)/2\\), whereas the other is a reciprocal Gaussian with mean parameter \\(c_2\\) and precision \\(\\lambda c_1\\). \\(\\mathsf{gamma}\\left\\{(n+1)/2+\\alpha\\right\\}\\)\nTo get the marginal \\(p(\\lambda \\mid \\boldsymbol{y})\\), we need to integrate with respect to \\(\\nu\\). Making the change of variable \\(\\mu = 1/\\nu\\), we recover a Gaussian kernel \\[\\begin{align*}\np(\\lambda \\mid \\boldsymbol{y}) &= \\lambda^{a-1}\\exp(-b\\lambda)\\int_{\\mathbb{R}}\\exp\\left\\{ -\\frac{\\lambda c_1}{2}\\left(\\mu - c_2\\right)^2\\right\\}  \\mathrm{d} \\mu\n\\\\&\\propto \\lambda^{a-1}\\exp(-b\\lambda) \\lambda^{-1/2}\n\\end{align*}\\] so we conclude that, marginally, \\(\\lambda \\sim \\mathsf{gamma}(n+ \\alpha, b)\\).",
    "crumbs": [
      "Exercises",
      "Solutions",
      "3. Priors"
    ]
  },
  {
    "objectID": "exercises/03-solution.html#exercise-3.1",
    "href": "exercises/03-solution.html#exercise-3.1",
    "title": "Solution 3",
    "section": "",
    "text": "Consider a simple random sample of size \\(n\\) from the Wald distribution, with density \\[\\begin{align*}\nf(y; \\nu, \\lambda) = \\left(\\frac{\\lambda}{2\\pi y^{3}}\\right)^{1/2} \\exp\\left\\{ - \\frac{\\lambda (y-\\nu)^2}{2\\nu^2y}\\right\\}\\mathrm{I}(y &gt; 0)\n\\end{align*}\\] for location \\(\\nu &gt;0\\) and shape \\(\\tau&gt;0\\).\n\nShow that the joint prior \\[ p(\\lambda) \\sim \\mathsf{gamma}(\\alpha, \\beta), \\quad p(1/\\nu \\mid \\lambda) \\sim  \\mathsf{Gauss}(\\mu, \\tau^{-1}\\lambda^{-1}),\\] the product of a gamma and a reciprocal Gaussian, is conjugate for the Wald distribution parameters.\nDerive the parameters of the posterior distribution and provide an interpretation of the prior parameters. Hint: write down the posterior parameters as a weighted average of data-dependent quantities and prior parameters.\nDerive the marginal posterior \\(p(\\lambda)\\).\n\n\nSolution. \n\nTo show conjugacy, we must prove that the posterior is of the same family. Multiplying the likelihood with the joint prior and expanding the squares in the exponential terms, we get \\[\\begin{align*}\np(\\lambda, \\nu \\mid \\boldsymbol{y}) &\\propto \\frac{\\lambda^{(n+1)/2+\\alpha-1}}{\\nu^2}\\exp(-\\lambda \\beta) \\exp\\left[ -\\frac{\\lambda}{2}\\left\\{\\frac{\\tau}{\\nu^{2}}-2\\frac{\\tau\\mu}{\\nu} + \\tau\\mu^2 +\\frac{t_1(\\boldsymbol{y})}{\\nu^2} -  \\frac{2n}{\\nu} + t_2(\\boldsymbol{y})\\right\\}\\right] \\\\& \\propto \\frac{\\lambda^{(n+1)/2+\\alpha-1}}{\\nu^2}\\exp(-\\lambda \\beta) \\exp\\left[ -\\frac{\\lambda}{2}\\left\\{\\frac{\\tau + t_1(\\boldsymbol{y})}{\\nu^2} - 2\\frac{\\tau\\mu+n}{\\nu} + \\tau\\mu^2 + t_2(\\boldsymbol{y})\\right\\} \\right]\n\\\\& \\propto \\frac{\\lambda^{(n+1)/2+\\alpha-1}}{\\nu^2}\\exp\\left[-\\lambda \\left\\{\\beta + \\frac{c_3-c_1c_2^2}{2}\\right\\}\\right] \\exp\\left\\{ -\\frac{\\lambda c_1}{2}\\left(\\nu^{-1} - c_2\\right)^2\\right\\}\n\\end{align*}\\] where \\(c_1=\\{\\tau + t_1(\\boldsymbol{y})\\}\\), \\(c_2 =(\\tau\\mu+n)/c_1\\) and \\(c_3 =\\tau\\mu^2 + t_2(\\boldsymbol{y})\\).\nWe see that the joint posterior as the product of two densities, say \\(q(\\lambda \\mid \\boldsymbol{y})p(1/\\nu \\mid \\lambda)\\); \\(q(\\lambda \\mid \\boldsymbol{y})\\) is the density of a gamma distribution with shape \\(a = (n+1)/2+\\alpha\\) and rate \\(b=\\beta + (c_3-c_1c_2^2)/2\\), whereas the other is a reciprocal Gaussian with mean parameter \\(c_2\\) and precision \\(\\lambda c_1\\). \\(\\mathsf{gamma}\\left\\{(n+1)/2+\\alpha\\right\\}\\)\nTo get the marginal \\(p(\\lambda \\mid \\boldsymbol{y})\\), we need to integrate with respect to \\(\\nu\\). Making the change of variable \\(\\mu = 1/\\nu\\), we recover a Gaussian kernel \\[\\begin{align*}\np(\\lambda \\mid \\boldsymbol{y}) &= \\lambda^{a-1}\\exp(-b\\lambda)\\int_{\\mathbb{R}}\\exp\\left\\{ -\\frac{\\lambda c_1}{2}\\left(\\mu - c_2\\right)^2\\right\\}  \\mathrm{d} \\mu\n\\\\&\\propto \\lambda^{a-1}\\exp(-b\\lambda) \\lambda^{-1/2}\n\\end{align*}\\] so we conclude that, marginally, \\(\\lambda \\sim \\mathsf{gamma}(n+ \\alpha, b)\\).",
    "crumbs": [
      "Exercises",
      "Solutions",
      "3. Priors"
    ]
  },
  {
    "objectID": "exercises/03-solution.html#exercise-3.2",
    "href": "exercises/03-solution.html#exercise-3.2",
    "title": "Solution 3",
    "section": "Exercise 3.2",
    "text": "Exercise 3.2\nConsider the Rayleigh distribution with scale \\(\\sigma&gt;0\\). It’s density is \\[f(y; \\sigma) = \\frac{y}{\\sigma^2} \\exp\\left(-\\frac{y^2}{2\\sigma^2}\\right)\\mathrm{I}(y \\geq 0).\\]\nDerive the Fisher information matrix and use it to obtain Jeffrey’s prior for \\(\\sigma\\). Determine whether the prior is proper.\n\nSolution. The log likelihood for a sample of size one is \\[\\begin{align*}\n\\ell(\\sigma) = \\log(y) - 2\\log(\\sigma) - \\frac{y^2}{2\\sigma^2}\n\\end{align*}\\] and the negative of the Hessian is \\[\\begin{align*}\n\\jmath(\\sigma) = -\\frac{\\partial^2 \\ell(\\sigma)}{\\partial \\sigma^2} = -\\frac{2}{\\sigma^2} + \\frac{3y^2}{\\sigma^4}\n\\end{align*}\\] To compute the Fisher information, we need the second moment of the Rayleigh distribution, \\[\\begin{align*}\n\\mathsf{E}(Y^2) &= \\int_0^\\infty \\frac{y^3}{\\sigma^2}\\exp\\left(-\\frac{y^2}{2\\sigma^2}\\right)\\mathrm{d} y\\\\&= 2\\sigma^2 \\int_0^\\infty u \\exp(-u) \\mathrm{d} u\n\\\\&= 2\\sigma^2\n\\end{align*}\\] where we made the change of variable \\(u= 0.5y^2\\sigma^{-2}\\), \\(\\mathrm{d} u = y\\sigma^{-2}\\mathrm{d} y\\) and recovered the expected value of a unit exponential distribution.\nThe Fisher information is \\(\\imath(\\sigma) = \\mathsf{E}\\{\\jmath(\\sigma)\\}=-2/\\sigma^2 + 6/\\sigma^2 = 3/\\sigma^2\\). Jeffrey’s prior for the scale, \\(p(\\sigma) =|\\imath(\\sigma)|^{1/2}\\), is proportional to \\(\\sigma^{-1}\\) and thus improper.",
    "crumbs": [
      "Exercises",
      "Solutions",
      "3. Priors"
    ]
  },
  {
    "objectID": "exercises/03-solution.html#exercise-3.3",
    "href": "exercises/03-solution.html#exercise-3.3",
    "title": "Solution 3",
    "section": "Exercise 3.3",
    "text": "Exercise 3.3\nConsider a binomial model with an unknown probability of successes \\(\\theta \\in [0,1]\\) model. Suppose your prior guess for \\(\\theta\\) has mean \\(0.1\\) and standard deviation \\(0.2\\)\nUsing moment matching, return values for the parameters of the conjugate beta prior corresponding to your opinion.\nPlot the resulting beta prior and compare it with a truncated Gaussian distribution on the unit interval with location \\(\\mu=0.1\\) and scale \\(\\sigma=0.2\\).1\n\nSolution. The beta distribution has expected value \\(\\alpha/(\\alpha+\\beta)\\) and variance \\(\\alpha\\beta(\\alpha+\\beta)^{-2}(\\alpha+\\beta+1)^{-1}\\).\nSince the system of equations is nonlinear, we need to solve numerically to find the two unknown value of the parameters or else simply substitute \\(\\beta = \\alpha (1-\\mu)/\\mu\\) in the equation for the variance.\n\nbeta_moments &lt;- function(par, mean, variance){\n  alpha &lt;- par[1]\n  beta &lt;- par[2]\n  c(alpha/(alpha+beta) - mean,\n    alpha*beta/(alpha+beta)^2/(alpha+beta+1) - variance)\n}\n# Numerical root finding algorithm\n# We need to give good starting values\nrootSolve::multiroot(f = beta_moments,\n                     start = c(0.1, 0.8),\n                     positive = TRUE,\n                     mean = 0.1, \n                     variance = 0.04)\n\n$root\n[1] 0.125 1.125\n\n$f.root\n[1] 5.504125e-12 4.298423e-12\n\n$iter\n[1] 5\n\n$estim.precis\n[1] 4.901274e-12\n\nalpha &lt;- uniroot(f = function(alpha, mean = 0.1, variance = 0.04){\n  beta &lt;- alpha*(1-mean)/mean\n  alpha*beta/(alpha+beta)^2/(alpha+beta+1) - variance}, \n  interval = c(1e-4, 1))$root\nbeta &lt;- alpha*(1-0.1)/0.1\nc(alpha = alpha, beta = beta)\n\nalpha  beta \n0.125 1.125 \n\n\nand we find \\(\\alpha = 0.125\\) and \\(\\beta=1.125\\).\nLet \\(a = -\\mu/\\sigma\\) and \\(b = (1-\\mu)/\\sigma\\) denote the standardized lower and upper bounds, respectively. The density of the truncated Gaussian with location \\(\\mu\\) and scale \\(\\sigma\\) on the unit interval is \\[\\begin{align*}\nf(x; \\mu, \\sigma) = \\frac{1}{\\sigma}\\frac{\\phi\\left(\\frac{x - \\mu}{\\sigma}\\right)}{\\Phi(b) - \\Phi(a)},\n\\end{align*}\\] where \\(\\phi\\) is the density of a standard Gaussian \\(\\mathsf{Gauss}(0,1)\\) and \\(\\Phi\\) the corresponding distribution function.\n\n\n\n\n\n\n\n\n\nFigure 1: Beta (full line) and truncated Gaussian (dashed line) prior densities.\n\n\n\n\n\nThe beta distribution, while matching the moments, is implying very low chance of success with a mode at zero. By contrast, the truncated Gaussian (which does not have mean \\(\\mu\\) and variance \\(\\sigma^2\\)) has the mode at \\(\\mu=0.1\\). Which one is preferable depends on the context; we could also match the parameters of the truncated Gaussian.",
    "crumbs": [
      "Exercises",
      "Solutions",
      "3. Priors"
    ]
  },
  {
    "objectID": "exercises/03-solution.html#footnotes",
    "href": "exercises/03-solution.html#footnotes",
    "title": "Solution 3",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote that the parameters of the truncated Gaussian distribution do not correspond to moments!↩︎",
    "crumbs": [
      "Exercises",
      "Solutions",
      "3. Priors"
    ]
  },
  {
    "objectID": "exercises/02-solution.html",
    "href": "exercises/02-solution.html",
    "title": "Solution 2",
    "section": "",
    "text": "You consider the waiting times between buses coming to HEC. Your bus line has frequent buses, but you decide to check the frequency. From your prior experience, you know that measured waiting times range between 3 and 15 minutes. You collect data over the two first week of classes and get an average of 8 minutes based on 10 observations.\nFor modelling, we consider data to arise an independent and identically distributed sample from an exponential distribution with rate \\(\\lambda&gt;0,\\) with associated density \\(f(x) = \\lambda \\exp(-\\lambda x).\\)",
    "crumbs": [
      "Exercises",
      "Solutions",
      "2. Bayesics"
    ]
  },
  {
    "objectID": "exercises/02-solution.html#exercise-2.1",
    "href": "exercises/02-solution.html#exercise-2.1",
    "title": "Solution 2",
    "section": "Exercise 2.1",
    "text": "Exercise 2.1\nCompute the marginal likelihood when the prior for \\(\\lambda\\) is\n\nan exponential distribution with rate \\(\\kappa&gt;0,\\) with prior density \\(p(\\lambda) = \\kappa \\exp(-\\lambda\\kappa)\\);\nsame, but truncated above at 1, so the density is \\(p(\\lambda) = \\kappa \\exp(-\\lambda\\kappa)\\mathrm{I}\\{\\lambda \\leq 1\\}\\); the indicator function \\(\\mathrm{I}(\\cdot)\\) equals one if the condition is true and zero otherwise.\n\\(\\lambda \\sim \\mathsf{Ga}(\\alpha, \\beta),\\) a gamma distribution with shape \\(\\alpha&gt;0\\) and rate \\(\\beta&gt;0,\\) with prior density \\(p(\\lambda) = \\beta^\\alpha\\lambda^{\\alpha-1}\\exp(-\\beta \\lambda)/\\Gamma(\\alpha).\\)\n\nDeduce that, in all cases above and up to truncation, the posterior distribution is a gamma distribution.\n\nSolution. The likelihood is \\[\\begin{align*}\nL(\\lambda) = \\prod_{i=1}^n \\lambda \\exp(-\\lambda y_i) = \\lambda^n \\exp(-\\lambda n\\overline{y}),\n\\end{align*}\\] where \\(\\overline{y}=8\\) is the sample mean and \\(n=10\\) the number of observations.\nThe exponential distribution is a special case of the gamma, where \\(\\lambda \\sim \\mathsf{Exp}(\\kappa) \\equiv \\mathsf{Ga}(1, \\kappa).\\)\nThe posterior densities are equal, up to proportionality, to \\[\\begin{align*}\np_1(\\lambda \\mid y) &\\propto\\lambda^{n}\\exp\\{-(n\\overline{y}+\\kappa)\\lambda\\} \\\\\np_2(\\lambda \\mid y) &\\propto\\lambda^{n}\\exp\\{-(n\\overline{y}+\\kappa)\\lambda\\}\\mathrm{I}\\{\\lambda \\geq 1\\} \\\\\np_3(\\lambda \\mid y) &\\propto\\lambda^{n+\\alpha-1}\\exp\\{-(n\\overline{y}+\\beta)\\lambda\\}\n\\end{align*}\\] so these are \\(\\mathsf{Ga}(n+1, n\\overline{y} + \\kappa),\\) \\(\\mathsf{Ga}(n+1, n\\overline{y} + \\kappa)\\) truncated over \\([0,1]\\) and \\(\\mathsf{Ga}(n+\\alpha, n\\overline{y} + \\beta).\\)\nLet \\(\\Gamma(\\cdot)\\) denote the gamma function and \\(\\gamma(a, x)\\) the lower incomplete gamma function, \\(\\gamma(a, x= \\int_0^x t^{a-1}\\exp(-t) \\mathrm{d} t.\\) The marginal likelihood can be obtained either by integrating the product of the likelihood and prior, or upon noting that\n\\[\\begin{align*}\np_i(\\boldsymbol{y}) = \\frac{L(\\lambda) p_i(\\lambda)}{p_i(\\lambda \\mid \\boldsymbol{y})}\n\\end{align*}\\] so we get \\[\\begin{align*}\np_1(\\boldsymbol{y}) &= \\kappa n!(n\\overline{y}+\\kappa)^{-(n+1)},\\\\\np_2(\\boldsymbol{y}) &= p_1(\\boldsymbol{y}) \\times \\gamma\\{n+1, (n\\overline{y}+\\kappa)\\}, \\\\\np_3(\\boldsymbol{y}) &= \\frac{\\Gamma(n + \\alpha)\\beta^\\alpha}{\\Gamma(\\alpha)(n\\overline{y} + \\beta)^{n+\\alpha}}.\n\\end{align*}\\]",
    "crumbs": [
      "Exercises",
      "Solutions",
      "2. Bayesics"
    ]
  },
  {
    "objectID": "exercises/02-solution.html#exercise-2.2",
    "href": "exercises/02-solution.html#exercise-2.2",
    "title": "Solution 2",
    "section": "Exercise 2.2",
    "text": "Exercise 2.2\n\n\n\n\n\n\n\n\n\n\n\nConsider the following priors for the reciprocal expected waiting time, \\(\\lambda.\\)\n\na gamma with rate \\(\\beta=100\\) and shape \\(\\alpha = 10\\)\nan exponential with rate \\(5\\)\na uniform prior on the unit interval \\([5,10]\\) for \\(1/\\lambda\\)\n\nAssociate each plot of the posterior with each of the priors. Which one seems most suitable for modelling?\nExplain what would happen to the posterior curve if we increased the sample size.\n\n\n\n\n\n\n\n\nFigure 1: Posteriors (full) and scaled likelihood (dashed) for exponential data, with different priors. The dashed vertical line indicates the maximum likelihood estimator.\n\n\n\n\n\n\nSolution. As the sample size increase, the curve becomes more concentrated around the maximum a posteriori value, which approaches the maximum likelihood estimate, \\(\\widehat{\\lambda}=1/8,\\) regardless of the prior function (if it is untruncated).\nThe mode of a gamma distribution with rate \\(\\beta\\) and shape \\(\\alpha\\) is \\((\\alpha-1)/\\beta\\) for \\(\\alpha&gt;1.\\)\nThe truncated distribution (bottom left) is clearly identified from the “stubborn” prior, which is \\(p(\\lambda) \\propto \\mathrm{I}(1/10 &lt; \\lambda &lt; 1/5)/\\lambda^2,\\) so 3C. Prior 1 has an average of 1/10 (less than the MLE) and provides nearly as much information as the data, so it is the more peaked posterior, so 1B. The exponential, or \\(\\mathsf{Ga}(1,5),\\) is much less informative than the likelihood and posterior should be only slightly different for the other, so 2A.",
    "crumbs": [
      "Exercises",
      "Solutions",
      "2. Bayesics"
    ]
  },
  {
    "objectID": "exercises/02-solution.html#exercice-2.3",
    "href": "exercises/02-solution.html#exercice-2.3",
    "title": "Solution 2",
    "section": "Exercice 2.3",
    "text": "Exercice 2.3\nThe purpose of this exercise is to show that even one-dimensional numerical integration requires some care. Consider a half Cauchy prior over the positive half line, with density \\[f(x) = 2\\pi^{-1}(1+x^2)^{-1}\\mathrm{I}(x \\geq 0).\\] Using a grid approximation in increments of 0.01, evaluate the unnormalized posterior density from 0 until 30 minutes\\(^{-1}.\\) Compare this approximation with that of quadrature methods via integrate and return the corresponding estimates of the normalizing constant. Indication: check the values and make sure the output is sensical. Modify the integrand if necessary.\nPlot the posterior distribution of \\(\\omega = 1/\\lambda,\\) the average waiting time.\n\nSolution. For an unnormalized density \\(g(x)\\) such that \\(\\int g(x) \\mathrm{d} x = c,\\) the normalizing constant is \\(1/c.\\)\nFirst, remember that the density function of the scale \\(\\omega = \\lambda^{-1}\\) is related to the one of the rate \\(\\lambda\\) through a change of variable, with Jacobian \\(\\omega^{-2}.\\)\n\n# Likelihood function - NOTE FORMULATION TO AVOID NUMERICAL OVERFLOW\nlik &lt;- function(x, n = 10, ybar = 8){exp(n*(log(x)-ybar*x))}\n# Density of Cauchy over positive real line\ndfoldedCauchy &lt;- function(x){2/pi/(1+x^2)}\n# Check integral\nintegrate(dfoldedCauchy, lower = 0, upper = Inf)\n\n1 with absolute error &lt; 1.6e-10\n\n# Unormalized posterior\nunnorm_post &lt;- function(x){dfoldedCauchy(x)*lik(x)}\n(icst_lambda &lt;- integrate(f = unnorm_post, 0, 100))\n\n7.074775e-15 with absolute error &lt; 1.4e-14\n\n# Check that the normalized value gives integral of 1\ncst_test &lt;- integrate(f = function(x){unnorm_post(x)/icst_lambda$value}, \n                      lower = 0,\n                      upper = 100)\n\nOuch! The integral is nearly zero, and there is significant risk of numerical underflow and the reciprocal of the integrals are one order of magnitude apart, even when the sample size is not large. The normalizing constant, the reciprocal of the marginal likelihood, is not well estimated. The absolute error is of higher order than the estimate of the marginal likelihood, and this will be more problematic in higher dimensions.\nTo palliate to this, we could slightly modify the integrand by scaling the likelihood by \\((n\\overline{y} )^{n+1}/n!,\\) the normalizing constant of the gamma integral, which is around \\(2.4 \\times 10^{14}.\\) This fixes the issue below.\n\n# Scale likelihood by using gamma distribution normalizing constant\nslik &lt;- function(x, n = 10, ybar = 8){\n  exp(-lgamma(n+1) + (n+1)*log(n*ybar) + n*(log(x)-ybar*x))\n}\n# Unnormalized posterior, version 2\nunnorm_post2 &lt;- function(x){dfoldedCauchy(x)*slik(x)}\n# Define grid and evaluate product\ngrid &lt;- seq(from = 0, to = 30, by = 0.01)\nmarglik_grid &lt;- sum(unnorm_post2(grid))*0.01\n# Is the grid approximation good enough?\n# check equality to numerical tolerance\nall.equal(integrate(f = unnorm_post2, 0, 100)$value, marglik_grid)\n\n[1] TRUE\n\nnorm_cst &lt;- 1/marglik_grid\n\nThe prior normalizing by a known constant fixes the numerical issues. Generally, one would tend to build an approximation only at the mode and match the curvature of the posterior there (using, e.g., a quadratic approximation to the posterior density).\nFor the posterior density, we can simply use the approximation with \\(p(\\lambda \\mid \\boldsymbol{y}) \\approx \\widehat{c} L(\\lambda)p(\\lambda).\\) The posterior density for the reciprocal rate is \\(p(\\omega \\mid \\boldsymbol{y}) \\approx \\widehat{c} L(\\omega^{-1})p(\\omega^{-1})\\omega^{-2}\\) (don’t forget the Jacobian)!\n\n\nCode\nlibrary(ggplot2)\nggplot() + \n  stat_function(fun = function(x){unnorm_post2(1/x)*norm_cst/x^2},\n                xlim = c(0, 30),\n                n = 1001) +\n  labs(y = \"\", \n       x = expression(paste(\"average waiting time \", 1/lambda, \" (in minutes)\")),\n       subtitle = \"posterior density\") + \n  scale_y_continuous(limits = c(0, NA), expand = expansion(mult = c(0, .1))) +\n  theme_classic()",
    "crumbs": [
      "Exercises",
      "Solutions",
      "2. Bayesics"
    ]
  },
  {
    "objectID": "exercises/02-solution.html#exercice-2.4",
    "href": "exercises/02-solution.html#exercice-2.4",
    "title": "Solution 2",
    "section": "Exercice 2.4",
    "text": "Exercice 2.4\nConsider \\(\\lambda \\sim \\mathsf{Ga}(\\alpha = 1.4, \\beta=0.2).\\)\n\nReturn the posterior mean, posterior median and maximum a posteriori (MAP).\nReturn the 89% equitailed percentile credible interval.\nReturn the 50% highest posterior density (HPD) interval (harder).\n\nNext, draw 1000 observations from the posterior predictive distribution and plot a histogram of the latter. Compare it to the exponential distribution of observations.\nWould the posterior predictive change if you gathered more data? Justify your answer and explain how it would change, if at all.\n\nSolution. We have already determined that the posterior is a Gamma distribution \\(\\mathsf{Ga}(a, b),\\) where \\(a= \\alpha+ n= 11.4\\) and \\(b=n\\overline{y} + \\beta = 80.2.\\) We can query the moments directly: the mode is \\((a-1)/b\\) and the mean \\(a/b,\\) while the median must be found numerically using the quantile function.\n\na &lt;- 11.4 # shape parameter\nb &lt;- 80.2 # rate parameter\nalpha &lt;- 0.11 # level\npostmean &lt;- a/b # posterior mean\npostmed &lt;- qgamma(p = 0.5, shape = a, rate = b) # median\npostmode &lt;- (a-1)/b # mode\ncredint &lt;- qgamma(p = c(alpha/2, 1-alpha/2), shape = a, rate = b)\n# Documentation states you must return the quantile function\nHDInterval::hdi(\n    object = qgamma, \n    shape = a, \n    rate = b, \n    credMass = 0.50)\n\n    lower     upper \n0.1042228 0.1589696 \nattr(,\"credMass\")\n[1] 0.5\n\n# Alternatively, find this numerically\n# MAP via minimization of the negative log likelihood\nMAP &lt;- optimize(\n  f = function(x){-dgamma(x, shape = a, rate = b, log = TRUE)},\n  interval = qgamma(p = c(0.2,0.8), shape = a, rate = b)\n  )$minimum\n# Other quantities approximated by Monte Carlo\n# Sample from posterior\npost_samp &lt;- rgamma(n = 1e4, shape = a, rate = b)\n# Sample mean and sample quantiles\nmean(post_samp)\n\n[1] 0.1422132\n\nquantile(post_samp, c(alpha/2, 0.5, 1-alpha/2))\n\n      5.5%        50%      94.5% \n0.08286817 0.13834515 0.21530067 \n\n# Highest posterior density interval\ncredHDI &lt;- HDInterval::hdi(\n  object = post_samp, \n  credMass = 0.50)\ncredHDI\n\n    lower     upper \n0.1061453 0.1597930 \nattr(,\"credMass\")\n[1] 0.5\n\n\nUp to three significant digits, the posterior mean is 0.142, the median is 0.138 and the mode 0.13. The bounds of the equitailed 89% credible interval are [0.082, 0.215], those of the 50% HDPI [0.1061453, 0.159793].\nFor the posterior predictive, we simply take the samples from the posterior, post_samp, and generate for each rate a new exponential\n\n\nCode\npostpred_samp &lt;- rexp(n = 1000, rate = post_samp[seq_len(1000)])\nggplot(data = data.frame(x = postpred_samp))+\n  geom_histogram(aes(x = x, y = ..density..)) + \n  # the likelihood is proportional to a gamma\n  stat_function(fun = dexp,  \n                n = 1001, \n                args = list(rate = 1/8) # mle is average\n                ) +\n  labs(x = \"waiting time (in minutes)\", \n       y = \"\") +\n  scale_x_continuous(limits = c(0, NA), expand = expansion(mult = c(0, .1))) +\n  scale_y_continuous(limits = c(0, NA), expand = expansion(mult = c(0, .1))) +\n  theme_classic()\n\n\n\n\n\n\n\n\nFigure 2: Histogram of posterior predictive draws and density function of observations.",
    "crumbs": [
      "Exercises",
      "Solutions",
      "2. Bayesics"
    ]
  },
  {
    "objectID": "exercises/01-solution.html",
    "href": "exercises/01-solution.html",
    "title": "Solution 1",
    "section": "",
    "text": "Linear mixed effect regression model specifies that response vectors for individual \\(i\\), \\(\\boldsymbol{Y}_i \\in \\mathbb{R}^k\\), are Gaussian. The model includes model matrix \\(\\mathbf{X}_i\\) with fixed effect coefficients \\(\\boldsymbol{\\beta}\\), and another \\(k\\times l\\) model matrix \\(\\mathbf{Z}_i\\) with random effects. The hierarchical formulation of the model is \\[\\begin{align*}\n\\boldsymbol{Y}_i \\mid \\mathcal{B}_i=\\boldsymbol{b}_i &\\sim \\mathsf{Gauss}_k(\\mathbf{X}_i\\boldsymbol{\\beta} + \\mathbf{Z}_i\\boldsymbol{b}_i, \\sigma^2 \\mathbf{I}_k) \\\\\n\\mathcal{B}_i & \\sim \\mathsf{Gauss}_l(\\boldsymbol{0}_k, \\boldsymbol{\\Omega})\n\\end{align*}\\]\n\nUsing the tower property, derive the marginal mean and covariance matrix of \\(\\boldsymbol{Y}_i\\)\nHence obtain the parameters of the joint distribution of \\((\\boldsymbol{Y}_i^\\top, \\mathcal{B}_i^\\top)^\\top.\\)\n\n\nSolution. Using the law of iterated expectation and variance\n\\[\\begin{align*}\n\\mathsf{E}_{\\boldsymbol{Y}_i}(\\boldsymbol{Y}_i) & =\\mathsf{E}_{\\mathcal{B}_i}\\left\\{\\mathsf{E}_{\\boldsymbol{Y}_i \\mid \\mathcal{B}_i}(\\boldsymbol{Y}_i)\\right\\} \\\\&=  \\mathsf{E}_{\\mathcal{B}_i}(\\mathbf{X}_i\\boldsymbol{\\beta} + \\mathbf{Z}_i\\mathcal{B}_i) \\\\&= \\mathbf{X}_i\\boldsymbol{\\beta}\n\\end{align*}\\]\n\\[\\begin{align*}\n\\mathsf{Va}_{\\boldsymbol{Y}_i}(\\boldsymbol{Y}_i) & =\\mathsf{Va}_{\\mathcal{B}_i}\\left\\{\\mathsf{E}_{\\boldsymbol{Y}_i \\mid \\mathcal{B}_i}(\\boldsymbol{Y}_i)\\right\\} + \\mathsf{E}_{\\mathcal{B}_i}\\left\\{\\mathsf{Va}_{\\boldsymbol{Y}_i \\mid \\mathcal{B}_i}(\\boldsymbol{Y}_i)\\right\\} \\\\&=  \\mathsf{Va}_{\\mathcal{B}_i}(\\mathbf{X}_i\\boldsymbol{\\beta} + \\mathbf{Z}_i\\mathcal{B}_i) +\\mathsf{E}_{\\mathcal{B}_i}(\\sigma^2\\mathbf{I}_k) \\\\&= \\mathbf{Z}_i\\boldsymbol{\\Omega}\\boldsymbol{Z}_i^\\top + \\sigma^2\\mathbf{I}_k.\n\\end{align*}\\]\nSince the conditional and marginal are Gaussian, and the product of their density functions is also \\(\\exp(-\\cdot)\\), with \\(\\cdot\\) quadratic in \\(\\boldsymbol{Y}_i\\) and \\(\\mathcal{B}_i\\), it must be multivariate Gaussian. As the latter is fully characterized by the mean and variance, it suffices to derive the covariance between \\(\\boldsymbol{Y}_i\\) and \\(\\mathcal{B}_i\\), which is the only missing piece of information. The latter is by definition\n\\[\\begin{align*}\n\\mathsf{Co}(\\boldsymbol{Y}_i,\\mathcal{B}_i) & = \\mathsf{E}_{\\boldsymbol{Y}_i,\\mathcal{B}_i}\\left[\\left\\{\\boldsymbol{Y}_i - \\mathsf{E}_{\\boldsymbol{Y}_i}(\\boldsymbol{Y}_i)\\right\\}\\left\\{\\mathcal{B}_i - \\mathsf{E}_{\\mathcal{B}_i}(\\mathcal{B}_i)\\right\\}^\\top\\right]\n\\\\&= \\mathsf{E}_{\\boldsymbol{Y}_i,\\mathcal{B}_i}\\{(\\boldsymbol{Y}_i - \\mathbf{X}_i\\boldsymbol{\\beta})\\mathcal{B}_i^\\top\\}\n\\\\&= \\mathsf{E}_{\\mathcal{B}_i}\\left[\\mathsf{E}_{\\boldsymbol{Y}_i \\mid \\mathcal{B}_i}\\{(\\boldsymbol{Y}_i - \\mathbf{X}_i\\boldsymbol{\\beta})\\mathcal{B}_i^\\top\\}\\right]\n\\\\&= \\mathbf{Z}_i\\mathsf{E}_{\\mathcal{B}_i}(\\mathcal{B}_i\\mathcal{B}_i^\\top)\n\\\\&=\\mathbf{Z}_i\\boldsymbol{\\Omega}\n\\end{align*}\\]\nand so we find \\[\\begin{align*}\n\\begin{pmatrix}\\boldsymbol{Y}_i \\\\ \\mathcal{B}_i\n\\end{pmatrix}\\sim \\mathsf{Gauss}_{k+l} \\left\\{ \\begin{pmatrix} \\mathbf{X}_i \\boldsymbol{\\beta} \\\\ \\boldsymbol{0}_l \\end{pmatrix}, \\begin{pmatrix} \\mathbf{Z}_i\\boldsymbol{\\Omega}\\boldsymbol{Z}_i^\\top + \\sigma^2\\mathbf{I}_k & \\mathbf{Z}_i\\boldsymbol{\\Omega} \\\\ \\boldsymbol{\\Omega}\\mathbf{Z}_i^\\top & \\boldsymbol{\\Omega}\\end{pmatrix}\\right\\}.\n\\end{align*}\\]",
    "crumbs": [
      "Exercises",
      "Solutions",
      "1. Introduction"
    ]
  },
  {
    "objectID": "exercises/01-solution.html#exercise-1.1",
    "href": "exercises/01-solution.html#exercise-1.1",
    "title": "Solution 1",
    "section": "",
    "text": "Linear mixed effect regression model specifies that response vectors for individual \\(i\\), \\(\\boldsymbol{Y}_i \\in \\mathbb{R}^k\\), are Gaussian. The model includes model matrix \\(\\mathbf{X}_i\\) with fixed effect coefficients \\(\\boldsymbol{\\beta}\\), and another \\(k\\times l\\) model matrix \\(\\mathbf{Z}_i\\) with random effects. The hierarchical formulation of the model is \\[\\begin{align*}\n\\boldsymbol{Y}_i \\mid \\mathcal{B}_i=\\boldsymbol{b}_i &\\sim \\mathsf{Gauss}_k(\\mathbf{X}_i\\boldsymbol{\\beta} + \\mathbf{Z}_i\\boldsymbol{b}_i, \\sigma^2 \\mathbf{I}_k) \\\\\n\\mathcal{B}_i & \\sim \\mathsf{Gauss}_l(\\boldsymbol{0}_k, \\boldsymbol{\\Omega})\n\\end{align*}\\]\n\nUsing the tower property, derive the marginal mean and covariance matrix of \\(\\boldsymbol{Y}_i\\)\nHence obtain the parameters of the joint distribution of \\((\\boldsymbol{Y}_i^\\top, \\mathcal{B}_i^\\top)^\\top.\\)\n\n\nSolution. Using the law of iterated expectation and variance\n\\[\\begin{align*}\n\\mathsf{E}_{\\boldsymbol{Y}_i}(\\boldsymbol{Y}_i) & =\\mathsf{E}_{\\mathcal{B}_i}\\left\\{\\mathsf{E}_{\\boldsymbol{Y}_i \\mid \\mathcal{B}_i}(\\boldsymbol{Y}_i)\\right\\} \\\\&=  \\mathsf{E}_{\\mathcal{B}_i}(\\mathbf{X}_i\\boldsymbol{\\beta} + \\mathbf{Z}_i\\mathcal{B}_i) \\\\&= \\mathbf{X}_i\\boldsymbol{\\beta}\n\\end{align*}\\]\n\\[\\begin{align*}\n\\mathsf{Va}_{\\boldsymbol{Y}_i}(\\boldsymbol{Y}_i) & =\\mathsf{Va}_{\\mathcal{B}_i}\\left\\{\\mathsf{E}_{\\boldsymbol{Y}_i \\mid \\mathcal{B}_i}(\\boldsymbol{Y}_i)\\right\\} + \\mathsf{E}_{\\mathcal{B}_i}\\left\\{\\mathsf{Va}_{\\boldsymbol{Y}_i \\mid \\mathcal{B}_i}(\\boldsymbol{Y}_i)\\right\\} \\\\&=  \\mathsf{Va}_{\\mathcal{B}_i}(\\mathbf{X}_i\\boldsymbol{\\beta} + \\mathbf{Z}_i\\mathcal{B}_i) +\\mathsf{E}_{\\mathcal{B}_i}(\\sigma^2\\mathbf{I}_k) \\\\&= \\mathbf{Z}_i\\boldsymbol{\\Omega}\\boldsymbol{Z}_i^\\top + \\sigma^2\\mathbf{I}_k.\n\\end{align*}\\]\nSince the conditional and marginal are Gaussian, and the product of their density functions is also \\(\\exp(-\\cdot)\\), with \\(\\cdot\\) quadratic in \\(\\boldsymbol{Y}_i\\) and \\(\\mathcal{B}_i\\), it must be multivariate Gaussian. As the latter is fully characterized by the mean and variance, it suffices to derive the covariance between \\(\\boldsymbol{Y}_i\\) and \\(\\mathcal{B}_i\\), which is the only missing piece of information. The latter is by definition\n\\[\\begin{align*}\n\\mathsf{Co}(\\boldsymbol{Y}_i,\\mathcal{B}_i) & = \\mathsf{E}_{\\boldsymbol{Y}_i,\\mathcal{B}_i}\\left[\\left\\{\\boldsymbol{Y}_i - \\mathsf{E}_{\\boldsymbol{Y}_i}(\\boldsymbol{Y}_i)\\right\\}\\left\\{\\mathcal{B}_i - \\mathsf{E}_{\\mathcal{B}_i}(\\mathcal{B}_i)\\right\\}^\\top\\right]\n\\\\&= \\mathsf{E}_{\\boldsymbol{Y}_i,\\mathcal{B}_i}\\{(\\boldsymbol{Y}_i - \\mathbf{X}_i\\boldsymbol{\\beta})\\mathcal{B}_i^\\top\\}\n\\\\&= \\mathsf{E}_{\\mathcal{B}_i}\\left[\\mathsf{E}_{\\boldsymbol{Y}_i \\mid \\mathcal{B}_i}\\{(\\boldsymbol{Y}_i - \\mathbf{X}_i\\boldsymbol{\\beta})\\mathcal{B}_i^\\top\\}\\right]\n\\\\&= \\mathbf{Z}_i\\mathsf{E}_{\\mathcal{B}_i}(\\mathcal{B}_i\\mathcal{B}_i^\\top)\n\\\\&=\\mathbf{Z}_i\\boldsymbol{\\Omega}\n\\end{align*}\\]\nand so we find \\[\\begin{align*}\n\\begin{pmatrix}\\boldsymbol{Y}_i \\\\ \\mathcal{B}_i\n\\end{pmatrix}\\sim \\mathsf{Gauss}_{k+l} \\left\\{ \\begin{pmatrix} \\mathbf{X}_i \\boldsymbol{\\beta} \\\\ \\boldsymbol{0}_l \\end{pmatrix}, \\begin{pmatrix} \\mathbf{Z}_i\\boldsymbol{\\Omega}\\boldsymbol{Z}_i^\\top + \\sigma^2\\mathbf{I}_k & \\mathbf{Z}_i\\boldsymbol{\\Omega} \\\\ \\boldsymbol{\\Omega}\\mathbf{Z}_i^\\top & \\boldsymbol{\\Omega}\\end{pmatrix}\\right\\}.\n\\end{align*}\\]",
    "crumbs": [
      "Exercises",
      "Solutions",
      "1. Introduction"
    ]
  },
  {
    "objectID": "exercises/01-solution.html#exercise-1.2",
    "href": "exercises/01-solution.html#exercise-1.2",
    "title": "Solution 1",
    "section": "Exercise 1.2",
    "text": "Exercise 1.2\nConsider a simple random sample of size \\(n\\) from the Wald distribution, with density \\[\\begin{align*}\nf(y; \\nu, \\lambda) = \\left(\\frac{\\lambda}{2\\pi y^{3}}\\right)^{1/2} \\exp\\left\\{ - \\frac{\\lambda (y-\\nu)^2}{2\\nu^2y}\\right\\}\\mathrm{I}(y &gt; 0)\n\\end{align*}\\] for location \\(\\nu &gt;0\\) and shape \\(\\tau&gt;0.\\) You may take for given that the expected value of the Wald distribution is \\(\\mathsf{E}(Y) = \\nu.\\)\nWrite down the likelihood and show that it can be written in terms of the sufficient statistics \\(\\sum_{i=1}^n y_i\\) and \\(\\sum_{i=1} y_i^{-1}.\\)\n\nSolution. The log likelihood for an independent and identically distributed sample is, up to terms not depending on the parameters, \\[\\begin{align*}\n\\ell(\\nu, \\lambda) \\stackrel{\\nu, \\lambda}{\\propto} \\frac{n}{2} \\ln(\\lambda) -  \\frac{\\lambda}{2\\nu^2} \\sum_{i=1}^n y_i + \\frac{n\\lambda}{\\nu} - \\frac{\\lambda}{2} \\sum_{i=1}^n \\frac{1}{y_i}\n\\end{align*}\\] and we readily see that the model is an exponential family with sufficient statistics \\(t_1(\\boldsymbol{y}) = \\sum_{i=1}^n y_i\\) and \\(t_2(\\boldsymbol{y}) = \\sum_{i=1}^n y_i^{-1}.\\)\nWe derive the score vector and information, \\[\\begin{align*}\nU(\\nu, \\lambda) &= \\begin{pmatrix} \\frac{\\partial \\ell(\\nu, \\lambda)}{\\partial \\nu} \\\\\\frac{\\partial \\ell(\\nu, \\lambda)}{\\partial \\lambda} \\end{pmatrix}\n\\\\&= \\begin{pmatrix}\n\\frac{\\lambda \\sum_{i=1}^n y_i}{\\nu^3} - \\frac{n\\lambda}{\\nu^2} \\\\\n\\frac{n}{2\\lambda} +  \\frac{\\sum_{i=1}^n y_i}{2\\nu^2}  + \\frac{n}{\\nu} - \\frac{\\sum_{i=1}^n y_i^{-1}}{2}\n\\end{pmatrix}\n\\end{align*}\\] and \\[\\begin{align*}\nj(\\nu, \\lambda) &= -\\begin{pmatrix} \\frac{\\partial^2 \\ell(\\nu, \\lambda)}{\\partial \\nu^2} & \\frac{\\partial^2 \\ell(\\nu, \\lambda)}{\\partial \\nu \\partial \\lambda} \\\\ \\frac{\\partial^2 \\ell(\\nu, \\lambda)}{\\partial \\lambda \\partial \\nu } & \\frac{\\partial^2 \\ell(\\nu, \\lambda)}{\\partial \\lambda^2} \\end{pmatrix}\n\\\\&= \\begin{pmatrix}\n\\frac{3\\lambda \\sum_{i=1}^n y_i}{\\nu^4} - \\frac{2n\\lambda}{\\nu^3} & -\\frac{\\sum_{i=1}^n y_i}{\\nu^3} + \\frac{n}{\\nu^2} \\\\\n-\\frac{\\sum_{i=1}^n y_i}{\\nu^3} + \\frac{n}{\\nu^2} &\\frac{n}{2\\lambda^2}\n\\end{pmatrix}\n\\end{align*}\\] To compute the expected information, we need to consider the random counterpart of this and replace values of \\(Y_i\\) by their \\(\\mathsf{E}(Y_i)=\\nu\\), so \\[\\begin{align*}\ni(\\nu, \\lambda) = \\begin{pmatrix}\n\\frac{n\\lambda}{\\nu^3} & 0 \\\\\n0 &\\frac{n}{2\\lambda^2}\n\\end{pmatrix}\n\\end{align*}\\] and the parameters are asymptotically independent.",
    "crumbs": [
      "Exercises",
      "Solutions",
      "1. Introduction"
    ]
  },
  {
    "objectID": "evaluations/weekly-check-in.html",
    "href": "evaluations/weekly-check-in.html",
    "title": "Weekly check-in",
    "section": "",
    "text": "Every week, after you finish working through the content, I want to hear about what you learned and what questions you still have. To facilitate this, and to encourage engagement with the course content, you’ll need to write a small feedback in ZoneCours. This should be ~150 words.\nYou should answer the following three questions each week:\n\nWhat was the most exciting thing you learned from the session? Why?\nWhat was the muddiest thing from the session this week? What are you still wondering about?\nWhich activity did you find the most useful? What could have been skipped?\n\nThe weekly check-in is an occasion for you to ask for clarification, highlight areas or topics for which examples could be added, or list superfluous activities and content. I will grade these before class, answer individually through the feedback form or at the beginning of class.",
    "crumbs": [
      "Evaluations",
      "Weekly check-in"
    ]
  },
  {
    "objectID": "evaluations/02-assignment.html",
    "href": "evaluations/02-assignment.html",
    "title": "Assignment 2",
    "section": "",
    "text": "These problems are for credit and to be handed in on ZoneCours on March 16th at the latest at 23:30.",
    "crumbs": [
      "Evaluations",
      "Assignments",
      "Assignment 2"
    ]
  },
  {
    "objectID": "evaluations/02-assignment.html#problem-2.1",
    "href": "evaluations/02-assignment.html#problem-2.1",
    "title": "Assignment 2",
    "section": "Problem 2.1",
    "text": "Problem 2.1\nThe rats data, extracted from Table 5 of Tarone (1982), contains observations from 70 experiments on animal carcinogenesis bioassay conducted with female F344 rats, recording the number of lung cancer tumors developed. Treating the observations as independent, write \\[\\begin{align*}\ny_i \\mid \\theta_i &\\sim \\mathsf{binom}(n_i, \\theta_i), \\quad i =1, \\ldots, 70 \\\\\n\\theta_i \\mid \\alpha, \\beta & \\sim \\mathsf{beta}(\\alpha, \\beta)\n\\end{align*}\\] with an improper prior \\(p(\\alpha, \\beta) = (\\alpha + \\beta)^{-5/2}\\mathrm{I}(\\alpha&gt;0, \\beta&gt;0).\\)\n\nDerive the conditional distributions of \\(p(\\theta_i \\mid \\alpha, \\beta, \\boldsymbol{y})\\), \\(p(\\alpha \\mid \\beta, \\boldsymbol{\\theta})\\) and \\(p(\\beta \\mid \\alpha, \\boldsymbol{\\theta}).\\)\nImplement a Gibbs sampling algorithm simulating from the conditionals \\(\\boldsymbol{\\theta} \\mid \\cdot,\\) \\(\\alpha \\mid \\cdot\\) and \\(\\beta \\mid \\cdot\\) using one of the following methods: rejection sampling (try an exponential distribution), ratio-of-uniform (Wakefield et al., 1991) via the R package rust, adaptive rejection sampling (Gilks & Wild, 1992; Martino et al., 2018) via the ars R package1 or slice sampling (Neal, 2003).2\nUse instead a sampling algorithm with a Gibbs step for \\(\\boldsymbol{\\theta}\\) and a random walk Metropolis–Hastings step for \\(\\alpha\\) and \\(\\beta\\).\nReparametrize the model in terms of \\(\\log(\\beta)\\) and \\(\\log(\\alpha)/\\log(\\beta)\\) instead and run a Metropolis–Hasting step for the two parameters.\nFor each sampler and parametrization, plot the bivariate histogram/density/scatter plot for \\((\\alpha, \\beta)\\), plus correlograms for both parameters. Comment on the mixing of the algorithms.",
    "crumbs": [
      "Evaluations",
      "Assignments",
      "Assignment 2"
    ]
  },
  {
    "objectID": "evaluations/02-assignment.html#problem-2.2",
    "href": "evaluations/02-assignment.html#problem-2.2",
    "title": "Assignment 2",
    "section": "Problem 2.2",
    "text": "Problem 2.2\nThe purpose of this exercise is to explore different parametrizations and their impact on sampling. The climatechange data contains mean global temperature increases \\(T\\) from the twenty year period 1970–1999 to projections 2069–2098 for different climate general circulation models (GCM), and sometimes multiple simulation runs for each GCM. The purpose of the analysis is to obtain a suitable mean temperature change globally for each representative concentration pathway (RCP, one of 2.6, 4.5, 6.0 and 8.5). The data were obtained from the bang R package and preprocessed to simplify the exposition, but see Northrop & Chandler (2014) for pointers about the methodology.\nThe hierarchical structure for Model A and temperature \\(T\\) for RCP \\(k\\) and GCM \\(l\\) is: \\[\\begin{align*}\nT_{k,l}\\mid  \\boldsymbol{\\alpha}, \\boldsymbol{\\beta}, \\tau &\\sim \\mathsf{Gauss}(\\alpha_k + \\beta_l, \\tau^2)\\\\\n\\boldsymbol{\\alpha} \\mid \\boldsymbol{\\mu}, \\omega &\\sim \\mathsf{Gauss}_4(\\boldsymbol{\\mu}, \\omega^2\\mathbf{I}_4)\\\\\n\\beta_l \\mid \\sigma &\\sim \\mathsf{Gauss}(0, \\sigma^2), \\qquad l = 1, \\ldots, L.\n\\end{align*}\\]\n\nPrior elicitation:\n\nwhat are your prior belief about climate change the range of plausible temperature increases? Write down suitable values for the means \\(\\boldsymbol{\\mu}\\) and the standard deviation \\(\\omega\\) (which could be the same for all RCP) under different emission scenarios, if \\(\\mu_1\\) corresponds to RCP 2.6, \\(\\mu_2\\) to RCP 4.5, etc. and your guesses are non-decreasing.\nchoose suitable priors for the scale parameters \\(\\omega,\\) \\(\\tau\\) and \\(\\sigma\\).\n\nReparametrization: enforce a sum-to-zero hard constraint for \\(\\beta_l\\) (as is done in the Stan code provided below) versus soft-constraint (by reducing the variance and setting the prior to mean zero). Indicate which works better for the problem based on considerations such as mixing and effective sample size.\nFor Model A, produce a caterpillar plot of the parameters \\(\\beta_l\\) (\\(l=1,\\ldots, 38\\)) as follows:\n\nobtain posterior mean for each random effect \\(\\beta_l\\) and sort them in increasing order\nfor each parameter \\(\\beta_l,\\) obtain 80% equitailed credible intervals.\nplot the ordered point estimates and intervals against rank.\n\nModel B: Consider forcing an ordering constraint for \\(\\boldsymbol{\\alpha}\\), so that \\(\\alpha_1 \\leq \\cdots \\leq \\alpha_4.\\) What happens to the posterior?\n\nPlot the marginal posterior density of \\(\\alpha_1, \\ldots, \\alpha_4\\) for the models with and without the ordering constraint and comment.\n\nModel C: keep RCP categorical, but let each emission scenario have it’s own response variance \\(\\omega^2_k,\\) so that \\(\\alpha_k \\sim \\mathsf{Gauss}(\\mu_k, \\omega^2_k)\\) independent.\nModel D: Replace the categorical variables \\(\\boldsymbol{\\alpha}\\) with a linear trend as a function of the value of RCP (i.e., treating the value of RCP as continuous rather than categorical, with \\(\\alpha \\cdot \\mathsf{RCP}\\)).\nCompare Models A to D:\n\nfor each, compute the log likelihood for each posterior draw and use it to obtain the WAIC criterion.\nin addition perform posterior predictive checks for a suitable test function.\n\nFor a chosen adequate model, report the summary statistics of your procedure (posterior means, std. errors, range and effective sample size) for the variance parameters and the mean increase per RCP (or slope).\n\n\nHelper code for Problem 2.2\nI am providing some Stan code (cross-platform) and show how to implement the model in R while defining suitable quantities, by casting the factors RCP and GCM to integer indicators.\n\ndata(climatechange, package = \"hecbayes\")\n# Transform factor name to integer for group assignment\nGCM &lt;- as.integer(climatechange$GCM)\ndata &lt;- list(N = nrow(climatechange),\n             K = 4L,\n             L = max(GCM), # number of GCM provides\n             y = climatechange$temp, # temperature series\n             # Treat RCP as a factor (Model\n             RCP = as.integer(factor(climatechange$RCP)),\n             GCM = GCM,\n             # TODO: add sensible prior values for mu\n             mu = sort(rexp(4)))\ncc_model &lt;- cmdstanr::cmdstan_model(stan_file = \"climatechange.stan\")\ncc_fit &lt;- cc_model$sample(data = data, chains = 4L)\n\nThe following code enforces the sum-to-zero constraint for \\(\\boldsymbol{\\beta}\\) (see the Stan manual). You can get ordered vectors for \\(\\boldsymbol{\\alpha}\\) by replacing vector by ordered below.\ndata {\n  int&lt;lower=1&gt; N;\n  int&lt;lower=1&gt; K;\n  int&lt;lower=2&gt; L;\n  vector[N] y;\n  array[N] int&lt;lower=0, upper=K&gt; RCP;\n  array[N] int&lt;lower=0, upper=L&gt; GCM;\n  ordered[K] mu;\n}\n\nparameters {\n  vector[K] alpha;\n  sum_to_zero_vector[L] beta;\n  real&lt;lower=0&gt; sigma;\n  real&lt;lower=0&gt; tau;\n  real&lt;lower=0&gt; omega;\n}\n\nmodel {\n  y ~ normal(alpha[RCP] + beta[GCM], sigma);\n  alpha ~ normal(mu, omega);\n  beta ~ normal(0, sqrt(L * inv(L - 1)) * tau);\n  // TODO: Add priors for sigma, tau, omega here\n}",
    "crumbs": [
      "Evaluations",
      "Assignments",
      "Assignment 2"
    ]
  },
  {
    "objectID": "evaluations/02-assignment.html#footnotes",
    "href": "evaluations/02-assignment.html#footnotes",
    "title": "Assignment 2",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAdaptive rejection sampling method works for log-concave distributions, which is the case for both the conditional of the hyperparameters \\(\\alpha\\) and \\(\\beta\\).↩︎\nIf everything fails for you, you can use Metropolis↩︎",
    "crumbs": [
      "Evaluations",
      "Assignments",
      "Assignment 2"
    ]
  },
  {
    "objectID": "content/rpackages.html",
    "href": "content/rpackages.html",
    "title": "R packages",
    "section": "",
    "text": "To install all R packages used throughout the course, use the command\n\ninstall.packages(\"cmdstanr\",\n                 repos = c(\"https://mc-stan.org/r-packages/\",\n                           getOption(\"repos\")))\n\npackages &lt;- c(\"coda\", \"mvtnorm\", \"remotes\", \"loo\", \"dagitty\", \"shape\", \"rust\")\nfor(i in seq_along(packages)){\n  if(!packages[i] %in% installed.packages()[,\"Package\"]){\n install.packages(packages[i])\n  }\n}\nremotes::install_github(\"rmcelreath/rethinking\")\n\ninstall.packages(c(\"BiocManager\",\"remotes\"))\nBiocManager::install(\"graph\")\nBiocManager::install(\"Rgraphviz\")\ninstall.packages(\n  \"INLA\",\n  repos = c(getOption(\"repos\"),\n            INLA = \"https://inla.r-inla-download.org/R/stable\"),\n  dep = TRUE)\n# Download databases for course\nremotes::install_github(\"lbelzile/hecbayes\")",
    "crumbs": [
      "Content",
      "Installation",
      "**R** packages"
    ]
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Readings, lectures, and videos",
    "section": "",
    "text": "Each class session has a set of required readings that you should complete before watching the lecture.",
    "crumbs": [
      "Content",
      "Overview",
      "Readings, lectures, and videos"
    ]
  },
  {
    "objectID": "content/06-content.html#content",
    "href": "content/06-content.html#content",
    "title": "Bayesian workflow and model diagnostics",
    "section": "Content",
    "text": "Content\n\nComputational tricks (blocking, reparametrization, marginalization, etc.)\nBayesian workflow\nGraphical diagnostics of convergence\nGoodness-of-fit measures (WAIC, LOO-CV, etc.)",
    "crumbs": [
      "Content",
      "Course content",
      "6: Bayesian workflow"
    ]
  },
  {
    "objectID": "content/06-content.html#learning-objectives",
    "href": "content/06-content.html#learning-objectives",
    "title": "Bayesian workflow and model diagnostics",
    "section": "Learning objectives",
    "text": "Learning objectives\nAt the end of the chapter, students should be able to\n\nchoose suitable test statistics to evaluate model adequacy\nassess convergence using graphical tools and effective sample size\nperform model comparisons using Bayes factor or predictive measures\ndiagnose performance of MCMC algorithms and implement potential remedies",
    "crumbs": [
      "Content",
      "Course content",
      "6: Bayesian workflow"
    ]
  },
  {
    "objectID": "content/06-content.html#readings",
    "href": "content/06-content.html#readings",
    "title": "Bayesian workflow and model diagnostics",
    "section": "Readings",
    "text": "Readings\n\n\n\n\n\n\nWarning\n\n\n\nThese readings should be completed before class, to ensure timely understanding and let us discuss the concepts together through various examples and case studies — the strict minimum being the course notes.\n\n\n\nChapter 7 of the course notes\nGelman et al. (2020)",
    "crumbs": [
      "Content",
      "Course content",
      "6: Bayesian workflow"
    ]
  },
  {
    "objectID": "content/06-content.html#complementary-readings",
    "href": "content/06-content.html#complementary-readings",
    "title": "Bayesian workflow and model diagnostics",
    "section": "Complementary readings",
    "text": "Complementary readings\n\n\n\n\n\n\nWarning\n\n\n\nComplementary readings are additional sources of information that are not required readings, but may be useful substitutes. Sometimes, they go beyond the scope of what we cover and provide more details.\n\n\n\nGelman et al. (2013), chapters 6 and 7\nMcElreath (2020), chapter 9.5",
    "crumbs": [
      "Content",
      "Course content",
      "6: Bayesian workflow"
    ]
  },
  {
    "objectID": "content/06-content.html#slides",
    "href": "content/06-content.html#slides",
    "title": "Bayesian workflow and model diagnostics",
    "section": "Slides",
    "text": "Slides\n\n  View all slides in new window   Download PDF of all slides",
    "crumbs": [
      "Content",
      "Course content",
      "6: Bayesian workflow"
    ]
  },
  {
    "objectID": "content/04-content.html#content",
    "href": "content/04-content.html#content",
    "title": "Markov chains and Metropolis–Hastings",
    "section": "Content",
    "text": "Content\n\nRejection sampling\nBasics of Markov chains\nMetropolis–Hastings algorithm",
    "crumbs": [
      "Content",
      "Course content",
      "4: Monte Carlo, Markov chains and Metropolis-Hastings"
    ]
  },
  {
    "objectID": "content/04-content.html#learning-objectives",
    "href": "content/04-content.html#learning-objectives",
    "title": "Markov chains and Metropolis–Hastings",
    "section": "Learning objectives",
    "text": "Learning objectives\nAt the end of the chapter, students should be able to\n\nunderstand how ordinary Monte Carlo and Markov chain Monte Carlo (MCMC) methods differ\nimplement a Metropolis–Hastings algorithm to draw samples from the posterior\nuse output of MCMC to obtain estimates and standard errors\nuse efficient proposals and tuning for MCMC",
    "crumbs": [
      "Content",
      "Course content",
      "4: Monte Carlo, Markov chains and Metropolis-Hastings"
    ]
  },
  {
    "objectID": "content/04-content.html#readings",
    "href": "content/04-content.html#readings",
    "title": "Markov chains and Metropolis–Hastings",
    "section": "Readings",
    "text": "Readings\n\nGeyer (2011) — up to 1.17\nChapters 4 and 5 of the course notes",
    "crumbs": [
      "Content",
      "Course content",
      "4: Monte Carlo, Markov chains and Metropolis-Hastings"
    ]
  },
  {
    "objectID": "content/04-content.html#complementary-readings",
    "href": "content/04-content.html#complementary-readings",
    "title": "Markov chains and Metropolis–Hastings",
    "section": "Complementary readings",
    "text": "Complementary readings\n\nGreen et al. (2015) (overview of MCMC methods)",
    "crumbs": [
      "Content",
      "Course content",
      "4: Monte Carlo, Markov chains and Metropolis-Hastings"
    ]
  },
  {
    "objectID": "content/04-content.html#slides",
    "href": "content/04-content.html#slides",
    "title": "Markov chains and Metropolis–Hastings",
    "section": "Slides",
    "text": "Slides\n\n  View all slides in new window   Download PDF of all slides",
    "crumbs": [
      "Content",
      "Course content",
      "4: Monte Carlo, Markov chains and Metropolis-Hastings"
    ]
  },
  {
    "objectID": "content/02-content.html#content",
    "href": "content/02-content.html#content",
    "title": "Bayesics",
    "section": "Content",
    "text": "Content\n\nProbability\nKey concepts: prior, posterior and interpretation\nPredictive distributions\nMarginal likelihood and numerical integration\nCredible intervals, loss functions and posterior summaries\nThe beta binomial conjugate model",
    "crumbs": [
      "Content",
      "Course content",
      "2: Bayesics"
    ]
  },
  {
    "objectID": "content/02-content.html#learning-objectives",
    "href": "content/02-content.html#learning-objectives",
    "title": "Bayesics",
    "section": "Learning objectives",
    "text": "Learning objectives\nAt the end of the chapter, students should be able to\n\ndefine key notions (posterior distribution, posterior predictive, marginal likelihood, credible intervals) of Bayesian inference\nperform inference in conjugate models with a single parameter\ncalculate and compute numerically summaries of posterior distributions (point estimators and credible intervals)\nexplain some of the conceptual differences between frequentist and Bayesian inference",
    "crumbs": [
      "Content",
      "Course content",
      "2: Bayesics"
    ]
  },
  {
    "objectID": "content/02-content.html#readings",
    "href": "content/02-content.html#readings",
    "title": "Bayesics",
    "section": "Readings",
    "text": "Readings\n\nChapter 2 of the course notes",
    "crumbs": [
      "Content",
      "Course content",
      "2: Bayesics"
    ]
  },
  {
    "objectID": "content/02-content.html#complementary-readings",
    "href": "content/02-content.html#complementary-readings",
    "title": "Bayesics",
    "section": "Complementary readings",
    "text": "Complementary readings\n\n\n\n\n\n\nWarning\n\n\n\nComplementary readings are additional sources of information that are not required readings, but may be useful substitutes. Sometimes, they go beyond the scope of what we cover and provide more details.\n\n\n\nEdwards et al. (1992)\nJohnson et al. (2022), chapters 2–4 and sections 8.1, 8.3\nVillani (2023), chapters 1 and 2\nAlbert (2009), chapters 2 and 3",
    "crumbs": [
      "Content",
      "Course content",
      "2: Bayesics"
    ]
  },
  {
    "objectID": "content/02-content.html#slides",
    "href": "content/02-content.html#slides",
    "title": "Bayesics",
    "section": "Slides",
    "text": "Slides\n\n  View all slides in new window   Download PDF of all slides",
    "crumbs": [
      "Content",
      "Course content",
      "2: Bayesics"
    ]
  },
  {
    "objectID": "content/01-content.html#content",
    "href": "content/01-content.html#content",
    "title": "Introduction",
    "section": "Content",
    "text": "Content\n\nMarginalization and conditioning\nBayes’ theorem\nReview of probability distributions\nLikelihood\nMonte Carlo integration",
    "crumbs": [
      "Content",
      "Course content",
      "1: Introduction"
    ]
  },
  {
    "objectID": "content/01-content.html#readings",
    "href": "content/01-content.html#readings",
    "title": "Introduction",
    "section": "Readings",
    "text": "Readings\n\n\n\n\n\n\nWarning\n\n\n\nThese readings should be completed before class, to ensure timely understanding and let us discuss the concepts together through various examples and case studies — the strict minimum being the course notes.\n\n\n\nChapter 1 of the course notes",
    "crumbs": [
      "Content",
      "Course content",
      "1: Introduction"
    ]
  },
  {
    "objectID": "content/01-content.html#complementary-readings",
    "href": "content/01-content.html#complementary-readings",
    "title": "Introduction",
    "section": "Complementary readings",
    "text": "Complementary readings\n\n\n\n\n\n\nWarning\n\n\n\nComplementary readings are additional sources of information that are not required readings, but may be useful substitutes. Sometimes, they go beyond the scope of what we cover and provide more details.\n\n\n\nChapter 1 of Wood (2015)\nChapter 4 and 6.1 of Davison (2003)\nChapters 2 and 3 of Robert & Casella (2004)\nChapters 1–6 of Casella & Berger (2002)",
    "crumbs": [
      "Content",
      "Course content",
      "1: Introduction"
    ]
  },
  {
    "objectID": "content/01-content.html#slides",
    "href": "content/01-content.html#slides",
    "title": "Introduction",
    "section": "Slides",
    "text": "Slides\n\n  View all slides in new window   Download PDF of all slides",
    "crumbs": [
      "Content",
      "Course content",
      "1: Introduction"
    ]
  },
  {
    "objectID": "content/03-content.html#content",
    "href": "content/03-content.html#content",
    "title": "Priors",
    "section": "Content",
    "text": "Content\n\nConjugate, flat, vague, Jeffrey’s, informative and penalized complexity priors\nPriors for regression models\nParameter elicitation\nPrior sensitivity analysis",
    "crumbs": [
      "Content",
      "Course content",
      "3: Priors"
    ]
  },
  {
    "objectID": "content/03-content.html#learning-objectives",
    "href": "content/03-content.html#learning-objectives",
    "title": "Priors",
    "section": "Learning objectives",
    "text": "Learning objectives\nAt the end of the chapter, students should be able to\n\nchoose a suitable prior for a Bayesian analysis\nderive parameters of posterior distributions in conjugate models\nperform parameter elicitation\nassess the impact of priors through sensitivity analysis",
    "crumbs": [
      "Content",
      "Course content",
      "3: Priors"
    ]
  },
  {
    "objectID": "content/03-content.html#readings",
    "href": "content/03-content.html#readings",
    "title": "Priors",
    "section": "Readings",
    "text": "Readings\n\n\n\n\n\n\nWarning\n\n\n\nThese readings should be completed before class, to ensure timely understanding and let us discuss the concepts together through various examples and case studies — the strict minimum being the course notes.\n\n\n\nChapter 3 of the course notes",
    "crumbs": [
      "Content",
      "Course content",
      "3: Priors"
    ]
  },
  {
    "objectID": "content/03-content.html#complementary-readings",
    "href": "content/03-content.html#complementary-readings",
    "title": "Priors",
    "section": "Complementary readings",
    "text": "Complementary readings\n\n\n\n\n\n\nWarning\n\n\n\nComplementary readings are additional sources of information that are not required readings, but may be useful substitutes. Sometimes, they go beyond the scope of what we cover and provide more details.\n\n\n\nVillani (2023), chapter 4\nGelman et al. (2013), chapters 2, 3 and 5\nJohnson et al. (2022), chapter 5\ntruncated Student-t priors for hierarchical models (Gelman, 2006)\npenalized complexity priors (Simpson et al., 2017)",
    "crumbs": [
      "Content",
      "Course content",
      "3: Priors"
    ]
  },
  {
    "objectID": "content/03-content.html#slides",
    "href": "content/03-content.html#slides",
    "title": "Priors",
    "section": "Slides",
    "text": "Slides\n\n  View all slides in new window   Download PDF of all slides",
    "crumbs": [
      "Content",
      "Course content",
      "3: Priors"
    ]
  },
  {
    "objectID": "content/05-content.html#content",
    "href": "content/05-content.html#content",
    "title": "Markov chain Monte Carlo",
    "section": "Content",
    "text": "Content\n\nMetropolis-adjusted Langevin algorithm (MALA)\nGibbs sampling\nData augmentation",
    "crumbs": [
      "Content",
      "Course content",
      "5: Gibbs sampling"
    ]
  },
  {
    "objectID": "content/05-content.html#learning-objectives",
    "href": "content/05-content.html#learning-objectives",
    "title": "Markov chain Monte Carlo",
    "section": "Learning objectives",
    "text": "Learning objectives\nAt the end of the chapter, students should be able to\n\nimplement Gibbs sampling\nderive the conditional distributions of a model for Gibbs sampling",
    "crumbs": [
      "Content",
      "Course content",
      "5: Gibbs sampling"
    ]
  },
  {
    "objectID": "content/05-content.html#readings",
    "href": "content/05-content.html#readings",
    "title": "Markov chain Monte Carlo",
    "section": "Readings",
    "text": "Readings\n\nChapters 5 and 6 of the course notes",
    "crumbs": [
      "Content",
      "Course content",
      "5: Gibbs sampling"
    ]
  },
  {
    "objectID": "content/05-content.html#complementary-readings",
    "href": "content/05-content.html#complementary-readings",
    "title": "Markov chain Monte Carlo",
    "section": "Complementary readings",
    "text": "Complementary readings\n\nAlbert (2009), chapters 6 and 10 (several examples)\nMcElreath (2020), chapter 9 (non technical)\nNeal (2003) (slice sampling)",
    "crumbs": [
      "Content",
      "Course content",
      "5: Gibbs sampling"
    ]
  },
  {
    "objectID": "content/05-content.html#slides",
    "href": "content/05-content.html#slides",
    "title": "Markov chain Monte Carlo",
    "section": "Slides",
    "text": "Slides\n\n  View all slides in new window   Download PDF of all slides",
    "crumbs": [
      "Content",
      "Course content",
      "5: Gibbs sampling"
    ]
  },
  {
    "objectID": "content/07-content.html#content",
    "href": "content/07-content.html#content",
    "title": "Probabilistic programming",
    "section": "Content",
    "text": "Content\n\nHamiltonian Monte Carlo\nProbabilistic programming\nStan",
    "crumbs": [
      "Content",
      "Course content",
      "7: Probabilistic programming"
    ]
  },
  {
    "objectID": "content/07-content.html#learning-objectives",
    "href": "content/07-content.html#learning-objectives",
    "title": "Probabilistic programming",
    "section": "Learning objectives",
    "text": "Learning objectives\nAt the end of the chapter, students should be able to\n\ncode models using Stan",
    "crumbs": [
      "Content",
      "Course content",
      "7: Probabilistic programming"
    ]
  },
  {
    "objectID": "content/07-content.html#readings",
    "href": "content/07-content.html#readings",
    "title": "Probabilistic programming",
    "section": "Readings",
    "text": "Readings\n\nBetancourt (2017)\nNeal (2011)\nChi Feng’s MCMC gallery",
    "crumbs": [
      "Content",
      "Course content",
      "7: Probabilistic programming"
    ]
  },
  {
    "objectID": "content/07-content.html#complementary-readings",
    "href": "content/07-content.html#complementary-readings",
    "title": "Probabilistic programming",
    "section": "Complementary readings",
    "text": "Complementary readings\n\nStan user guide",
    "crumbs": [
      "Content",
      "Course content",
      "7: Probabilistic programming"
    ]
  },
  {
    "objectID": "content/07-content.html#slides",
    "href": "content/07-content.html#slides",
    "title": "Probabilistic programming",
    "section": "Slides",
    "text": "Slides\n\n  View all slides in new window   Download PDF of all slides",
    "crumbs": [
      "Content",
      "Course content",
      "7: Probabilistic programming"
    ]
  },
  {
    "objectID": "content/07-content.html#code",
    "href": "content/07-content.html#code",
    "title": "Probabilistic programming",
    "section": "Code",
    "text": "Code\n\nStochastic volatility model: Stan code 1 and 2 and cmdstanr R script\nSmartwatch example and cmdstanr R script",
    "crumbs": [
      "Content",
      "Course content",
      "7: Probabilistic programming"
    ]
  },
  {
    "objectID": "content/installation.html",
    "href": "content/installation.html",
    "title": "Installing R and RStudio",
    "section": "",
    "text": "Install R\nTo install the latest version of R itself (the engine), currently 4.4.2 (Pile of Leaves).\n\nGo to the Comprehensive R Archive Network (CRAN) website: https://cran.r-project.org/\nClick on “Download R for XXX”, where XXX is either Mac or Windows:\n\n\n\n\n\n\n\n\n\n\nIf you use macOS, scroll down to the first .pkg file in the list of files and download it.\n\n\n\n\n\n\n\n\n\nIf you use Windows, click “base” (or click on the bolded “install R for the first time” link) and download it.\n\n\n\n\n\n\n\n\n\n\nDouble click on the downloaded file (check your Downloads folder). Click yes through all the prompts to install like any other program.\nInstall OS specific programs\n\n\nmacOS only: download and install XQuartz.\nWindows only: download and install Rtools\n\n\n\nInstall RStudio\nRStudio is an integrated development environment (IDE) for R. To install the latter, follow the instructions.\n\nGo to the free download location on RStudio’s website: https://www.rstudio.com/products/rstudio/download/#download\nThe website should automatically detect your operating system (Linux, macOS or Windows) and show a big download button for it:\n\n\n\n\n\n\n\n\n\n\nIf not, scroll down a little to the large table and choose the version of RStudio that matches your operating system.\n\n\n\n\n\n\n\n\n\n\nDouble click on the downloaded file (again, check your Downloads folder). Click yes through all the prompts to install like any other program.\n\nDouble click on RStudio to run it (check your applications folder or start menu).\n\n\nInstall tidyverse\nR packages are easy to install with RStudio. Select the packages panel, click on “Install,” type the name of the package you want to install, and press enter.\n\n\n\n\n\n\n\n\n\nThis can sometimes be tedious when you’re installing lots of packages, though. The tidyverse, for instance, consists of dozens of packages (including ggplot2) that all work together. Rather than install each individually, you can install a single magical package and get them all at the same time.\nGo to the packages panel in RStudio, click on “Install,” type “tidyverse”, and press enter. You’ll see a bunch of output in the RStudio console as all the tidyverse packages are installed.\n\n\n\n\n\n\n\n\n\nNotice also that RStudio will generate a line of code for you and run it: install.packages(\"tidyverse\"). You can also just paste and run this instead of using the packages panel.\n\n\nInstall tinytex\nWhen you knit to PDF, R uses a special scientific typesetting program named LaTeX, which is complicated and a large download. To make life easier, there’s an R package named tinytex that installs a minimal LaTeX program and that automatically deals with differences between macOS and Windows.\nTo install tinytex:\n\nUse the Packages in panel in RStudio to install tinytex like you did above with tidyverse. Alternatively, run install.packages(\"tinytex\") in the console.\nRun tinytex::install_tinytex() in the console.\nWait for a bit while R downloads and installs everything you need.\nYou should now be able to knit to PDF.",
    "crumbs": [
      "Content",
      "Installation",
      "**R** and RStudio"
    ]
  },
  {
    "objectID": "evaluations/01-assignment.html",
    "href": "evaluations/01-assignment.html",
    "title": "Assignment 1",
    "section": "",
    "text": "These problems are for credit and to be handed in on February 2nd at the latest.",
    "crumbs": [
      "Evaluations",
      "Assignments",
      "Assignment 1"
    ]
  },
  {
    "objectID": "evaluations/01-assignment.html#problem-1.1",
    "href": "evaluations/01-assignment.html#problem-1.1",
    "title": "Assignment 1",
    "section": "Problem 1.1",
    "text": "Problem 1.1\nConsider the geometric distribution \\(\\mathsf{geom}(p)\\) with mass function \\[\\begin{align*}\nf(y; p) = p(1-p)^{y}, \\qquad y = 0, 1, 2, \\ldots;\n\\end{align*}\\] the latter is used to model the number of failures \\(Y\\) from independent trials until a first success, which occurs with probability \\(p\\).\n\nIf \\(Y \\mid P=p \\sim \\mathsf{geom}(p)\\) and \\(P \\sim \\mathsf{beta}(\\alpha_1, \\alpha_2)\\), show that \\(P \\mid Y=y\\) is beta distributed and obtain the parameters of the latter.\nObtain the marginal distribution of \\(Y\\) and show that it is a special case of the beta-negative binomial distribution.\nUsing the tower property, compute the unconditional mean and variance of \\(Y\\). Hint: the formulae will depend on the reciprocal moments of a beta distribution, \\(\\mathsf{E}_P(P^{-1})\\) and \\(\\mathsf{E}_P(P^{-2})\\). Complete the kernel to obtain these using the property \\(\\Gamma(\\alpha+1) = \\alpha \\Gamma(\\alpha)\\).\nForward sampling: generate data from the marginal of \\(Y\\) as follows\n\nPick values for \\((\\alpha_1, \\alpha_2)\\).1\nDraw 10 000 observations from \\(Y\\) by first simulating from \\(P\\), then from \\(Y \\mid P\\).\nDiscard the values of \\(P\\) and keep only those for \\(Y\\).\nPlot the marginal distribution of \\(Y\\) using a bar plot.\n\nVerify the formulas for the expected value and variance derived previously using Monte Carlo integration.",
    "crumbs": [
      "Evaluations",
      "Assignments",
      "Assignment 1"
    ]
  },
  {
    "objectID": "evaluations/01-assignment.html#problem-1.2",
    "href": "evaluations/01-assignment.html#problem-1.2",
    "title": "Assignment 1",
    "section": "Problem 1.2",
    "text": "Problem 1.2\nThe sweden dataset contains the number of accidents \\(Y\\) per day in Sweden for 1961–1962. Some days, a speed limit was in place on specified days (day) of each year. We write the mean model as \\[\\begin{align*}\n\\mathsf{E}(Y_i; \\lambda_0, \\lambda_1) &= \\exp(\\beta_0 + \\beta_1\\texttt{limit}_i)\n\\\\&= \\begin{cases} \\lambda_0 & \\texttt{limit}_i=0 \\\\ \\lambda_1 & \\texttt{limit}_i=1.\\end{cases}\n\\end{align*}\\]\nAssume each of the 184 observations are independent from two Poisson populations with mean \\(\\lambda_0\\) and \\(\\lambda_1\\), when limit=0 and limit=1, respectively. Check Example 3.5 (Should you phrase your headline as a question?) of the course notes\n\nUse a noninformative conjugate prior and obtain posterior samples for \\(\\lambda_0\\) and \\(\\lambda_1\\). Use these to obtain \\(B=10 000\\) posterior samples for the mean ratio \\(\\lambda_1/\\lambda_0\\) and plot a histogram or density estimator of the latter.\nCalculate the posterior probability that the speed limit enforcement reduces the average number of accidents.",
    "crumbs": [
      "Evaluations",
      "Assignments",
      "Assignment 1"
    ]
  },
  {
    "objectID": "evaluations/01-assignment.html#problem-1.3",
    "href": "evaluations/01-assignment.html#problem-1.3",
    "title": "Assignment 1",
    "section": "Problem 1.3",
    "text": "Problem 1.3\nThe waiting dataset contains waiting times (in seconds) from 17:59 until the departure of the next metro at the Universite de Montreal station during week-days over three consecutive months.\n\nAssume first that the waiting time are independent and identically distributed as exponential.\n\nUse a conjugate gamma prior such that the average waiting time \\(1/\\lambda\\) has mean 30 seconds and std. deviation 30 seconds.2 Give the values of the corresponding shape and rate parameters of the prior.\nPlot an histogram of prior predictive draws.\nDerive the posterior distribution and report its parameter values.\nCalculate the posterior probability of waiting more than 30 seconds analytically and verify the result via Monte Carlo integration.\n\nThe post_waiting_weibull contains 10K random samples from the posterior of a Weibull model \\(\\mathsf{Weibull}(\\lambda, \\alpha)\\) with a penalized-complexity prior for the shape parameter with \\(\\alpha \\sim \\mathsf{PC}(\\theta=0.5)\\) (Niekerk et al., 2021) and \\(\\lambda \\sim \\mathsf{inv. gamma}(\\gamma, \\omega)\\) with scale \\(\\gamma=90\\) and shape \\(\\omega=4\\).\n\nDraw \\(B=1000\\) posterior predictive samples of size \\(n=62\\) from the Weibull and exponential models. Each draw should use different parameter values.\nFor each, compute (i) the sample mean, (ii) the sample std. deviation and (iii) the empirical proportion of samples exceeding 30 seconds. Plot an histogram for each of the three summary and each model (Weibull and exponential). Superimpose a vertical line indicating the corresponding function for the original waiting sample. Hence comment on the adequacy (or lack thereof) of the two models.",
    "crumbs": [
      "Evaluations",
      "Assignments",
      "Assignment 1"
    ]
  },
  {
    "objectID": "evaluations/01-assignment.html#footnotes",
    "href": "evaluations/01-assignment.html#footnotes",
    "title": "Assignment 1",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTake \\(\\alpha_1 &gt; 3\\) for part e.↩︎\nHint: if \\(\\Lambda \\sim \\mathsf{gamma}(\\alpha, \\beta)\\), then the reciprocal rate follows \\(1/\\Lambda \\sim \\mathsf{inv. gamma}(\\alpha, \\beta)\\) with \\(\\mathsf{E}(\\Lambda^{-1}) = \\beta/(\\alpha-1)\\) for \\(\\alpha&gt;1\\) and \\(\\mathsf{Va}(\\Lambda^{-1}) = \\beta^2/\\{(\\alpha-1)^2(\\alpha-2)\\}\\). Solve to find the values of the parameters and check numerically by generating data from the inverse gamma distribution.↩︎",
    "crumbs": [
      "Evaluations",
      "Assignments",
      "Assignment 1"
    ]
  },
  {
    "objectID": "evaluations/index.html",
    "href": "evaluations/index.html",
    "title": "Evaluations",
    "section": "",
    "text": "The main goals of this class are to help you understand the steps require to design and analyse the results of an experiment.\n\nEvaluations\nYour final grade will be based on assignments and check-ins, a midterm and a final examination. All evaluations are individual work.\nThe midterm and final are closed book exams. Students are forbidden to use generative artificial intelligence (AI) tools. Any reference should be adequately cited.\nThere will be weekly exercises pertaining to the class material, one of which must be handed in for credit. We will discuss the other exercises at the beginning of the next class. The assignment problem will be released weekly, but will have to be handed in bundles.\nThe midterm will take place on Monday, March 3rd from 15:30–18:30. The final is cumulative and will take place on Tuesday, April 15th from 18:30–21:30.",
    "crumbs": [
      "Evaluations"
    ]
  },
  {
    "objectID": "exercises/01-exercise.html",
    "href": "exercises/01-exercise.html",
    "title": "Exercises 1",
    "section": "",
    "text": "Linear mixed effect regression model specifies that response vectors for individual \\(i\\), \\(\\boldsymbol{Y}_i \\in \\mathbb{R}^k\\), are Gaussian. The model includes model matrix \\(\\mathbf{X}_i\\) with fixed effect coefficients \\(\\boldsymbol{\\beta}\\), and another \\(k\\times l\\) model matrix \\(\\mathbf{Z}_i\\) with random effects. The hierarchical formulation of the model is \\[\\begin{align*}\n\\boldsymbol{Y}_i \\mid \\mathcal{B}_i=\\boldsymbol{b}_i &\\sim \\mathsf{Gauss}_k(\\mathbf{X}_i\\boldsymbol{\\beta} + \\mathbf{Z}_i\\boldsymbol{b}_i, \\sigma^2 \\mathbf{I}_k) \\\\\n\\mathcal{B}_i & \\sim \\mathsf{Gauss}_l(\\boldsymbol{0}_k, \\boldsymbol{\\Omega})\n\\end{align*}\\]\n\nUsing the tower property, derive the marginal mean and covariance matrix of \\(\\boldsymbol{Y}_i\\)\nHence obtain the parameters of the joint distribution of \\((\\boldsymbol{Y}_i^\\top, \\mathcal{B}_i^\\top)^\\top\\).",
    "crumbs": [
      "Exercises",
      "1. Introduction"
    ]
  },
  {
    "objectID": "exercises/01-exercise.html#exercise-1.1",
    "href": "exercises/01-exercise.html#exercise-1.1",
    "title": "Exercises 1",
    "section": "",
    "text": "Linear mixed effect regression model specifies that response vectors for individual \\(i\\), \\(\\boldsymbol{Y}_i \\in \\mathbb{R}^k\\), are Gaussian. The model includes model matrix \\(\\mathbf{X}_i\\) with fixed effect coefficients \\(\\boldsymbol{\\beta}\\), and another \\(k\\times l\\) model matrix \\(\\mathbf{Z}_i\\) with random effects. The hierarchical formulation of the model is \\[\\begin{align*}\n\\boldsymbol{Y}_i \\mid \\mathcal{B}_i=\\boldsymbol{b}_i &\\sim \\mathsf{Gauss}_k(\\mathbf{X}_i\\boldsymbol{\\beta} + \\mathbf{Z}_i\\boldsymbol{b}_i, \\sigma^2 \\mathbf{I}_k) \\\\\n\\mathcal{B}_i & \\sim \\mathsf{Gauss}_l(\\boldsymbol{0}_k, \\boldsymbol{\\Omega})\n\\end{align*}\\]\n\nUsing the tower property, derive the marginal mean and covariance matrix of \\(\\boldsymbol{Y}_i\\)\nHence obtain the parameters of the joint distribution of \\((\\boldsymbol{Y}_i^\\top, \\mathcal{B}_i^\\top)^\\top\\).",
    "crumbs": [
      "Exercises",
      "1. Introduction"
    ]
  },
  {
    "objectID": "exercises/01-exercise.html#exercise-1.3",
    "href": "exercises/01-exercise.html#exercise-1.3",
    "title": "Exercises 1",
    "section": "Exercise 1.3",
    "text": "Exercise 1.3\nConsider a simple random sample of size \\(n\\) from the Wald distribution, with density \\[\\begin{align*}\nf(y; \\nu, \\lambda) = \\left(\\frac{\\lambda}{2\\pi y^{3}}\\right)^{1/2} \\exp\\left\\{ - \\frac{\\lambda (y-\\nu)^2}{2\\nu^2y}\\right\\}, \\qquad y &gt; 0.\n\\end{align*}\\] for location \\(\\nu &gt;0\\) and shape \\(\\tau&gt;0\\). You may take for given that the expected value of the Wald distribution is \\(\\mathsf{E}(Y) = \\nu\\).\n\nWrite down the likelihood and show that it can be written in terms of the sufficient statistics \\(\\sum_{i=1}^n y_i\\) and \\(\\sum_{i=1} y_i^{-1}\\).\nDerive the Fisher information matrix",
    "crumbs": [
      "Exercises",
      "1. Introduction"
    ]
  },
  {
    "objectID": "exercises/02-exercise.html",
    "href": "exercises/02-exercise.html",
    "title": "Exercises 2",
    "section": "",
    "text": "You consider the waiting times between buses coming to HEC. Your bus line has frequent buses, but you decide to check the frequency. From your prior experience, you know that measured waiting times range between 3 and 15 minutes. You collect data over the two first week of classes and get an average of 8 minutes based on 10 observations.\nFor modelling, we consider data to arise an independent and identically distributed sample from an exponential distribution with rate \\(\\lambda&gt;0,\\) with associated density \\(f(x) = \\lambda \\exp(-\\lambda x).\\)",
    "crumbs": [
      "Exercises",
      "2. Bayesics"
    ]
  },
  {
    "objectID": "exercises/02-exercise.html#exercise-2.1",
    "href": "exercises/02-exercise.html#exercise-2.1",
    "title": "Exercises 2",
    "section": "Exercise 2.1",
    "text": "Exercise 2.1\nCompute the marginal likelihood when the prior for \\(\\lambda\\) is\n\nan exponential distribution with rate \\(\\kappa&gt;0,\\) with prior density \\(p(\\lambda) = \\kappa \\exp(-\\lambda\\kappa)\\);\nsame, but truncated above at 1, so the density is \\(p(\\lambda) = \\kappa \\exp(-\\lambda\\kappa)\\mathrm{I}\\{\\lambda \\leq 1\\}\\); the indicator function \\(\\mathrm{I}(\\cdot)\\) equals one if the condition is true and zero otherwise.\n\\(\\lambda \\sim \\mathsf{Ga}(\\alpha, \\beta),\\) a gamma distribution with shape \\(\\alpha&gt;0\\) and rate \\(\\beta&gt;0,\\) with prior density \\(p(\\lambda) = \\beta^\\alpha\\lambda^{\\alpha-1}\\exp(-\\beta \\lambda)/\\Gamma(\\alpha).\\)\n\nDeduce that, in all cases above and up to truncation, the posterior distribution is a gamma distribution.",
    "crumbs": [
      "Exercises",
      "2. Bayesics"
    ]
  },
  {
    "objectID": "exercises/02-exercise.html#exercise-2.2",
    "href": "exercises/02-exercise.html#exercise-2.2",
    "title": "Exercises 2",
    "section": "Exercise 2.2",
    "text": "Exercise 2.2\nConsider the following priors for the reciprocal expected waiting time, \\(\\lambda.\\)\n\na gamma with rate \\(\\beta=100\\) and shape \\(\\alpha = 10\\)\nan exponential with rate \\(5\\)\na uniform prior on the unit interval \\([5,10]\\) for \\(1/\\lambda\\)\n\nAssociate each plot of the posterior with each of the priors. Which one seems most suitable for modelling?\nExplain what would happen to the posterior curve if we increased the sample size.\n\n\n\n\n\n\n\n\nFigure 1: Posteriors (full) and scaled likelihood (dashed) for exponential data, with different priors. The dashed vertical line indicates the maximum likelihood estimator.",
    "crumbs": [
      "Exercises",
      "2. Bayesics"
    ]
  },
  {
    "objectID": "exercises/02-exercise.html#exercice-2.3",
    "href": "exercises/02-exercise.html#exercice-2.3",
    "title": "Exercises 2",
    "section": "Exercice 2.3",
    "text": "Exercice 2.3\nThe purpose of this exercise is to show that even one-dimensional numerical integration requires some care. Consider a half Cauchy prior over the positive half line, with density \\[f(x) = 2\\pi^{-1}(1+x^2)^{-1}\\mathrm{I}(x \\geq 0).\\] Using a grid approximation in increments of 0.01, evaluate the unnormalized posterior density from 0 until 30 minutes\\(^{-1}.\\) Compare this approximation with that of quadrature methods (e.g., via integrate in R) and return the corresponding estimates of the normalizing constant. Indication: check the values and make sure the output is sensical. Modify the integrand if necessary.\nPlot the posterior distribution of \\(1/\\lambda,\\) the average waiting time.",
    "crumbs": [
      "Exercises",
      "2. Bayesics"
    ]
  },
  {
    "objectID": "exercises/02-exercise.html#exercice-2.4",
    "href": "exercises/02-exercise.html#exercice-2.4",
    "title": "Exercises 2",
    "section": "Exercice 2.4",
    "text": "Exercice 2.4\nConsider \\(\\lambda \\sim \\mathsf{Ga}(\\alpha = 1.4, \\beta=0.2).\\)\n\nReturn the posterior mean, posterior median and maximum a posteriori (MAP).\nReturn the 89% equitailed percentile credible interval.\nReturn the 50% highest posterior density (HPD) interval (harder). Hint: the hdi function from pacakge HDInterval may be useful for this.\n\nNext, draw 1000 observations from the posterior predictive distribution and plot a histogram of the latter. Compare it to the exponential distribution of observations.\nWould the posterior predictive change if you gathered more data? Justify your answer and explain how it would change, if at all.",
    "crumbs": [
      "Exercises",
      "2. Bayesics"
    ]
  },
  {
    "objectID": "exercises/03-exercise.html",
    "href": "exercises/03-exercise.html",
    "title": "Exercises 3",
    "section": "",
    "text": "Consider a simple random sample of size \\(n\\) from the Wald distribution, with density \\[\\begin{align*}\nf(y; \\nu, \\lambda) = \\left(\\frac{\\lambda}{2\\pi y^{3}}\\right)^{1/2} \\exp\\left\\{ - \\frac{\\lambda (y-\\nu)^2}{2\\nu^2y}\\right\\}\\mathrm{I}(y &gt; 0)\n\\end{align*}\\] for location \\(\\nu &gt;0\\) and shape \\(\\tau&gt;0\\).\n\nShow that the joint prior \\[ p(\\lambda) \\sim \\mathsf{gamma}(\\alpha, \\beta), \\quad p(1/\\nu \\mid \\lambda) \\sim  \\mathsf{Gauss}(\\mu, \\tau^{-1}\\lambda^{-1}),\\] the product of a gamma and a reciprocal Gaussian, is conjugate for the Wald distribution parameters.\nDerive the parameters of the posterior distribution and provide an interpretation of the prior parameters. Hint: write down the posterior parameters as a weighted average of data-dependent quantities and prior parameters.\nDerive the marginal posterior \\(p(\\lambda)\\).",
    "crumbs": [
      "Exercises",
      "3. Priors"
    ]
  },
  {
    "objectID": "exercises/03-exercise.html#exercise-3.1",
    "href": "exercises/03-exercise.html#exercise-3.1",
    "title": "Exercises 3",
    "section": "",
    "text": "Consider a simple random sample of size \\(n\\) from the Wald distribution, with density \\[\\begin{align*}\nf(y; \\nu, \\lambda) = \\left(\\frac{\\lambda}{2\\pi y^{3}}\\right)^{1/2} \\exp\\left\\{ - \\frac{\\lambda (y-\\nu)^2}{2\\nu^2y}\\right\\}\\mathrm{I}(y &gt; 0)\n\\end{align*}\\] for location \\(\\nu &gt;0\\) and shape \\(\\tau&gt;0\\).\n\nShow that the joint prior \\[ p(\\lambda) \\sim \\mathsf{gamma}(\\alpha, \\beta), \\quad p(1/\\nu \\mid \\lambda) \\sim  \\mathsf{Gauss}(\\mu, \\tau^{-1}\\lambda^{-1}),\\] the product of a gamma and a reciprocal Gaussian, is conjugate for the Wald distribution parameters.\nDerive the parameters of the posterior distribution and provide an interpretation of the prior parameters. Hint: write down the posterior parameters as a weighted average of data-dependent quantities and prior parameters.\nDerive the marginal posterior \\(p(\\lambda)\\).",
    "crumbs": [
      "Exercises",
      "3. Priors"
    ]
  },
  {
    "objectID": "exercises/03-exercise.html#exercise-3.2",
    "href": "exercises/03-exercise.html#exercise-3.2",
    "title": "Exercises 3",
    "section": "Exercise 3.2",
    "text": "Exercise 3.2\nConsider the Rayleigh distribution with scale \\(\\sigma&gt;0\\). It’s density is \\[f(y; \\sigma) = \\frac{y}{\\sigma^2} \\exp\\left(-\\frac{y^2}{2\\sigma^2}\\right)\\mathrm{I}(y \\geq 0).\\]\nDerive the Fisher information matrix and use it to obtain Jeffrey’s prior for \\(\\sigma\\). Determine whether the prior is proper.",
    "crumbs": [
      "Exercises",
      "3. Priors"
    ]
  },
  {
    "objectID": "exercises/03-exercise.html#exercise-3.3",
    "href": "exercises/03-exercise.html#exercise-3.3",
    "title": "Exercises 3",
    "section": "Exercise 3.3",
    "text": "Exercise 3.3\nConsider a binomial model with an unknown probability of successes \\(\\theta \\in [0,1]\\) model. Suppose your prior guess for \\(\\theta\\) has mean \\(0.1\\) and standard deviation \\(0.2\\)\nUsing moment matching, return values for the parameters of the conjugate beta prior corresponding to your opinion.\nPlot the resulting beta prior and compare it with a truncated Gaussian distribution on the unit interval with location \\(\\mu=0.1\\) and scale \\(\\sigma=0.2\\).1",
    "crumbs": [
      "Exercises",
      "3. Priors"
    ]
  },
  {
    "objectID": "exercises/03-exercise.html#footnotes",
    "href": "exercises/03-exercise.html#footnotes",
    "title": "Exercises 3",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote that the parameters of the truncated Gaussian distribution do not correspond to moments!↩︎",
    "crumbs": [
      "Exercises",
      "3. Priors"
    ]
  },
  {
    "objectID": "exercises/04-exercise.html",
    "href": "exercises/04-exercise.html",
    "title": "Exercises 4",
    "section": "",
    "text": "Consider the Laplace family of distribution, \\(\\mathsf{Laplace}(\\nu, \\tau)\\), with density \\[\\begin{align*}\ng(x; \\nu, \\tau) = \\frac{1}{2\\tau} \\exp\\left(- \\frac{|x-\\nu|}{\\tau}\\right), \\qquad \\nu \\in \\mathbb{R}, \\tau &gt; 0\n\\end{align*}\\] as a candidate distribution for rejection sampling from \\(\\mathsf{Gauss}(0,1).\\)\n\nProvide an inversion sampling algorithm to generate from \\(\\mathsf{Laplace}(\\nu, \\tau).\\)\nCan you use the proposal to generate from a standard Gaussian? for Student-\\(t\\) with 1 degree of freedom? Justify your answer.\nConsider as proposal a location-scale version of the Student-t with \\(3\\) degrees of freedom. Find the optimal location and scale parameters and the upper bound \\(C\\) for your choice.\nUse the accept-reject to simulate 1000 independent observations and compute the empirical acceptance rate.",
    "crumbs": [
      "Exercises",
      "4. Monte Carlo methods"
    ]
  },
  {
    "objectID": "exercises/04-exercise.html#exercise-4.1",
    "href": "exercises/04-exercise.html#exercise-4.1",
    "title": "Exercises 4",
    "section": "",
    "text": "Consider the Laplace family of distribution, \\(\\mathsf{Laplace}(\\nu, \\tau)\\), with density \\[\\begin{align*}\ng(x; \\nu, \\tau) = \\frac{1}{2\\tau} \\exp\\left(- \\frac{|x-\\nu|}{\\tau}\\right), \\qquad \\nu \\in \\mathbb{R}, \\tau &gt; 0\n\\end{align*}\\] as a candidate distribution for rejection sampling from \\(\\mathsf{Gauss}(0,1).\\)\n\nProvide an inversion sampling algorithm to generate from \\(\\mathsf{Laplace}(\\nu, \\tau).\\)\nCan you use the proposal to generate from a standard Gaussian? for Student-\\(t\\) with 1 degree of freedom? Justify your answer.\nConsider as proposal a location-scale version of the Student-t with \\(3\\) degrees of freedom. Find the optimal location and scale parameters and the upper bound \\(C\\) for your choice.\nUse the accept-reject to simulate 1000 independent observations and compute the empirical acceptance rate.",
    "crumbs": [
      "Exercises",
      "4. Monte Carlo methods"
    ]
  },
  {
    "objectID": "exercises/04-exercise.html#exercise-4.2",
    "href": "exercises/04-exercise.html#exercise-4.2",
    "title": "Exercises 4",
    "section": "Exercise 4.2",
    "text": "Exercise 4.2\nWe revisit Exercise 2.3, which used a half-Cauchy prior for the exponential waiting time of buses.\nThe ratio-of-uniform method, implemented in the rust R package, can be used to simulate independent draws from the posterior of the rate \\(\\lambda\\). The following code produces\n\nnobs &lt;- 10L # number of observations\nybar &lt;- 8   # average waiting time\nB &lt;- 1000L  # number of draws\n# Un-normalized log posterior: scaled log likelihood + log prior\nlog_post &lt;- function(x){ \n  dgamma(x = x, shape = nobs + 1L, rate = nobs*ybar, log = TRUE) +\n    log(2) + dt(x = x, df = 1, log = TRUE)}\npost_samp &lt;- rust::ru(logf = log_post, \n                      n = B, \n                      d = 1,  # dimension of parameter (scalar)\n                      init = nobs/ybar)$sim_vals # initial value of mode\n\nEstimate using the independent Monte Carlo samples:\n\nthe probability that the waiting time is between 3 and 15 minutes\nthe average waiting time\nthe standard deviation of the waiting time.\n\nNext, implement a random walk Metropolis–Hastings algorithm to sample draws from the posterior and re-estimate the quantities. Compare the values and the standard errors of the posterior mean for \\(\\lambda.\\)",
    "crumbs": [
      "Exercises",
      "4. Monte Carlo methods"
    ]
  },
  {
    "objectID": "exercises/04-exercise.html#exercise-4.3",
    "href": "exercises/04-exercise.html#exercise-4.3",
    "title": "Exercises 4",
    "section": "Exercise 4.3",
    "text": "Exercise 4.3\nConsider the following code which implements a Metropolis–Hastings algorithm to simulate observations from a \\(\\mathsf{beta}(0.5, 0.5)\\) density.\n\nlog_f &lt;- function(par){\n  dbeta(x = par, shape1 = 0.5, shape2 = 0.5, log = TRUE)\n}\nmetropo &lt;- function(B, sd_prop = 0.2){\n  chain &lt;- rep(0, B)\n  # Draw initial value\n  cur &lt;- runif(1)\n  for(b in seq_len(B)){\n    repeat {\n        # Simulate proposal from Gaussian random walk proposal\n        prop &lt;- cur + rnorm(1, sd = sd_prop)\n        # check admissibility for probability of success\n        if (prop &gt;= 0 & prop &lt;= 1)\n          break\n    }\n    # Compute (log) acceptance ratio\n    logR &lt;- log_f(prop) - log_f(cur) \n    # Accept the move if R &gt; u\n    if(isTRUE(logR &gt; log(runif(1)))){\n     cur &lt;- prop \n    }\n    chain[b] &lt;- cur\n  }\n  return(chain)\n}\n# Run MCMC for 10K iterations\nmc &lt;- metropo(1e4L)\n\nTo see if the algorithm works:\n\nPlot the density of the Markov chain draws along with the beta density curve.\nCheck that empirical moments match the theoretical ones\n\nIf the algorithm is incorrect, provide a fix and explain the reason for the problem.",
    "crumbs": [
      "Exercises",
      "4. Monte Carlo methods"
    ]
  },
  {
    "objectID": "exercises/05-exercise.html",
    "href": "exercises/05-exercise.html",
    "title": "Exercises 5",
    "section": "",
    "text": "The Pareto distribution with shape \\(\\alpha&gt;0\\) and scale \\(\\tau&gt;0\\) has density \\[\nf(x; \\alpha, \\tau) = \\alpha x^{-\\alpha-1}\\tau^\\alpha \\mathrm{I}(x &gt; \\tau).\n\\] It can be used to model power laws in insurance and finance, or in demography. The uscitypopn data set in the hecbayes package contains the population size of cities above 200K inhabitants in the United States, from the 2020 census.\n\nUsing improper priors \\(p(\\alpha, \\tau) \\propto 1,\\) write the joint posterior for a simple random sample of size \\(n\\) and derive the conditional distributions \\(p(\\alpha \\mid \\boldsymbol{y}, \\tau)\\) and \\(p(\\tau \\mid \\alpha, \\boldsymbol{y})\\). Hint: the conditional density \\(p(\\alpha \\mid \\boldsymbol{y}, \\tau)\\) is that of a gamma; use the fact that \\(m^\\alpha=\\exp\\{\\alpha\\log(m)\\}\\) for \\(m&gt;0\\).\nThe mononomial distribution \\(\\mathsf{Mono}(a,b)\\) has density \\(p(x) \\propto x^{a-1}\\mathsf{I}(0 \\leq x \\leq b)\\) for \\(a, b &gt; 0\\). Find the normalizing constant for the distribution and obtain the quantile function to derive a random number generator.\nImplement Gibbs sampling for this problem for the uscitypopn data. Draw enough observations to obtain an effective sample size of at least 1000 observations. Calculate the accuracy of your estimates.",
    "crumbs": [
      "Exercises",
      "5. Gibbs sampling"
    ]
  },
  {
    "objectID": "exercises/05-exercise.html#exercise-5.1",
    "href": "exercises/05-exercise.html#exercise-5.1",
    "title": "Exercises 5",
    "section": "",
    "text": "The Pareto distribution with shape \\(\\alpha&gt;0\\) and scale \\(\\tau&gt;0\\) has density \\[\nf(x; \\alpha, \\tau) = \\alpha x^{-\\alpha-1}\\tau^\\alpha \\mathrm{I}(x &gt; \\tau).\n\\] It can be used to model power laws in insurance and finance, or in demography. The uscitypopn data set in the hecbayes package contains the population size of cities above 200K inhabitants in the United States, from the 2020 census.\n\nUsing improper priors \\(p(\\alpha, \\tau) \\propto 1,\\) write the joint posterior for a simple random sample of size \\(n\\) and derive the conditional distributions \\(p(\\alpha \\mid \\boldsymbol{y}, \\tau)\\) and \\(p(\\tau \\mid \\alpha, \\boldsymbol{y})\\). Hint: the conditional density \\(p(\\alpha \\mid \\boldsymbol{y}, \\tau)\\) is that of a gamma; use the fact that \\(m^\\alpha=\\exp\\{\\alpha\\log(m)\\}\\) for \\(m&gt;0\\).\nThe mononomial distribution \\(\\mathsf{Mono}(a,b)\\) has density \\(p(x) \\propto x^{a-1}\\mathsf{I}(0 \\leq x \\leq b)\\) for \\(a, b &gt; 0\\). Find the normalizing constant for the distribution and obtain the quantile function to derive a random number generator.\nImplement Gibbs sampling for this problem for the uscitypopn data. Draw enough observations to obtain an effective sample size of at least 1000 observations. Calculate the accuracy of your estimates.",
    "crumbs": [
      "Exercises",
      "5. Gibbs sampling"
    ]
  },
  {
    "objectID": "exercises/05-exercise.html#exercise-5.2",
    "href": "exercises/05-exercise.html#exercise-5.2",
    "title": "Exercises 5",
    "section": "Exercise 5.2",
    "text": "Exercise 5.2\nImplement the Bayesian LASSO for the diabetes cancer surgery from package lars. Check Park & Casella (2008) for the details of the Gibbs sampling (p. 682, right column).\n\nFit the model for a range of values of \\(\\lambda\\) and produce parameter estimate paths to replicate Figure 2 of the paper.\nCheck the effective sample size and comment on the mixing. Is it impacted by the tuning parameter?\nImplement the method of section 3.1 from Park & Casella (2008) by adding \\(\\lambda\\) as a parameter.",
    "crumbs": [
      "Exercises",
      "5. Gibbs sampling"
    ]
  },
  {
    "objectID": "exercises/index.html",
    "href": "exercises/index.html",
    "title": "Exercises",
    "section": "",
    "text": "This section will contain exercises that are directly connected to the course notes, in addition to other exercises from reference manuals.",
    "crumbs": [
      "Exercises"
    ]
  },
  {
    "objectID": "slides/bayesmod-slides1.html#distribution-and-density-function",
    "href": "slides/bayesmod-slides1.html#distribution-and-density-function",
    "title": "Bayesian modelling",
    "section": "Distribution and density function",
    "text": "Distribution and density function\nLet \\(\\boldsymbol{X} \\in \\mathbb{R}^d\\) be a random vector with distribution function \\[\\begin{align*}\nF_{\\boldsymbol{X}}(\\boldsymbol{x}) = \\Pr(\\boldsymbol{X} \\leq \\boldsymbol{x}) = \\Pr(X_1 \\leq x_1, \\ldots, X_d \\leq x_d).\n\\end{align*}\\]\nIf the distribution of \\(\\boldsymbol{X}\\) is absolutely continuous, \\[\\begin{align*}\nF_{\\boldsymbol{X}}(\\boldsymbol{x}) = \\int_{-\\infty}^{x_d} \\cdots \\int_{-\\infty}^{x_1} f_{\\boldsymbol{X}}(z_1, \\ldots, z_d) \\mathrm{d} z_1 \\cdots \\mathrm{d} z_d,\n\\end{align*}\\] where \\(f_{\\boldsymbol{X}}(\\boldsymbol{x})\\) is the joint density function."
  },
  {
    "objectID": "slides/bayesmod-slides1.html#mass-function",
    "href": "slides/bayesmod-slides1.html#mass-function",
    "title": "Bayesian modelling",
    "section": "Mass function",
    "text": "Mass function\nBy abuse of notation, we denote the mass function in the discrete case \\[0 \\leq f_{\\boldsymbol{X}}(\\boldsymbol{x}) = \\Pr(X_1 = x_1, \\ldots, X_d = x_d) \\leq 1.\\]\nThe support is the set of non-zero density/probability total probability over all points in the support, \\[\\sum_{\\boldsymbol{x} \\in \\mathsf{supp}(\\boldsymbol{X})} f_{\\boldsymbol{X}}(\\boldsymbol{x}) = 1.\\]"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#marginal-distribution",
    "href": "slides/bayesmod-slides1.html#marginal-distribution",
    "title": "Bayesian modelling",
    "section": "Marginal distribution",
    "text": "Marginal distribution\nThe marginal distribution of a subvector \\(\\boldsymbol{X}_{1:k}=(X_1, \\ldots, X_k)^\\top\\) is \\[\\begin{align*}\nF_{\\boldsymbol{X}_{1:k}}(\\boldsymbol{x}_{1:k}) &= \\Pr(\\boldsymbol{X}_{1:k} \\leq \\boldsymbol{x}_{1:k}) \\\\&= F_{\\boldsymbol{X}}(x_1, \\ldots, x_k, \\infty, \\ldots, \\infty).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#marginal-density",
    "href": "slides/bayesmod-slides1.html#marginal-density",
    "title": "Bayesian modelling",
    "section": "Marginal density",
    "text": "Marginal density\nThe marginal density \\(f_{\\boldsymbol{X}_{1:k}}(\\boldsymbol{x}_{1:k})\\) of an absolutely continuous subvector \\(\\boldsymbol{X}_{1:k}=(X_1, \\ldots, X_k)^\\top\\) is \\[\\begin{align*}\n\\int_{-\\infty}^\\infty \\cdots  \\int_{-\\infty}^\\infty  f_{\\boldsymbol{X}}(x_1, \\ldots, x_k, z_{k+1}, \\ldots, z_{d}) \\mathrm{d} z_{k+1} \\cdots \\mathrm{d}z_d.\n\\end{align*}\\] through integration from the joint density."
  },
  {
    "objectID": "slides/bayesmod-slides1.html#conditional-distribution",
    "href": "slides/bayesmod-slides1.html#conditional-distribution",
    "title": "Bayesian modelling",
    "section": "Conditional distribution",
    "text": "Conditional distribution\nThe conditional distribution function of \\(\\boldsymbol{Y}\\) given \\(\\boldsymbol{X}=\\boldsymbol{x}\\), is \\[\\begin{align*}\nf_{\\boldsymbol{Y} \\mid \\boldsymbol{X}}(\\boldsymbol{y}; \\boldsymbol{x}) = \\frac{f_{\\boldsymbol{X}, \\boldsymbol{Y}}(\\boldsymbol{x}, \\boldsymbol{y})}{f_{\\boldsymbol{X}}(\\boldsymbol{x})}\n\\end{align*}\\] for any value of \\(\\boldsymbol{x}\\) in the support of \\(\\boldsymbol{X}\\)."
  },
  {
    "objectID": "slides/bayesmod-slides1.html#conditional-and-marginal-for-contingency-table",
    "href": "slides/bayesmod-slides1.html#conditional-and-marginal-for-contingency-table",
    "title": "Bayesian modelling",
    "section": "Conditional and marginal for contingency table",
    "text": "Conditional and marginal for contingency table\nConsider a bivariate distribution for \\((Y_1, Y_2)\\) supported on \\(\\{1,2,3\\} \\times \\{1, 2\\}\\) whose joint probability mass function is given in Table 1\n\n\n\n\nTable 1: Bivariate mass function with probability of each outcome for \\((Y_1, Y_2)\\).\n\n\n\n\n\n\n\n\\(Y_1=1\\)\n\\(Y_1=2\\)\n\\(Y_1=3\\)\nrow total\n\n\n\n\n\\(Y_2=1\\)\n0.20\n0.3\n0.10\n0.6\n\n\n\\(Y_2=2\\)\n0.15\n0.2\n0.05\n0.4\n\n\ncol. total\n0.35\n0.5\n0.15\n1.0"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#calculations-for-the-marginal-distribution",
    "href": "slides/bayesmod-slides1.html#calculations-for-the-marginal-distribution",
    "title": "Bayesian modelling",
    "section": "Calculations for the marginal distribution",
    "text": "Calculations for the marginal distribution\nThe marginal distribution of \\(Y_1\\) is obtain by looking at the total probability for each row/column, e.g., \\[\\Pr(Y_1=i) = \\Pr(Y_1=i, Y_2=1)+ \\Pr(Y_1=i, Y_2=2).\\]\n\n\\(\\Pr(Y_1=1)=0.35\\), \\(\\Pr(Y_1=2)=0.5\\), \\(\\Pr(Y_1=3) = 0.15\\).\n\\(\\Pr(Y_2=1)=0.6\\) and \\(\\Pr(Y_2=2)=0.4\\)"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#conditional-distribution-1",
    "href": "slides/bayesmod-slides1.html#conditional-distribution-1",
    "title": "Bayesian modelling",
    "section": "Conditional distribution",
    "text": "Conditional distribution\nThe conditional distribution \\[\\Pr(Y_2 = i \\mid Y_1=2) = \\frac{\\Pr(Y_1=2, Y_2=i)}{\\Pr(Y_1=2)},\\] so \\[\\begin{align*}\n\\Pr(Y_2 = 1 \\mid Y_1=2) &= 0.3/0.5 = 0.6\n\\\\ \\Pr(Y_2=2 \\mid Y_1=2) &= 0.4.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#independence",
    "href": "slides/bayesmod-slides1.html#independence",
    "title": "Bayesian modelling",
    "section": "Independence",
    "text": "Independence\nVectors \\(\\boldsymbol{Y}\\) and \\(\\boldsymbol{X}\\) are independent if \\[\\begin{align*}\nF_{\\boldsymbol{X}, \\boldsymbol{Y}}(\\boldsymbol{x}, \\boldsymbol{y}) = F_{\\boldsymbol{X}}(\\boldsymbol{x})F_{\\boldsymbol{Y}}(\\boldsymbol{y})\n\\end{align*}\\] for any value of \\(\\boldsymbol{x}\\), \\(\\boldsymbol{y}\\).\nThe joint density, if it exists, also factorizes \\[\\begin{align*}\nf_{\\boldsymbol{X}, \\boldsymbol{Y}}(\\boldsymbol{x}, \\boldsymbol{y}) = f_{\\boldsymbol{X}}(\\boldsymbol{x})f_{\\boldsymbol{Y}}(\\boldsymbol{y}).\n\\end{align*}\\]\nIf two subvectors \\(\\boldsymbol{X}\\) and \\(\\boldsymbol{Y}\\) are independent, then the conditional density \\(f_{\\boldsymbol{Y} \\mid \\boldsymbol{X}}(\\boldsymbol{y}; \\boldsymbol{x})\\) equals the marginal \\(f_{\\boldsymbol{Y}}(\\boldsymbol{y})\\)."
  },
  {
    "objectID": "slides/bayesmod-slides1.html#expected-value",
    "href": "slides/bayesmod-slides1.html#expected-value",
    "title": "Bayesian modelling",
    "section": "Expected value",
    "text": "Expected value\nIf \\(\\boldsymbol{Y}\\) has density \\(f_{\\boldsymbol{Y}},\\) then \\[\\begin{align*}\n\\mathsf{E}\\{g(\\boldsymbol{Y})\\} = \\int g(\\boldsymbol{y}) f_{\\boldsymbol{Y}}(\\boldsymbol{y}) \\mathrm{d} \\boldsymbol{y}\n\\end{align*}\\] a weighted integral of \\(g\\) with weight \\(f_{\\boldsymbol{Y}}.\\)\nThe identity function gives the expected value \\(\\mathsf{E}(\\boldsymbol{Y}).\\)"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#covariance-matrix",
    "href": "slides/bayesmod-slides1.html#covariance-matrix",
    "title": "Bayesian modelling",
    "section": "Covariance matrix",
    "text": "Covariance matrix\nWe define the covariance matrix of \\(\\boldsymbol{Y}\\) as \\[\\begin{align*}\n\\mathsf{Va}(\\boldsymbol{Y}) = \\mathsf{E}\\left[\\left\\{\\boldsymbol{Y} - \\mathsf{E}(\\boldsymbol{Y})\\right\\}\\left\\{\\boldsymbol{Y} - \\mathsf{E}(\\boldsymbol{Y})\\right\\}^\\top\\right],\n\\end{align*}\\] which reduces in the unidimensional setting to \\(\\mathsf{Va}(Y) = \\mathsf{E}\\{Y - \\mathsf{E}(Y)\\}^2 = \\mathsf{E}(Y^2) - \\mathsf{E}(Y)^2.\\)"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#affine-transformations",
    "href": "slides/bayesmod-slides1.html#affine-transformations",
    "title": "Bayesian modelling",
    "section": "Affine transformations",
    "text": "Affine transformations\nIf \\(\\boldsymbol{Y}\\) is \\(d\\)-dimensional and \\(\\mathbf{A}\\) is \\(p \\times d\\) and \\(\\boldsymbol{b}\\) is a \\(p\\) vector, then\n\\[\\begin{align*}\n\\mathsf{E}(\\boldsymbol{AY} + \\boldsymbol{b}) &= \\boldsymbol{A}\\mathsf{E}(\\boldsymbol{Y}) + \\boldsymbol{b},\\\\\n\\mathsf{Va}(\\boldsymbol{AY} + \\boldsymbol{b}) &= \\boldsymbol{A}\\mathsf{Va}(\\boldsymbol{Y})\\boldsymbol{A}^\\top.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#law-of-iterated-expectation-and-variance",
    "href": "slides/bayesmod-slides1.html#law-of-iterated-expectation-and-variance",
    "title": "Bayesian modelling",
    "section": "Law of iterated expectation and variance",
    "text": "Law of iterated expectation and variance\nLet \\(\\boldsymbol{Z}\\) and \\(\\boldsymbol{Y}\\) be random vectors. The expected value of \\(\\boldsymbol{Y}\\) is \\[\\begin{align*}\n\\mathsf{E}_{\\boldsymbol{Y}}(\\boldsymbol{Y}) = \\mathsf{E}_{\\boldsymbol{Z}}\\left\\{\\mathsf{E}_{\\boldsymbol{Y} \\mid \\boldsymbol{Z}}(\\boldsymbol{Y})\\right\\}.\n\\end{align*}\\]\nThe tower property gives a law of iterated variance \\[\\begin{align*}\n\\mathsf{Va}_{\\boldsymbol{Y}}(\\boldsymbol{Y}) = \\mathsf{E}_{\\boldsymbol{Z}}\\left\\{\\mathsf{Va}_{\\boldsymbol{Y} \\mid \\boldsymbol{Z}}(\\boldsymbol{Y})\\right\\} + \\mathsf{Va}_{\\boldsymbol{Z}}\\left\\{\\mathsf{E}_{\\boldsymbol{Y} \\mid \\boldsymbol{Z}}(\\boldsymbol{Y})\\right\\}.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#poisson-distribution",
    "href": "slides/bayesmod-slides1.html#poisson-distribution",
    "title": "Bayesian modelling",
    "section": "Poisson distribution",
    "text": "Poisson distribution\nThe Poisson distribution has mass \\[\\begin{align*}\nf(x)=\\mathsf{Pr}(Y=x) = \\frac{\\exp(-\\lambda)\\lambda^y}{\\Gamma(y+1)}, \\quad x=0, 1, 2, \\ldots\n\\end{align*}\\] where \\(\\Gamma(\\cdot)\\) denotes the gamma function.\nThe parameter \\(\\lambda\\) of the Poisson distribution is both the expectation and the variance of the distribution, meaning \\[\\mathsf{E}(Y)=\\mathsf{Va}(Y)=\\lambda.\\]"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#gamma-distribution",
    "href": "slides/bayesmod-slides1.html#gamma-distribution",
    "title": "Bayesian modelling",
    "section": "Gamma distribution",
    "text": "Gamma distribution\nA gamma distribution with shape \\(\\alpha&gt;0\\) and rate \\(\\beta&gt;0\\), denoted \\(Y \\sim \\mathsf{gamma}(\\alpha, \\beta)\\), has density \\[\\begin{align*}\nf(x) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}x^{\\alpha-1}\\exp(-\\beta x), \\qquad x \\in (0, \\infty),\n\\end{align*}\\] where \\(\\Gamma(\\alpha)=\\int_0^\\infty t^{\\alpha-1}\\exp(-t)\\mathrm{d} t\\) is the gamma function."
  },
  {
    "objectID": "slides/bayesmod-slides1.html#poisson-with-random-scale",
    "href": "slides/bayesmod-slides1.html#poisson-with-random-scale",
    "title": "Bayesian modelling",
    "section": "Poisson with random scale",
    "text": "Poisson with random scale\nTo handle overdispersion in count data, take\n\\[\\begin{align*}\nY \\mid \\Lambda &= \\lambda \\sim \\mathsf{Poisson}(\\lambda)\\\\\n\\Lambda &\\sim \\mathsf{Gamma}(k\\mu, k).\n\\end{align*}\\]\nThe joint density of \\(Y\\) and \\(\\Lambda\\) on \\(\\mathbb{N}=\\{0,1,\\ldots\\} \\times \\mathbb{R}_{+}\\) is \\[\\begin{align*}\nf(y, \\lambda) &= f(y \\mid \\lambda)f(\\lambda) \\\\\n&= \\frac{\\lambda^y\\exp(-\\lambda)}{\\Gamma(y+1)}  \\frac{k^{k\\mu}\\lambda^{k\\mu-1}\\exp(-k\\lambda)}{\\Gamma(k\\mu)}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#conditional-distribution-2",
    "href": "slides/bayesmod-slides1.html#conditional-distribution-2",
    "title": "Bayesian modelling",
    "section": "Conditional distribution",
    "text": "Conditional distribution\nThe conditional distribution of \\(\\Lambda \\mid Y=y\\) can be found by considering only terms that are function of \\(\\lambda\\), whence \\[\\begin{align*}\nf(\\lambda \\mid Y=y) \\stackrel{\\lambda}{\\propto}\\lambda^{y+k\\mu-1}\\exp\\{-(k+1)\\lambda\\}\n\\end{align*}\\] so \\(\\Lambda \\mid Y=y \\sim \\mathsf{gamma}(k\\mu + y, k+1)\\)."
  },
  {
    "objectID": "slides/bayesmod-slides1.html#marginal-density-of-poisson-mean-mixture",
    "href": "slides/bayesmod-slides1.html#marginal-density-of-poisson-mean-mixture",
    "title": "Bayesian modelling",
    "section": "Marginal density of Poisson mean mixture",
    "text": "Marginal density of Poisson mean mixture\n\\[\\begin{align*}\nf(y) &= \\frac{f(y,  \\lambda)}{f(\\lambda \\mid y)} = \\frac{\\frac{\\lambda^y\\exp(-\\lambda)}{\\Gamma(y+1)}  \\frac{k^{k\\mu}\\lambda^{k\\mu-1}\\exp(-k\\lambda)}{\\Gamma(k\\mu)}}{ \\frac{(k+1)^{k\\mu+y}\\lambda^{k\\mu+y-1}\\exp\\{-(k+1)\\lambda\\}}{\\Gamma(k\\mu+y)}}\\\\\n&= \\frac{\\Gamma(k\\mu+y)}{\\Gamma(k\\mu)\\Gamma(y+1)}k^{k\\mu} (k+1)^{-k\\mu-y}\\\\&= \\frac{\\Gamma(k\\mu+y)}{\\Gamma(k\\mu)\\Gamma(y+1)}\\left(1-\\frac{1}{k+1}\\right)^{k\\mu} \\left(\\frac{1}{k+1}\\right)^y\n\\end{align*}\\] Marginally, \\(Y \\sim \\mathsf{neg. binom}(p)\\) where \\(p=(k+1)^{-1}.\\)"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#moments-of-negative-binomial",
    "href": "slides/bayesmod-slides1.html#moments-of-negative-binomial",
    "title": "Bayesian modelling",
    "section": "Moments of negative binomial",
    "text": "Moments of negative binomial\nBy the laws of iterated expectation and iterative variance, \\[\\begin{align*}\n\\mathsf{E}(Y) &= \\mathsf{E}_{\\Lambda}\\{\\mathsf{E}(Y \\mid \\Lambda\\} \\\\& = \\mathsf{E}(\\Lambda) = \\mu\\\\\n\\mathsf{Va}(Y) &= \\mathsf{E}_{\\Lambda}\\{\\mathsf{Va}(Y \\mid \\Lambda)\\} + \\mathsf{Va}_{\\Lambda}\\{\\mathsf{E}(Y \\mid \\Lambda)\\} \\\\&= \\mathsf{E}(\\Lambda) + \\mathsf{Va}(\\Lambda) \\\\&= \\mu + \\mu/k.\n\\end{align*}\\] The marginal distribution of \\(Y\\), unconditionally, has a variance which exceeds its mean."
  },
  {
    "objectID": "slides/bayesmod-slides1.html#change-of-variable-formula",
    "href": "slides/bayesmod-slides1.html#change-of-variable-formula",
    "title": "Bayesian modelling",
    "section": "Change of variable formula",
    "text": "Change of variable formula\nConsider an injective (one-to-one) differentiable function \\(\\boldsymbol{g}: \\mathbb{R}^d \\to \\mathbb{R}^d,\\) with inverse \\(\\boldsymbol{g}^{-1}.\\) Then, if \\(\\boldsymbol{Y}=\\boldsymbol{g}(\\boldsymbol{X}),\\) \\[\\begin{align*}\n\\Pr(\\boldsymbol{Y} \\leq \\boldsymbol{y}) = \\Pr\\{\\boldsymbol{g}(\\boldsymbol{X}) \\leq \\boldsymbol{y}\\} = \\Pr\\{\\boldsymbol{X} \\leq \\boldsymbol{x} = \\boldsymbol{g}^{-1}(\\boldsymbol{y})\\}.\n\\end{align*}\\]\nUsing the chain rule, the density of \\(\\boldsymbol{Y}\\) is \\[\\begin{align*}\nf_{\\boldsymbol{Y}}(\\boldsymbol{y}) = f_{\\boldsymbol{X}}\\left\\{\\boldsymbol{g}^{-1}(\\boldsymbol{y})\\right\\} \\left| \\mathbf{J}_{\\boldsymbol{g}^{-1}}(\\boldsymbol{y})\\right| = f_{\\boldsymbol{X}}(\\boldsymbol{x}) \\left| \\mathbf{J}_{\\boldsymbol{g}}(\\boldsymbol{x})\\right|^{-1}\n\\end{align*}\\] where \\(\\mathbf{J}_{\\boldsymbol{g}}(\\boldsymbol{x})\\) is the Jacobian matrix with \\(i,j\\)th element \\(\\partial [\\boldsymbol{g}(\\boldsymbol{x})]_i / \\partial x_j.\\)"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#gaussian-location-scale",
    "href": "slides/bayesmod-slides1.html#gaussian-location-scale",
    "title": "Bayesian modelling",
    "section": "Gaussian location-scale",
    "text": "Gaussian location-scale\nConsider \\(d\\) independent standard Gaussian variates \\(X_j \\sim \\mathsf{Gauss}(0, 1)\\) for \\(j=1, \\ldots, d,\\) with joint density function \\[\\begin{align*}\nf_{\\boldsymbol{X}}(\\boldsymbol{x})= (2\\pi)^{-d/2} \\exp \\left( - \\frac{\\boldsymbol{x}^\\top\\boldsymbol{x}}{2}\\right).\n\\end{align*}\\] Consider the transformation \\(\\boldsymbol{Y} = \\mathbf{A}\\boldsymbol{X}+\\boldsymbol{b},\\) with \\(\\mathbf{A}\\) an invertible matrix."
  },
  {
    "objectID": "slides/bayesmod-slides1.html#change-of-variable-for-gaussian",
    "href": "slides/bayesmod-slides1.html#change-of-variable-for-gaussian",
    "title": "Bayesian modelling",
    "section": "Change of variable for Gaussian",
    "text": "Change of variable for Gaussian\n\nThe inverse transformation is \\(\\boldsymbol{g}^{-1}(\\boldsymbol{y}) = \\mathbf{A}^{-1}(\\boldsymbol{y}-\\boldsymbol{b}).\\)\nThe Jacobian \\(\\mathbf{J}_{\\boldsymbol{g}}(\\boldsymbol{x})\\) is simply \\(\\mathbf{A},\\) so the joint density of \\(\\boldsymbol{Y}\\) is \\[\\begin{align*}\n(2\\pi)^{-d/2} |\\mathbf{A}|^{-1}\\exp \\left\\{ - \\frac{(\\boldsymbol{y}-\\boldsymbol{b})^\\top\\mathbf{A}^{-\\top}\\mathbf{A}^{-1}(\\boldsymbol{y}-\\boldsymbol{b})}{2}\\right\\}.\n\\end{align*}\\] Since \\(|\\mathbf{A}^{-1}| = |\\mathbf{A}|^{-1}\\) and \\(\\mathbf{A}^{-\\top}\\mathbf{A}^{-1} = (\\mathbf{AA}^\\top)^{-1},\\) we recover \\(\\boldsymbol{Y} \\sim \\mathsf{Gauss}_d(\\boldsymbol{b}, \\mathbf{AA}^\\top).\\)"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#conditional-distribution-of-gaussian-subvectors",
    "href": "slides/bayesmod-slides1.html#conditional-distribution-of-gaussian-subvectors",
    "title": "Bayesian modelling",
    "section": "Conditional distribution of Gaussian subvectors",
    "text": "Conditional distribution of Gaussian subvectors\nLet \\(\\boldsymbol{Y} \\sim \\mathsf{Gauss}_d(\\boldsymbol{\\mu}, \\boldsymbol{Q}^{-1})\\) and consider the partition \\[\\begin{align*}\n\\boldsymbol{Y} = \\begin{pmatrix} \\boldsymbol{Y}_1 \\\\ \\boldsymbol{Y}_2\\end{pmatrix}, \\quad\n\\boldsymbol{\\mu} = \\begin{pmatrix} \\boldsymbol{\\mu}_1 \\\\ \\boldsymbol{\\mu}_2\\end{pmatrix}, \\quad\n\\boldsymbol{Q} = \\begin{pmatrix} \\boldsymbol{Q}_{11} & \\boldsymbol{Q}_{12}\\\\ \\boldsymbol{Q}_{21} & \\boldsymbol{\\Sigma}_{22}\\end{pmatrix},\n\\end{align*}\\] where \\(\\boldsymbol{Y}_1\\) is a \\(k \\times 1\\) and \\(\\boldsymbol{Y}_2\\) is a \\((d-k) \\times 1\\) vector for some \\(1\\leq k &lt; d.\\)\nThen, we have the conditional distribution \\[\\begin{align*}\n\\boldsymbol{Y}_1 \\mid \\boldsymbol{Y}_2 =\\boldsymbol{y}_2 &\\sim \\mathsf{Gauss}_k(\\boldsymbol{\\mu}_1-\\boldsymbol{Q}_{11}^{-1}\\boldsymbol{Q}_{12}(\\boldsymbol{y}_2-\\boldsymbol{\\mu}_2), \\boldsymbol{Q}^{-1}_{11})\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#likelihood",
    "href": "slides/bayesmod-slides1.html#likelihood",
    "title": "Bayesian modelling",
    "section": "Likelihood",
    "text": "Likelihood\nThe likelihood \\(L(\\boldsymbol{\\theta})\\) is a function of the parameter vector \\(\\boldsymbol{\\theta}\\) that gives the ‘density’ of a sample under a postulated distribution, treating the observations as fixed, \\[\\begin{align*}\nL(\\boldsymbol{\\theta}; \\boldsymbol{y}) = f(\\boldsymbol{y}; \\boldsymbol{\\theta}).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#likelihood-for-independent-observations",
    "href": "slides/bayesmod-slides1.html#likelihood-for-independent-observations",
    "title": "Bayesian modelling",
    "section": "Likelihood for independent observations",
    "text": "Likelihood for independent observations\nIf the joint density factorizes, \\[\\begin{align*}\nL(\\boldsymbol{\\theta}; \\boldsymbol{y})=\\prod_{i=1}^n f_i(y_i; \\boldsymbol{\\theta}) = f_1(y_1; \\boldsymbol{\\theta}) \\times \\cdots \\times f_n(y_n; \\boldsymbol{\\theta}).\n\\end{align*}\\] The corresponding log likelihood function for independent and identically distributions observations is \\[\\begin{align*}\n\\ell(\\boldsymbol{\\theta}; \\boldsymbol{y}) = \\sum_{i=1}^n \\ln f(y_i; \\boldsymbol{\\theta})\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#score",
    "href": "slides/bayesmod-slides1.html#score",
    "title": "Bayesian modelling",
    "section": "Score",
    "text": "Score\nLet \\(\\ell(\\boldsymbol{\\theta}),\\) \\(\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta} \\subseteq \\mathbb{R}^p,\\) be the log likelihood function. The gradient of the log likelihood, termed score is the \\(p\\)-vector \\[U(\\boldsymbol{\\theta}) = \\frac{\\partial \\ell(\\boldsymbol{\\theta})}{ \\partial \\boldsymbol{\\theta}}.\\]"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#information-matrix",
    "href": "slides/bayesmod-slides1.html#information-matrix",
    "title": "Bayesian modelling",
    "section": "Information matrix",
    "text": "Information matrix\nThe observed information matrix is the hessian of the negative log likelihood, \\[\\begin{align*}\nj(\\boldsymbol{\\theta}; \\boldsymbol{y})=-\\frac{\\partial^2 \\ell(\\boldsymbol{\\theta}; \\boldsymbol{y})}{\\partial \\boldsymbol{\\theta} \\partial \\boldsymbol{\\theta}^\\top},\n\\end{align*}\\] evaluated at the maximum likelihood estimate \\(\\widehat{\\boldsymbol{\\theta}},\\) so \\(j(\\widehat{\\boldsymbol{\\theta}}).\\)"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#expected-information",
    "href": "slides/bayesmod-slides1.html#expected-information",
    "title": "Bayesian modelling",
    "section": "Expected information",
    "text": "Expected information\nUnder regularity conditions, the expected information, also called Fisher information matrix, is \\[\\begin{align*}\ni(\\boldsymbol{\\theta}) = \\mathsf{E}\\left\\{U(\\boldsymbol{\\theta}; \\boldsymbol{Y}) U(\\boldsymbol{\\theta}; \\boldsymbol{Y})^\\top\\right\\} = \\mathsf{E}\\left\\{j(\\boldsymbol{\\theta}; \\boldsymbol{Y})\\right\\}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#note-on-information-matrices",
    "href": "slides/bayesmod-slides1.html#note-on-information-matrices",
    "title": "Bayesian modelling",
    "section": "Note on information matrices",
    "text": "Note on information matrices\nInformation matrices are symmetric and provide information about the variability of \\(\\widehat{\\boldsymbol{\\theta}}.\\)\nThe information of an iid sample of size \\(n\\)is \\(n\\) times that of a single observation\n\ninformation accumulates at a linear rate."
  },
  {
    "objectID": "slides/bayesmod-slides1.html#information-for-the-gaussian-distribution",
    "href": "slides/bayesmod-slides1.html#information-for-the-gaussian-distribution",
    "title": "Bayesian modelling",
    "section": "Information for the Gaussian distribution",
    "text": "Information for the Gaussian distribution\nConsider \\(Y \\sim \\mathsf{Gauss}(\\mu, \\tau^{-1})\\), parametrized in terms of precision \\(\\tau\\). The likelihood contribution for an \\(n\\) sample is, up to proportionality, \\[\\begin{align*}\n\\ell(\\mu, \\tau) \\propto \\frac{n}{2}\\log(\\tau) - \\frac{\\tau}{2}\\sum_{i=1}^n(Y_i^2-2\\mu Y_i+\\mu^2)\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#gaussian-information-matrices",
    "href": "slides/bayesmod-slides1.html#gaussian-information-matrices",
    "title": "Bayesian modelling",
    "section": "Gaussian information matrices",
    "text": "Gaussian information matrices\nThe observed and Fisher information matrices are \\[\\begin{align*}\nj(\\mu, \\tau) &= \\begin{pmatrix}\nn\\tau & -\\sum_{i=1}^n (Y_i-\\mu)\\\\\n-\\sum_{i=1}^n (Y_i-\\mu) & \\frac{n}{2\\tau^2}\n\\end{pmatrix}, \\\\\ni(\\mu, \\tau) &= n\\begin{pmatrix}\n\\tau & 0\\\\\n0 & \\frac{1}{2\\tau^2}\n\\end{pmatrix}\n\\end{align*}\\] Since \\(\\mathsf{E}(Y_i) = \\mu\\), the expected value of the off-diagonal entries of the Fisher information matrix are zero."
  },
  {
    "objectID": "slides/bayesmod-slides1.html#example-random-right-censoring",
    "href": "slides/bayesmod-slides1.html#example-random-right-censoring",
    "title": "Bayesian modelling",
    "section": "Example: random right-censoring",
    "text": "Example: random right-censoring\nConsider a survival analysis problem for independent time-to-event data subject to (noninformative) random right-censoring. We observe\n\nfailure times \\(Y_i (i=1, \\ldots, n)\\) drawn from \\(F(\\cdot; \\boldsymbol{\\theta})\\) supported on \\((0, \\infty)\\)\nindependent binary censoring indicators \\(C_i \\in \\{0,1\\}\\), with \\(0\\) indicating right-censoring and \\(C_i=1\\) observed failure time."
  },
  {
    "objectID": "slides/bayesmod-slides1.html#likelihood-contribution-with-censoring",
    "href": "slides/bayesmod-slides1.html#likelihood-contribution-with-censoring",
    "title": "Bayesian modelling",
    "section": "Likelihood contribution with censoring",
    "text": "Likelihood contribution with censoring\nIf individual observation \\(i\\) has not experienced the event at the end of the collection period, then the likelihood contribution is \\(\\Pr(Y &gt; y) = 1-F(y; \\boldsymbol{\\theta})\\), where \\(y_i\\) is the maximum time observed for \\(Y_i\\). We write the log likelihood \\[\\begin{align*}\n\\ell(\\boldsymbol{\\theta}) = \\sum_{i: c_i=0} \\log \\{1- F(y_i; \\boldsymbol{\\theta})\\} + \\sum_{i: c_i=1} \\log f(y_i; \\boldsymbol{\\theta})\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#censoring-and-exponential-data",
    "href": "slides/bayesmod-slides1.html#censoring-and-exponential-data",
    "title": "Bayesian modelling",
    "section": "Censoring and exponential data",
    "text": "Censoring and exponential data\nSuppose for simplicity that \\(Y_i \\sim \\mathsf{expo}(\\lambda)\\) and let \\(m=c_1 + \\cdots + c_n\\) denote the number of observed failure times. Then, the log likelihood and the Fisher information are \\[\\begin{align*}\n\\ell(\\lambda) &= \\lambda \\sum_{i=1}^n y_i + \\log \\lambda m\\\\\ni(\\lambda) &= m/\\lambda^2\n\\end{align*}\\] and the right-censored observations for the exponential model do not contribute to the information."
  },
  {
    "objectID": "slides/bayesmod-slides1.html#example-first-order-autoregressive-process",
    "href": "slides/bayesmod-slides1.html#example-first-order-autoregressive-process",
    "title": "Bayesian modelling",
    "section": "Example: first-order autoregressive process",
    "text": "Example: first-order autoregressive process\nConsider an \\(\\mathsf{AR}(1)\\) model of the form \\[Y_t = \\mu + \\phi(Y_{t-1} - \\mu) + \\varepsilon_t,\\] where\n\n\\(\\phi\\) is the lag-one correlation,\n\\(\\mu\\) the global mean and\n\\(\\varepsilon_t\\) is an iid innovation with mean zero and variance \\(\\sigma^2\\).\n\nIf \\(|\\phi| &lt; 1\\), the process is stationary, and the variance does not increase with \\(t\\)."
  },
  {
    "objectID": "slides/bayesmod-slides1.html#markov-property-and-likelihood-decomposition",
    "href": "slides/bayesmod-slides1.html#markov-property-and-likelihood-decomposition",
    "title": "Bayesian modelling",
    "section": "Markov property and likelihood decomposition",
    "text": "Markov property and likelihood decomposition\nThe Markov property states that the current realization depends on the past, \\(Y_t \\mid Y_1, \\ldots, Y_{t-1},\\) only through the most recent value \\(Y_{t-1}.\\) The log likelihood thus becomes \\[\\begin{align*}\n\\ell(\\boldsymbol{\\theta}) = \\ln f(y_1) + \\sum_{i=2}^n f(y_i \\mid y_{i-1}).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#marginal-of-ar1",
    "href": "slides/bayesmod-slides1.html#marginal-of-ar1",
    "title": "Bayesian modelling",
    "section": "Marginal of AR(1)",
    "text": "Marginal of AR(1)\nThe \\(\\mathsf{AR}(1)\\) stationarity process has unconditional moments \\[\\mathsf{E}(Y_t) = \\mu, \\qquad \\mathsf{Var}(Y_t)=\\sigma^2/(1-\\phi^2).\\]\nThe \\(\\mathsf{AR}(1)\\) process is first-order Markov since the conditional distribution \\(f(Y_t \\mid Y_{t-1}, \\ldots, Y_{t-p})\\) equals \\(f(Y_t \\mid Y_{t-1})\\)."
  },
  {
    "objectID": "slides/bayesmod-slides1.html#log-likelihood-of-ar1",
    "href": "slides/bayesmod-slides1.html#log-likelihood-of-ar1",
    "title": "Bayesian modelling",
    "section": "Log likelihood of AR(1)",
    "text": "Log likelihood of AR(1)\nIf innovations are Gaussian, we have \\[Y_t \\mid Y_{t-1}=y_{t-1} \\sim \\mathsf{Gauss}\\{\\mu(1-\\phi)+ \\phi y_{t-1}, \\sigma^2\\}, \\qquad t&gt;1.\\] so the log-likelihood is \\[\\begin{align*}\n&\\ell(\\mu, \\phi,\\sigma^2)= -\\frac{n}{2}\\log(2\\pi) - n\\log \\sigma + \\frac{1}{2}\\log(1-\\phi^2) \\\\&\\quad -\\frac{(1-\\phi^2)(y_1- \\mu)^2}{2\\sigma^2} - \\sum_{i=2}^n \\frac{(y_t - \\mu(1-\\phi)- \\phi y_{t-1})^2}{2\\sigma^2}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#estimation-of-integrals",
    "href": "slides/bayesmod-slides1.html#estimation-of-integrals",
    "title": "Bayesian modelling",
    "section": "Estimation of integrals",
    "text": "Estimation of integrals\nSuppose we can simulate \\(B\\) i.i.d. variables with the same distribution, \\(x_1, \\ldots, x_B\\) with distribution \\(F\\).\nWe want to compute \\(\\mathsf{E}\\{g(X)\\}=\\int g(x) f(x) \\mathrm{d} x=\\mu_g\\) for some functional \\(g(\\cdot)\\)\n\n\\(g(x)=x\\) (mean)\n\\(g(x) = \\mathsf{I}(x \\in A)\\) (probability of event)\netc."
  },
  {
    "objectID": "slides/bayesmod-slides1.html#vanilla-monte-carlo-integration",
    "href": "slides/bayesmod-slides1.html#vanilla-monte-carlo-integration",
    "title": "Bayesian modelling",
    "section": "Vanilla Monte Carlo integration",
    "text": "Vanilla Monte Carlo integration\nWe substitute expected value by sample average of \\[\\begin{align*}\n\\widehat{\\mu}_g = \\frac{1}{B} \\sum_{b=1}^B g(x_b).\n\\end{align*}\\]\n\nlaw of large number guarantees convergence of \\(\\widehat{\\mu}_g \\to \\mu_g\\) if the latter is finite.\nUnder finite second moments, central limit theorem gives \\[\\sqrt{B}(\\widehat{\\mu}_g - \\mu_g) \\sim \\mathsf{No}(0, \\sigma^2_g).\\]"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#importance-sampling",
    "href": "slides/bayesmod-slides1.html#importance-sampling",
    "title": "Bayesian modelling",
    "section": "Importance sampling",
    "text": "Importance sampling\nConsider density \\(q\\) instead with \\(\\mathrm{supp}(p) \\subseteq \\mathrm{supp}(q).\\) Then, \\[\\begin{align*}\n\\mathsf{E}\\{g(X)\\} = \\int_{\\mathcal{X}} g(x) \\frac{p(x)}{q(x)} q(x) \\mathrm{d} x\n\\end{align*}\\] and we can proceed similarly by drawing samples from \\(q\\)."
  },
  {
    "objectID": "slides/bayesmod-slides1.html#importance-sampling-estimator",
    "href": "slides/bayesmod-slides1.html#importance-sampling-estimator",
    "title": "Bayesian modelling",
    "section": "Importance sampling estimator",
    "text": "Importance sampling estimator\nAn alternative Monte Carlo estimator uses the weighted average \\[\\begin{align*}\n\\widetilde{\\mathsf{E}}\\{g(X)\\} =\\frac{B^{-1} \\sum_{b=1}^B w_b g(x_b) }{B^{-1}\\sum_{b=1}^B w_b}.\n\\end{align*}\\] with weights \\(w_b = p(x_b)/q(x_b)\\). The latter equal 1 on average, so one could omit the denominator without harm."
  },
  {
    "objectID": "slides/bayesmod-slides1.html#standard-errors",
    "href": "slides/bayesmod-slides1.html#standard-errors",
    "title": "Bayesian modelling",
    "section": "Standard errors",
    "text": "Standard errors\nIf the variance of \\(g(X)\\) is finite, we can approximate the latter by the sample variance of the simple random sample and obtain the Monte Carlo standard error of the estimator \\[\\begin{align*}\n\\mathsf{se}^2[\\widehat{\\mathsf{E}}\\{g(X)\\}] = \\frac{1}{B(B-1)} \\sum_{b=1}^B \\left[ g(x_b) -  \\widehat{\\mathsf{E}}\\{g(X)\\} \\right]^2.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides1.html#precision-of-monte-carlo-integration",
    "href": "slides/bayesmod-slides1.html#precision-of-monte-carlo-integration",
    "title": "Bayesian modelling",
    "section": "Precision of Monte Carlo integration",
    "text": "Precision of Monte Carlo integration\nWe want to have an estimator as precise as possible.\n\nbut we can’t control the variance of \\(g(X)\\), say \\(\\sigma_g^2\\)\nthe more simulations \\(B\\), the lower the variance of the mean.\nsample average for i.i.d. data has variance \\(\\sigma^2_g/B\\)\nto reduce the standard deviation by a factor 10, we need \\(100\\) times more draws!\n\nRemember: the answer is random."
  },
  {
    "objectID": "slides/bayesmod-slides1.html#example-functionals-of-gamma-distribution",
    "href": "slides/bayesmod-slides1.html#example-functionals-of-gamma-distribution",
    "title": "Bayesian modelling",
    "section": "Example: functionals of gamma distribution",
    "text": "Example: functionals of gamma distribution\n\n\nFigure 1: Running mean trace plots for \\(g(x)=\\mathrm{I}(x&lt;1)\\) (left), \\(g(x)=x\\) (middle) and \\(g(x)=1/x\\) (right) for a Gamma distribution with shape 0.5 and rate 2, as a function of the Monte Carlo sample size."
  },
  {
    "objectID": "slides/bayesmod-slides1.html#recap",
    "href": "slides/bayesmod-slides1.html#recap",
    "title": "Bayesian modelling",
    "section": "Recap",
    "text": "Recap\n\nWe can specify distribution using hierarchies, with marginal \\(\\times\\) conditional.\nMost density and mass functions for \\(\\boldsymbol{Y}\\) can be identified from their support and their kernel, i.e., terms that depend on \\(\\boldsymbol{y}\\), ignoring normalizing constants. We then match expressions.\nExpectations can be calculated analytically, or approximated via Monte Carlo simulations."
  },
  {
    "objectID": "slides/bayesmod-slides3.html#priors",
    "href": "slides/bayesmod-slides3.html#priors",
    "title": "Bayesian modelling",
    "section": "Priors",
    "text": "Priors\nThe posterior density is\n\\[\\begin{align*}\n\\color{#D55E00}{p(\\boldsymbol{\\theta} \\mid \\boldsymbol{Y})} = \\frac{\\color{#0072B2}{p(\\boldsymbol{Y} \\mid \\boldsymbol{\\theta})} \\times  \\color{#56B4E9}{p(\\boldsymbol{\\theta})}}{\\color{#E69F00}{\\int p(\\boldsymbol{Y} \\mid \\boldsymbol{\\theta}) p(\\boldsymbol{\\theta})\\mathrm{d} \\boldsymbol{\\theta}}},\n\\end{align*}\\]\nwhere \\[\\color{#D55E00}{\\text{posterior}} \\propto \\color{#0072B2}{\\text{likelihood}} \\times \\color{#56B4E9}{\\text{prior}}\\]\nWe need to determine a suitable prior."
  },
  {
    "objectID": "slides/bayesmod-slides3.html#impact-of-the-prior",
    "href": "slides/bayesmod-slides3.html#impact-of-the-prior",
    "title": "Bayesian modelling",
    "section": "Impact of the prior",
    "text": "Impact of the prior\nThe posterior is a compromise prior and likelihood:\n\nthe more informative the prior, the more the posterior resembles it.\nin large samples, the effect of the prior is often negligible"
  },
  {
    "objectID": "slides/bayesmod-slides3.html#controversial",
    "href": "slides/bayesmod-slides3.html#controversial",
    "title": "Bayesian modelling",
    "section": "Controversial?",
    "text": "Controversial?\n\nNo unique choice for the prior: different analysts get different inferences\nWhat is the robustness to the prior specification? Check through sensitivity analysis.\nEven with prior knowledge, hard to elicit parameter (many different models could yield similar summary statistics)"
  },
  {
    "objectID": "slides/bayesmod-slides3.html#choosing-priors",
    "href": "slides/bayesmod-slides3.html#choosing-priors",
    "title": "Bayesian modelling",
    "section": "Choosing priors",
    "text": "Choosing priors\nInfinite number of choice, but many default choices…\n\nconditionally conjugate priors (ease of interpretation, computational advantages)\nflat priors and vague priors (mostly uninformative)\ninformative priors (expert opinion)\nJeffrey’s priors (improper, invariant to reparametrization)\npenalized complexity (regularization)\nshrinkage priors (variable selection, reduce overfitting)"
  },
  {
    "objectID": "slides/bayesmod-slides3.html#determining-hyperparameters",
    "href": "slides/bayesmod-slides3.html#determining-hyperparameters",
    "title": "Bayesian modelling",
    "section": "Determining hyperparameters",
    "text": "Determining hyperparameters\nWe term hyperparameters the parameters of the (hyper)priors.\nHow to elicit reasonable values for them?\n\nuse moment matching to get sensible values\ntrial-and-error using the prior predictive\n\ndraw a parameter value from the prior \\(\\boldsymbol{\\theta}_0\\)\nfor each, generate a new observation from the model \\(f(y_{\\text{new}} \\mid \\boldsymbol{\\theta}_0)\\)"
  },
  {
    "objectID": "slides/bayesmod-slides3.html#example-of-simple-linear-regression",
    "href": "slides/bayesmod-slides3.html#example-of-simple-linear-regression",
    "title": "Bayesian modelling",
    "section": "Example of simple linear regression",
    "text": "Example of simple linear regression\nWorking with standardized response and inputs \\[x_i \\mapsto (x_i - \\overline{x})/\\mathrm{sd}(\\boldsymbol{x}),\\]\n\nthe slope is the correlation between explanatory \\(\\mathrm{X}\\) and response \\(Y\\)\nthe intercept should be mean zero\nare there sensible bounds for the range of the response?"
  },
  {
    "objectID": "slides/bayesmod-slides3.html#example---simple-linear-regression",
    "href": "slides/bayesmod-slides3.html#example---simple-linear-regression",
    "title": "Bayesian modelling",
    "section": "Example - simple linear regression",
    "text": "Example - simple linear regression\nConsider the relationship between height (\\(Y,\\) in cm) and weight (\\(X,\\) in kg) among humans adults.1\nModel using a simple linear regression\n\\[\\begin{align*}\nY_i &\\sim \\mathsf{Gauss}(\\mu_i, \\sigma^2) \\\\\n\\mu_i &= \\beta_0 + \\beta_1(\\mathrm{x}_i - \\overline{x}) \\\\\n\\beta_0 &\\sim \\mathsf{Gauss}(178, 20^2) \\\\\n\\sigma &\\sim \\mathsf{unif}(0, 50)\n\\end{align*}\\] What about the slope parameter prior \\(p(\\beta_1)\\)?\nSection 4.4.1 of McElreath (2020)"
  },
  {
    "objectID": "slides/bayesmod-slides3.html#priors-for-the-slope",
    "href": "slides/bayesmod-slides3.html#priors-for-the-slope",
    "title": "Bayesian modelling",
    "section": "Priors for the slope",
    "text": "Priors for the slope\n\n\nFigure 1: Prior draws of linear regressions with different priors: vague \\(\\beta_1 \\sim \\mathsf{Gauss}(0, 100)\\) (left) and lognormal \\(\\ln(\\beta_1) \\sim \\mathsf{Gauss}(0,1)\\) (right). Figure 4.5 of McElreath (2020). The Guiness record for the world’s tallest person is 272cm."
  },
  {
    "objectID": "slides/bayesmod-slides3.html#conjugate-priors",
    "href": "slides/bayesmod-slides3.html#conjugate-priors",
    "title": "Bayesian modelling",
    "section": "Conjugate priors",
    "text": "Conjugate priors\nA prior density \\(p(\\boldsymbol{\\theta})\\) is conjugate for likelihood \\(L(\\boldsymbol{\\theta}; \\boldsymbol{y})\\) if the product \\(L(\\boldsymbol{\\theta}; \\boldsymbol{y})p(\\boldsymbol{\\theta}),\\) after renormalization, is of the same parametric family as the prior.\nDistributions that are exponential family admit conjugate priors.\n\nA distribution is an exponential family if it’s density can be written \\[\\begin{align*}\nf(y; \\boldsymbol{\\theta}) = \\exp\\left\\{ \\sum_{k=1}^K Q_k(\\boldsymbol{\\theta}) t_k(y) + D(\\boldsymbol{\\theta}) + h(y)\\right\\}.\n\\end{align*}\\] The support of \\(f\\) must not depend on \\(\\boldsymbol{\\theta}.\\)"
  },
  {
    "objectID": "slides/bayesmod-slides3.html#conjugate-priors-for-common-exponential-families",
    "href": "slides/bayesmod-slides3.html#conjugate-priors-for-common-exponential-families",
    "title": "Bayesian modelling",
    "section": "Conjugate priors for common exponential families",
    "text": "Conjugate priors for common exponential families\n\n\n\n\n\n\n\n\ndistribution\nunknown parameter\nconjugate prior\n\n\n\n\n\\(Y \\sim \\mathsf{expo}(\\lambda)\\)\n\\(\\lambda\\)\n\\(\\lambda \\sim \\mathsf{gamma}(\\alpha, \\beta)\\)\n\n\n\\(Y \\sim \\mathsf{Poisson}(\\mu)\\)\n\\(\\mu\\)\n\\(\\mu \\sim \\mathsf{gamma}(\\alpha, \\beta)\\)\n\n\n\\(Y \\sim \\mathsf{binom}(n, \\theta)\\)\n\\(\\theta\\)\n\\(\\theta \\sim \\mathsf{Be}(\\alpha, \\beta)\\)\n\n\n\\(Y \\sim \\mathsf{Gauss}(\\mu, \\sigma^2)\\)\n\\(\\mu\\)\n\\(\\mu \\sim \\mathsf{Gauss}(\\nu, \\omega^2)\\)\n\n\n\\(Y \\sim \\mathsf{Gauss}(\\mu, \\sigma^2)\\)\n\\(\\sigma\\)\n\\(\\sigma^{-2} \\sim \\mathsf{gamma}(\\alpha, \\beta)\\)\n\n\n\\(Y \\sim \\mathsf{Gauss}(\\mu, \\sigma^2)\\)\n\\(\\mu, \\sigma\\)\n\\(\\mu \\mid \\sigma^2 \\sim \\mathsf{Gauss}(\\nu, \\omega \\sigma^2),\\) \\(\\sigma^{-2} \\sim \\mathsf{gamma}(\\alpha, \\beta)\\)"
  },
  {
    "objectID": "slides/bayesmod-slides3.html#conjugate-prior-for-the-poisson",
    "href": "slides/bayesmod-slides3.html#conjugate-prior-for-the-poisson",
    "title": "Bayesian modelling",
    "section": "Conjugate prior for the Poisson",
    "text": "Conjugate prior for the Poisson\nIf \\(Y \\sim \\mathsf{Poisson}(\\mu)\\) with density \\(f(y) = \\mu^x\\exp(-\\mu x)/x!,\\) then for \\(\\mu \\sim \\mathsf{gamma}(\\alpha, \\beta)\\) with \\(\\alpha, \\beta\\) fixed. Consider an i.i.d. sample with mean \\(\\overline{y}.\\) The posterior density is\n\\[\np(\\mu \\mid y) \\stackrel{\\mu}{\\propto} \\mu^{n\\overline{y}} \\exp\\left(-\\mu n\\overline{y}\\right) \\mu^{\\alpha-1} \\exp(-\\beta \\mu)\n\\] so must be gamma \\(\\mathsf{gamma}(n\\overline{y} + \\alpha, n\\overline{y} + \\beta).\\)\nParameter interpretation: \\(\\alpha\\) events in \\(\\beta\\) time intervals."
  },
  {
    "objectID": "slides/bayesmod-slides3.html#conjugate-prior-for-gaussian-known-variance",
    "href": "slides/bayesmod-slides3.html#conjugate-prior-for-gaussian-known-variance",
    "title": "Bayesian modelling",
    "section": "Conjugate prior for Gaussian (known variance)",
    "text": "Conjugate prior for Gaussian (known variance)\nConsider an iid sample, \\(Y_i \\sim \\mathsf{Gauss}(\\mu, \\sigma^2)\\) and let \\(\\mu \\mid \\sigma \\sim \\mathsf{Gauss}(\\nu, \\sigma^2\\tau^2).\\) Then, \\[\\begin{align*}\np(\\mu, \\sigma) &\\propto \\frac{p(\\sigma)}{\\sigma^{n+1}} \\exp\\left\\{ -\\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y_{i}-\\mu)^2\\right\\} \\exp\\left\\{-\\frac{1}{2\\sigma^2\\tau^2}(\\mu - \\nu)^2\\right\\}\n\\\\&\\propto \\frac{p(\\sigma)}{\\sigma^{n+1}} \\exp\\left\\{\\left(\\sum_{i=1}^n y_{i} + \\frac{\\nu}{\\tau^2}\\right)\\frac{\\mu}{\\sigma^2} - \\left( \\frac{n}{2} +\\frac{1}{2\\tau^2}\\right)\\frac{\\mu^2}{\\sigma^2}\\right\\}.\n\\end{align*}\\]\nThe conditional posterior \\(p(\\mu \\mid \\sigma)\\) is Gaussian with\n\nmean \\((n\\overline{y}\\tau^2 + \\nu)/(n\\tau^2 + 1)\\) and\nprecision (reciprocal variance) \\((n + 1/\\tau^2)/\\sigma^2.\\)"
  },
  {
    "objectID": "slides/bayesmod-slides3.html#upworthy-examples",
    "href": "slides/bayesmod-slides3.html#upworthy-examples",
    "title": "Bayesian modelling",
    "section": "Upworthy examples",
    "text": "Upworthy examples\n\nThe Upworthy Research Archive (Matias et al., 2021) contains results for 22743 experiments, with a click through rate of 1.58% on average and a standard deviation of 1.23%.\nWe consider an A/B test that compared four different headlines for a story.\nWe model the conversion rate for each using \\(\\texttt{click}_i \\sim \\mathsf{Poisson}(\\lambda_i\\texttt{impression}_i).\\)\n\nWe treat \\(\\texttt{impression}\\) as a known offset."
  },
  {
    "objectID": "slides/bayesmod-slides3.html#headlines",
    "href": "slides/bayesmod-slides3.html#headlines",
    "title": "Bayesian modelling",
    "section": "Headlines",
    "text": "Headlines\nConsider an A/B test from November 23st, 2014, that compared four different headlines for a story on Sesame Street workshop with interviews of children whose parents were in jail and visiting them in prisons. The headlines tested were:\n\nSome Don’t Like It When He Sees His Mom. But To Him? Pure Joy. Why Keep Her From Him?\nThey’re Not In Danger. They’re Right. See True Compassion From The Children Of The Incarcerated.\nKids Have No Place In Jail … But In This Case, They Totally Deserve It.\nGoing To Jail Should Be The Worst Part Of Their Life. It’s So Not. Not At All."
  },
  {
    "objectID": "slides/bayesmod-slides3.html#ab-test-sesame-street-example",
    "href": "slides/bayesmod-slides3.html#ab-test-sesame-street-example",
    "title": "Bayesian modelling",
    "section": "A/B test: Sesame street example",
    "text": "A/B test: Sesame street example\n\n\n\n\n\nheadline\nimpressions\nclicks\n\n\n\n\nH1\n3060\n49\n\n\nH2\n2982\n20\n\n\nH3\n3112\n31\n\n\nH4\n3083\n9"
  },
  {
    "objectID": "slides/bayesmod-slides3.html#moment-matching-for-gamma-distribution",
    "href": "slides/bayesmod-slides3.html#moment-matching-for-gamma-distribution",
    "title": "Bayesian modelling",
    "section": "Moment matching for gamma distribution",
    "text": "Moment matching for gamma distribution\nFor \\(Y \\sim \\mathsf{gamma}(\\alpha, \\beta)\\) with \\(\\beta\\) the rate parameter, we have \\[\\begin{align*}\n\\mathsf{E}(Y)=\\alpha/\\beta, \\qquad \\mathsf{Va}(Y)=\\alpha/\\beta^2.\n\\end{align*}\\] We can solve for \\(\\beta =\\mathsf{E}_0(\\lambda)/\\mathsf{Va}_0(\\lambda)\\) and then use the mean relationship to retrieve $.\n\nmu &lt;- 0.0158; sd &lt;- 0.0123\n(beta &lt;- mu/sd^2)\n\n[1] 104.4352\n\n(alpha &lt;- mu * beta)\n\n[1] 1.650076\n\n\nMoment matching gives \\(\\alpha = 1.65\\) and \\(\\beta = 104.44.\\)"
  },
  {
    "objectID": "slides/bayesmod-slides3.html#posterior-distributions-for-sesame-street",
    "href": "slides/bayesmod-slides3.html#posterior-distributions-for-sesame-street",
    "title": "Bayesian modelling",
    "section": "Posterior distributions for Sesame Street",
    "text": "Posterior distributions for Sesame Street\n\n\nFigure 2: Gamma posteriors of the conversion rate for the Upworthy Sesame street headline."
  },
  {
    "objectID": "slides/bayesmod-slides3.html#proper-priors",
    "href": "slides/bayesmod-slides3.html#proper-priors",
    "title": "Bayesian modelling",
    "section": "Proper priors",
    "text": "Proper priors\n\nTheorem 1 A sufficient condition for a prior to yield a proper (i.e., integrable) posterior density function is that it is (proportional) to a density function.\n\n\nIf we pick an improper prior, we need to check that the posterior is well-defined.\nThe answer to this question may depend on the sample size."
  },
  {
    "objectID": "slides/bayesmod-slides3.html#proper-posterior-in-a-random-effect-model",
    "href": "slides/bayesmod-slides3.html#proper-posterior-in-a-random-effect-model",
    "title": "Bayesian modelling",
    "section": "Proper posterior in a random effect model",
    "text": "Proper posterior in a random effect model\nConsider a Gaussian random effect model with \\(n\\) independent observations in \\(J\\) groups\nThe \\(i\\)th observation in group \\(j\\) is \\[\\begin{align*}\nY_{ij} &\\sim \\mathsf{Gauss}(\\mu_{ij}, \\sigma^2) \\\\\n\\mu_{ij}&= \\mathbf{X}_i \\boldsymbol{\\beta} + \\alpha_j,  \\\\\n\\alpha_j &\\sim \\mathsf{Gauss}(0, \\tau^2)\\\\\n...\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides3.html#conditions-for-a-proper-posterior",
    "href": "slides/bayesmod-slides3.html#conditions-for-a-proper-posterior",
    "title": "Bayesian modelling",
    "section": "Conditions for a proper posterior",
    "text": "Conditions for a proper posterior\n\nfor \\(\\tau \\sim \\mathsf{unif}(0, \\infty),\\) we need at least \\(J \\geq 3\\) ‘groups’ for the posterior to be proper.\nif we take \\(p(\\tau) \\propto \\tau^{-1},\\) the posterior is never proper.\n\nAs Gelman (2006) states:\n\nin a hierarchical model the data can never rule out a group-level variance of zero, and so [a] prior distribution cannot put an infinite mass in this area"
  },
  {
    "objectID": "slides/bayesmod-slides3.html#improper-priors-as-limiting-cases",
    "href": "slides/bayesmod-slides3.html#improper-priors-as-limiting-cases",
    "title": "Bayesian modelling",
    "section": "Improper priors as limiting cases",
    "text": "Improper priors as limiting cases\nWe can view the improper prior as a limiting case \\[\\sigma \\sim \\mathsf{unif}(0, t), \\qquad t \\to \\infty.\\]\nThe Haldane prior for \\(\\theta\\) in a binomial model is \\(\\theta^{-1}(1-\\theta)^{-1},\\) a limiting \\(\\mathsf{Be}(0,0)\\) distribution.\nThe improper prior \\(p(\\sigma) \\propto \\sigma^{-1}\\) is equivalent to an inverse gamma \\(\\mathsf{inv. gamma}(\\epsilon, \\epsilon)\\) when \\(\\epsilon \\to 0.\\)\nThe limiting posterior is thus improper for random effects scales, so the value of \\(\\epsilon\\) matters."
  },
  {
    "objectID": "slides/bayesmod-slides3.html#mdi-prior-for-generalized-pareto",
    "href": "slides/bayesmod-slides3.html#mdi-prior-for-generalized-pareto",
    "title": "Bayesian modelling",
    "section": "MDI prior for generalized Pareto",
    "text": "MDI prior for generalized Pareto\nLet \\(Y_i \\sim \\mathsf{GP}(\\sigma, \\xi)\\) be generalized Pareto with density \\[f(x) = \\sigma^{-1}(1+\\xi x/\\sigma)_{+}^{-1/\\xi-1}\\] for \\(\\sigma&gt;0\\) and \\(\\xi \\in \\mathbb{R},\\) and \\(x_{+} =\\max\\{0, x\\}.\\)\nConsider the maximum data information (MDI) \\[p(\\xi) \\propto \\exp(-\\xi).\\]\nSince \\(\\lim_{\\xi \\to -\\infty} \\exp(-\\xi) = \\infty,\\) the prior density increases without bound as \\(\\xi\\) becomes smaller."
  },
  {
    "objectID": "slides/bayesmod-slides3.html#truncated-mdi-for-generalized-pareto-distribution",
    "href": "slides/bayesmod-slides3.html#truncated-mdi-for-generalized-pareto-distribution",
    "title": "Bayesian modelling",
    "section": "Truncated MDI for generalized Pareto distribution",
    "text": "Truncated MDI for generalized Pareto distribution\nThe MDI prior leads to an improper posterior without modification.\n\n\nFigure 3: Unscaled maximum data information (MDI) prior density.\nIf we restrict the range of the MDI prior \\(p(\\xi)\\) to \\(\\xi \\geq -1,\\) then \\(p(\\xi + 1) \\sim \\mathsf{expo}(1)\\) and posterior is proper."
  },
  {
    "objectID": "slides/bayesmod-slides3.html#flat-priors",
    "href": "slides/bayesmod-slides3.html#flat-priors",
    "title": "Bayesian modelling",
    "section": "Flat priors",
    "text": "Flat priors\nUniform prior over the support of \\(\\theta,\\) \\[p(\\theta) \\propto 1.\\]\nImproper prior unless \\(\\theta \\in [a,b]\\) for finite \\(a, b.\\)"
  },
  {
    "objectID": "slides/bayesmod-slides3.html#flat-priors-for-scale-parameters",
    "href": "slides/bayesmod-slides3.html#flat-priors-for-scale-parameters",
    "title": "Bayesian modelling",
    "section": "Flat priors for scale parameters",
    "text": "Flat priors for scale parameters\nConsider a scale parameter \\(\\sigma &gt; 0.\\)\n\nWe could truncate the range, e.g., \\(\\sigma \\sim \\mathsf{unif}(0, 50),\\) but this is not ‘uninformative’, as extreme values of \\(\\sigma\\) are as likely as small ones.\nThese priors are not invariant: if \\(p\\{\\log(\\sigma)\\} \\propto 1\\) implies \\(p(\\sigma) \\propto \\sigma^{-1}\\) so can be informative on another scale."
  },
  {
    "objectID": "slides/bayesmod-slides3.html#vague-priors",
    "href": "slides/bayesmod-slides3.html#vague-priors",
    "title": "Bayesian modelling",
    "section": "Vague priors",
    "text": "Vague priors\nVague priors are very diffuse proper prior.\nFor example, a vague Gaussian prior for regression coefficients on standardized data, \\[\\boldsymbol{\\beta} \\sim \\mathsf{Gauss}_p(\\mathbf{0}_p, 100\\mathbf{I}_p).\\]\n\nif we consider a logistic regression with a binary variable \\(\\mathrm{X}_j \\in \\{0,1\\},\\) then \\(\\beta_j =5\\) gives odds ratios of 150, and \\(\\beta_j=10\\) of around 22K…"
  },
  {
    "objectID": "slides/bayesmod-slides3.html#invariance-and-jeffreys-prior",
    "href": "slides/bayesmod-slides3.html#invariance-and-jeffreys-prior",
    "title": "Bayesian modelling",
    "section": "Invariance and Jeffrey’s prior",
    "text": "Invariance and Jeffrey’s prior\nIn single-parameter models, the Jeffrey’s prior \\[p(\\theta) \\propto |\\imath(\\theta)|^{1/2},\\] proportional to the square root of the determinant of the Fisher information matrix, is invariant to any (differentiable) reparametrization."
  },
  {
    "objectID": "slides/bayesmod-slides3.html#jeffreys-prior-for-the-binomial-distribution",
    "href": "slides/bayesmod-slides3.html#jeffreys-prior-for-the-binomial-distribution",
    "title": "Bayesian modelling",
    "section": "Jeffrey’s prior for the binomial distribution",
    "text": "Jeffrey’s prior for the binomial distribution\nConsider \\(Y \\sim \\mathsf{binom}(1, \\theta).\\) The negative of the second derivative of the log likelihood with respect to \\(p\\) is \\[\n\\jmath(\\theta) = - \\partial^2 \\ell(\\theta; y) / \\partial \\theta^2 = y/\\theta^2 + (1-y)/(1-\\theta)^2.\n\\]\nSince \\(\\mathsf{E}(Y)=\\theta,\\) the Fisher information is \\[\\imath(\\vartheta) = \\mathsf{E}\\{\\jmath(\\theta)\\}=1/\\theta + 1/(1-\\theta) = 1/\\{\\theta(1-\\theta)\\}.\\] Jeffrey’s prior is therefore \\(p(\\theta) \\propto \\theta^{-1/2}(1-\\theta)^{-1/2},\\) a conjugate Beta prior \\(\\mathsf{Be}(0.5,0.5).\\)"
  },
  {
    "objectID": "slides/bayesmod-slides3.html#invariant-priors-for-location-scale-families",
    "href": "slides/bayesmod-slides3.html#invariant-priors-for-location-scale-families",
    "title": "Bayesian modelling",
    "section": "Invariant priors for location-scale families",
    "text": "Invariant priors for location-scale families\nFor a location-scale family with location \\(\\mu\\) and scale \\(\\sigma,\\) the independent priors \\[\\begin{align*}\np(\\mu) &\\propto 1\\\\\np(\\sigma) &\\propto \\sigma^{-1}\n\\end{align*}\\] are location-scale invariant.\nThe results are invariant to affine transformations of the units, \\(\\vartheta = a + b \\theta.\\)"
  },
  {
    "objectID": "slides/bayesmod-slides3.html#penalized-complexity-priors",
    "href": "slides/bayesmod-slides3.html#penalized-complexity-priors",
    "title": "Bayesian modelling",
    "section": "Penalized complexity priors",
    "text": "Penalized complexity priors\nSimpson et al. (2017) consider a principled way of constructing priors that penalized model complexity for stable inference and limit over-specification.\nComputes Kullback–Leibler divergence between \\(f\\) and base model \\(f_0\\) densities, builds an exponential prior on the distance scale and backtransform.\nThe resulting prior is scale-invariant, but it’s derivation is nontrivial."
  },
  {
    "objectID": "slides/bayesmod-slides3.html#penalized-complexity-prior-for-random-effect-scale",
    "href": "slides/bayesmod-slides3.html#penalized-complexity-prior-for-random-effect-scale",
    "title": "Bayesian modelling",
    "section": "Penalized complexity prior for random effect scale",
    "text": "Penalized complexity prior for random effect scale\nIf \\(\\alpha_j \\sim \\mathsf{Gauss}(0, \\zeta^2),\\) the penalized complexity prior for the scale \\(\\zeta \\sim \\mathsf{expo}(\\lambda).\\)\nElicit \\(Q,\\) a high quantile of the standard deviation \\(\\zeta\\) with tail probability \\(\\alpha\\) and set \\(\\lambda = -\\log(\\alpha/Q).\\)"
  },
  {
    "objectID": "slides/bayesmod-slides3.html#priors-for-scale-of-random-effects",
    "href": "slides/bayesmod-slides3.html#priors-for-scale-of-random-effects",
    "title": "Bayesian modelling",
    "section": "Priors for scale of random effects",
    "text": "Priors for scale of random effects\nThe conjugate inverse gamma prior \\(p(\\zeta^2) \\sim \\mathsf{inv. gamma}(\\alpha, \\beta)\\) is such that the mode for \\(\\zeta^2\\) is \\(\\beta/(1+\\alpha).\\)\nOften, we take \\(\\beta=\\alpha = 0.01\\) or \\(0.001,\\) but this leads to near-improper priors, so small values of the parameters are not optimal for ‘random effects’.\nThe inverse gamma prior cannot provide shrinkage or allow for no variability between groups."
  },
  {
    "objectID": "slides/bayesmod-slides3.html#priors-for-scale-of-random-effects-1",
    "href": "slides/bayesmod-slides3.html#priors-for-scale-of-random-effects-1",
    "title": "Bayesian modelling",
    "section": "Priors for scale of random effects",
    "text": "Priors for scale of random effects\nA popular suggestion, due to Gelman (2006), is to take a centered Student-\\(t\\) distribution with \\(\\nu\\) degrees of freedoms, truncated over \\([0, \\infty)\\) with scale \\(s.\\)\n\nsince the mode is at zero, provides support for the base model\nwe want small degrees of freedom \\(\\nu,\\) preferable to take \\(\\nu=3\\)? Cauchy model (\\(\\nu=1\\)) still popular."
  },
  {
    "objectID": "slides/bayesmod-slides3.html#prior-sensitivity",
    "href": "slides/bayesmod-slides3.html#prior-sensitivity",
    "title": "Bayesian modelling",
    "section": "Prior sensitivity",
    "text": "Prior sensitivity\nDoes the priors matter? As robustness check, one can fit the model with\n\ndifferent priors function\ndifferent hyperparameter values\n\nCostly, but may be needed to convince reviewers ;)"
  },
  {
    "objectID": "slides/bayesmod-slides3.html#distraction-from-smartwach",
    "href": "slides/bayesmod-slides3.html#distraction-from-smartwach",
    "title": "Bayesian modelling",
    "section": "Distraction from smartwach",
    "text": "Distraction from smartwach\nWe consider an experimental study conducted at Tech3Lab on road safety.\n\nIn Brodeur et al. (2021), 31 participants were asked to drive in a virtual environment.\nThe number of road violation was measured for 4 different type of distractions (phone notification, phone on speaker, texting and smartwatch).\nBalanced data, random order of tasks"
  },
  {
    "objectID": "slides/bayesmod-slides3.html#poisson-mixed-model",
    "href": "slides/bayesmod-slides3.html#poisson-mixed-model",
    "title": "Bayesian modelling",
    "section": "Poisson mixed model",
    "text": "Poisson mixed model\nWe model the number of violations, nviolation as a function of distraction type (task) and participant id. \\[\\begin{align*}\n\\texttt{nviolation}_{ij} &\\sim \\mathsf{Poisson}(\\mu_{ij})\\\\\n\\mu_{ij} &= \\exp(\\beta_{j} + \\alpha_i),\\\\\n\\beta_j &\\sim \\mathsf{Gauss}(0, 100), \\\\\n\\alpha_i &\\sim \\mathsf{Gauss}(0, \\tau^2).\n\\end{align*}\\]\nSpecifically,\n\n\\(\\beta_j\\) is the coefficient for task \\(j\\) (distraction type),\n\\(\\alpha_i\\) is the random effect of participant \\(i.\\)"
  },
  {
    "objectID": "slides/bayesmod-slides3.html#priors-for-random-effect-scale",
    "href": "slides/bayesmod-slides3.html#priors-for-random-effect-scale",
    "title": "Bayesian modelling",
    "section": "Priors for random effect scale",
    "text": "Priors for random effect scale\nConsider different priors for \\(\\tau\\)\n\nflat uniform prior \\(\\mathsf{unif}(0,10)\\)\nconjugate inverse gamma \\(\\mathsf{inv. gamma}(0.01, 0.01)\\) prior\na truncated Student-\\(t\\) on \\([0, \\infty)\\) with \\(\\nu=3\\) degrees of freedom, \\(\\mathsf{Student}_{+}(0,1,3)\\)\na penalized complexity prior such that the 0.95 percentile of the scale is 5, corresponding to \\(\\mathsf{expo}(0.6).\\)"
  },
  {
    "objectID": "slides/bayesmod-slides3.html#sensitivity-analysis-for-smartwatch-data",
    "href": "slides/bayesmod-slides3.html#sensitivity-analysis-for-smartwatch-data",
    "title": "Bayesian modelling",
    "section": "Sensitivity analysis for smartwatch data",
    "text": "Sensitivity analysis for smartwatch data\n\n\nFigure 4: Posterior density of \\(\\tau\\) for four different priors. The circle denotes the median and the bars the 50% and 95% percentile credible intervals.\nBasically indistinguishable results for the random scale.."
  },
  {
    "objectID": "slides/bayesmod-slides3.html#eight-schools-example",
    "href": "slides/bayesmod-slides3.html#eight-schools-example",
    "title": "Bayesian modelling",
    "section": "Eight schools example",
    "text": "Eight schools example\nAverage results on SAT program, for eight schools (Rubin, 1981).\nThe hierarchical model is\n\\[\\begin{align*}\nY_i &\\sim \\mathsf{Gauss}(\\mu + \\eta_i, \\sigma_i^2)\\\\\n\\mu &\\sim \\mathsf{Gauss}(0, 100)\\\\\n\\eta_i & \\sim \\mathsf{Gauss}(0, \\tau^2)\n\\end{align*}\\] Given the large sample in each school, we treat \\(\\sigma_i\\) as fixed data by using the sample standard deviation."
  },
  {
    "objectID": "slides/bayesmod-slides3.html#sensibility-analysis-for-eight-schools-example",
    "href": "slides/bayesmod-slides3.html#sensibility-analysis-for-eight-schools-example",
    "title": "Bayesian modelling",
    "section": "Sensibility analysis for eight schools example",
    "text": "Sensibility analysis for eight schools example\n\n\nFigure 5: Posterior density of the school-specific random effects standard deviation \\(\\tau\\) under different priors."
  },
  {
    "objectID": "slides/bayesmod-slides3.html#references",
    "href": "slides/bayesmod-slides3.html#references",
    "title": "Bayesian modelling",
    "section": "References",
    "text": "References\n\n\n\n\nBrodeur, M., Ruer, P., Léger, P.-M., & Sénécal, S. (2021). Smartwatches are more distracting than mobile phones while driving: Results from an experimental study. Accident Analysis & Prevention, 149, 105846. https://doi.org/10.1016/j.aap.2020.105846\n\n\nGelman, A. (2006). Prior distributions for variance parameters in hierarchical models (comment on article by Browne and Draper). Bayesian Analysis, 1(3), 515–534. https://doi.org/10.1214/06-ba117a\n\n\nMatias, J. N., Munger, K., Le Quere, M. A., & Ebersole, C. (2021). The Upworthy Research Archive, a time series of 32,487 experiments in U.S. media. Scientific Data, 8(195). https://doi.org/10.1038/s41597-021-00934-7\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and STAN (2nd ed.). Chapman; Hall/CRC.\n\n\nRubin, D. B. (1981). Estimation in parallel randomized experiments. Journal of Educational Statistics, 6(4), 377–401. https://doi.org/10.3102/10769986006004377\n\n\nSimpson, D., Rue, H., Riebler, A., Martins, T. G., & Sørbye, S. H. (2017). Penalising model component complexity: A principled, practical approach to constructing priors. Statistical Science, 32(1), 1–28. https://doi.org/10.1214/16-sts576"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#reminder-metropolishastings-algorithm",
    "href": "slides/bayesmod-slides5.html#reminder-metropolishastings-algorithm",
    "title": "Bayesian modelling",
    "section": "Reminder: Metropolis–Hastings algorithm",
    "text": "Reminder: Metropolis–Hastings algorithm\nStarting from an initial value \\(\\boldsymbol{\\theta}_0\\):\n\ndraw a proposal value \\(\\boldsymbol{\\theta}_t^{\\star} \\sim q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}_{t-1})\\).\nCompute the acceptance ratio \\[\nR = \\frac{p(\\boldsymbol{\\theta}_t^{\\star})}{p(\\boldsymbol{\\theta}_{t-1})}\\frac{q(\\boldsymbol{\\theta}_{t-1} \\mid \\boldsymbol{\\theta}_t^{\\star} )}{q(\\boldsymbol{\\theta}_t^{\\star} \\mid \\boldsymbol{\\theta}_{t-1})}\n\\]\nWith probability \\(\\min\\{R, 1\\}\\), accept the proposal and set \\(\\boldsymbol{\\theta}_t \\gets \\boldsymbol{\\theta}_t^{\\star}\\), otherwise set the value to the previous state, \\(\\boldsymbol{\\theta}_t \\gets \\boldsymbol{\\theta}_{t-1}\\)."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#calculations",
    "href": "slides/bayesmod-slides5.html#calculations",
    "title": "Bayesian modelling",
    "section": "Calculations",
    "text": "Calculations\nWe compute the log of the acceptance ratio, \\(\\ln R\\), to avoid numerical overflow, with the log posterior difference \\[\n\\ln \\left\\{\\frac{p(\\boldsymbol{\\theta}_t^{\\star})}{p(\\boldsymbol{\\theta}_{t-1})}\\right\\} = \\ell(\\boldsymbol{\\theta}_t^{\\star}) + \\ln p(\\boldsymbol{\\theta}_t^{\\star}) - \\ell(\\boldsymbol{\\theta}_{t-1}) - \\ln p(\\boldsymbol{\\theta}_{t-1})\n\\]\nCompare the value of \\(\\ln R\\) (if less than zero) to \\(\\log(U)\\), where \\(U \\sim \\mathsf{unif}(0,1)\\)."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#what-proposal",
    "href": "slides/bayesmod-slides5.html#what-proposal",
    "title": "Bayesian modelling",
    "section": "What proposal?",
    "text": "What proposal?\nThe independence Metropolis–Hastings uses a global proposal \\(q\\) which does not depend on the current state (typically centered at the MAP)\nThis may be problematic with multimodal targets.\nThe Gaussian random walk takes \\(\\boldsymbol{\\theta}_t^{\\star} =\\boldsymbol{\\theta}_{t-1}+ \\sigma_\\text{p}Z\\), where \\(Z \\sim \\mathsf{Gauss}(0,1)\\) and \\(\\sigma_\\text{p}\\) is the proposal standard deviation. Random walks allow us to explore the space."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#burn-in",
    "href": "slides/bayesmod-slides5.html#burn-in",
    "title": "Bayesian modelling",
    "section": "Burn in",
    "text": "Burn in\nWe are guaranteed to reach stationarity with Metropolis–Hastings, but it may take a large number of iterations…\nOne should discard initial draws during a burn in or warmup period if the chain has not reached stationarity. Ideally, use good starting value to reduce waste.\nWe can also use the warmup period to adapt the variance of the proposal."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#goldilock-principle-and-proposal-variance",
    "href": "slides/bayesmod-slides5.html#goldilock-principle-and-proposal-variance",
    "title": "Bayesian modelling",
    "section": "Goldilock principle and proposal variance",
    "text": "Goldilock principle and proposal variance\nMixing of the chain requires just the right variance (not too small nor too large).\n\n\nFigure 1: Example of traceplot with proposal variance that is too small (top), adequate (middle) and too large (bottom)."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#correlograms-for-goldilock",
    "href": "slides/bayesmod-slides5.html#correlograms-for-goldilock",
    "title": "Bayesian modelling",
    "section": "Correlograms for Goldilock",
    "text": "Correlograms for Goldilock\n\n\nFigure 2: Correlogram for the three Markov chains."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#tuning-markov-chain-monte-carlo",
    "href": "slides/bayesmod-slides5.html#tuning-markov-chain-monte-carlo",
    "title": "Bayesian modelling",
    "section": "Tuning Markov chain Monte Carlo",
    "text": "Tuning Markov chain Monte Carlo\n\nOutside of starting values, the variance of the proposal has a huge impact on the asymptotic variance.\nWe can adapt the variance during warmup by increasing/decreasing proposal variance (if acceptance rate is too large/small).\nWe can check this via the acceptance rate (how many proposals are accepted)."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#optimal-acceptance-rates",
    "href": "slides/bayesmod-slides5.html#optimal-acceptance-rates",
    "title": "Bayesian modelling",
    "section": "Optimal acceptance rates",
    "text": "Optimal acceptance rates\nThe following rules were derived for Gaussian targets under idealized situations.\n\nIn 1D, rule of thumb is an acceptance rate of \\(0.44\\) is optimal, and this ratio decreases to \\(0.234\\) when \\(D \\geq 2\\) (Sherlock, 2013) for random walk Metropolis–Hastings.\nProposals for \\(D\\)-variate update should have proposal variance of roughly \\((2.38^2/d)\\times \\boldsymbol{\\Sigma}\\), where \\(\\boldsymbol{\\Sigma}\\) is the posterior variance.\nFor MALA (see later), we get \\(0.574\\) rather than \\(0.234\\)"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#block-update-or-one-parameter-at-a-time",
    "href": "slides/bayesmod-slides5.html#block-update-or-one-parameter-at-a-time",
    "title": "Bayesian modelling",
    "section": "Block update or one parameter at a time?",
    "text": "Block update or one parameter at a time?\nAs with any accept-reject, proposals become inefficient when the dimension \\(D\\) increase.\nThis is the curse of dimensionality.\nUpdating parameters in turn\n\nincreases acceptance rate (with clever proposals),\nbut also leads to more autocorrelation between parameters"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#solutions-for-strongly-correlated-coefficients",
    "href": "slides/bayesmod-slides5.html#solutions-for-strongly-correlated-coefficients",
    "title": "Bayesian modelling",
    "section": "Solutions for strongly correlated coefficients",
    "text": "Solutions for strongly correlated coefficients\n\nReparametrize the model to decorrelate variables (orthogonal parametrization).\nBlock updates: draw correlated parameters together\n\nusing the chain history to learn the correlation, if necessary"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#parameter-transformation",
    "href": "slides/bayesmod-slides5.html#parameter-transformation",
    "title": "Bayesian modelling",
    "section": "Parameter transformation",
    "text": "Parameter transformation\nParameters may be bounded, e.g. \\(\\theta_i \\in [a,b]\\).\n\nWe can ignore this and simply discard proposals outside of the range, by setting the log posterior at \\(-\\infty\\) outside \\([a,b]\\)\nWe can do a transformation, e.g., \\(\\log \\theta_i\\) if \\(\\theta_i &gt; 0\\) and perform a random walk on the unconstrained space: don’t forget Jacobians for \\(q(\\cdot)\\)!\nAnother alternative is to use truncated proposals (useful with more complex algorithms like MALA)"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#efficient-proposals-mala",
    "href": "slides/bayesmod-slides5.html#efficient-proposals-mala",
    "title": "Bayesian modelling",
    "section": "Efficient proposals: MALA",
    "text": "Efficient proposals: MALA\nThe Metropolis-adjusted Langevin algorithm (MALA) uses a Gaussian random walk proposal \\[\\boldsymbol{\\theta}^{\\star}_t \\sim \\mathsf{Gauss}\\{\\mu(\\boldsymbol{\\theta}_{t-1}), \\tau^2\\mathbf{A}\\},\\] with mean \\[\\mu(\\boldsymbol{\\theta}_{t-1})=\\boldsymbol{\\theta}_{t-1} + \\mathbf{A}\\eta \\nabla \\log p(\\boldsymbol{\\theta}_{t-1} \\mid \\boldsymbol{y}),\\] and variance \\(\\tau^2\\mathbf{A}\\), for some mass matrix \\(\\mathbf{A}\\), tuning parameter \\(\\tau&gt;0\\).\nThe parameter \\(\\eta &lt; 1\\) is a learning rate. This is akin to a Newton algorithm, so beware if you are far from the mode (where the gradient is typically large)!"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#higher-order-proposals",
    "href": "slides/bayesmod-slides5.html#higher-order-proposals",
    "title": "Bayesian modelling",
    "section": "Higher order proposals",
    "text": "Higher order proposals\nFor a single parameter update \\(\\theta\\), a Taylor series expansion of the log posterior around the current value suggests using as proposal density a Gaussian approximation with (Rue & Held, 2005)\n\nmean \\(\\mu_{t-1} = \\theta_{t-1} - f'(\\theta_{t-1})/f''(\\theta_{t-1})\\) and\nprecision \\(\\tau^{-2} = -f''(\\theta_{t-1})\\)\n\nWe need \\(f''(\\theta_{t-1})\\) to be negative!\nThis gives local adaption relative to MALA (global variance)."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#higher-order-and-moves",
    "href": "slides/bayesmod-slides5.html#higher-order-and-moves",
    "title": "Bayesian modelling",
    "section": "Higher order and moves",
    "text": "Higher order and moves\nFor MALA and cie., we need to compute the density of the proposal also for the reverse move for the expansion starting from the proposal \\(\\mu(\\boldsymbol{\\theta}_{t}^\\star)\\).\nThese methods are more efficient than random walk Metropolis–Hastings, but they require the gradient and the hessian (can be obtained analytically using autodiff, or numerically)."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#modelling-individual-headlines-of-upworthy-example",
    "href": "slides/bayesmod-slides5.html#modelling-individual-headlines-of-upworthy-example",
    "title": "Bayesian modelling",
    "section": "Modelling individual headlines of Upworthy example",
    "text": "Modelling individual headlines of Upworthy example\nThe number of conversions nclick is binomial with sample size \\(n_i=\\)nimpression.\nSince \\(n_i\\) is large, the sample average nclick/nimpression is approximately Gaussian, so write\n\\[\\begin{align*}\nY_i &\\sim \\mathsf{Gauss}(\\mu, \\sigma^2/n_i)\\\\\n\\mu &\\sim \\mathsf{trunc. Gauss}(0.01, 0.1^2, 0, 1) \\\\\n\\sigma &\\sim \\mathsf{expo}(0.7)\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#mala-data-set-up",
    "href": "slides/bayesmod-slides5.html#mala-data-set-up",
    "title": "Bayesian modelling",
    "section": "MALA: data set-up",
    "text": "MALA: data set-up\n\ndata(upworthy_question, package = \"hecbayes\")\n# Select data for a single question\nqdata &lt;- upworthy_question |&gt;\n  dplyr::filter(question == \"yes\") |&gt;\n  dplyr::mutate(y = clicks/impressions,\n                no = impressions)"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#mala-define-functions",
    "href": "slides/bayesmod-slides5.html#mala-define-functions",
    "title": "Bayesian modelling",
    "section": "MALA: define functions",
    "text": "MALA: define functions\n\n# Create functions with the same signature (...) for the algorithm\nlogpost &lt;- function(par, data, ...){\n  mu &lt;- par[1]; sigma &lt;- par[2]\n  no &lt;- data$no\n  y &lt;- data$y\n  if(isTRUE(any(sigma &lt;= 0, mu &lt; 0, mu &gt; 1))){\n    return(-Inf)\n  }\n  dnorm(x = mu, mean = 0.01, sd = 0.1, log = TRUE) +\n  dexp(sigma, rate = 0.7, log = TRUE) + \n  sum(dnorm(x = y, mean = mu, sd = sigma/sqrt(no), log = TRUE))\n}"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#mala-compute-gradient-of-log-posterior",
    "href": "slides/bayesmod-slides5.html#mala-compute-gradient-of-log-posterior",
    "title": "Bayesian modelling",
    "section": "MALA: compute gradient of log posterior",
    "text": "MALA: compute gradient of log posterior\n\nlogpost_grad &lt;- function(par, data, ...){\n   no &lt;- data$no\n  y &lt;- data$y\n  mu &lt;- par[1]; sigma &lt;- par[2]\n  c(sum(no*(y-mu))/sigma^2 -(mu - 0.01)/0.01,\n    -length(y)/sigma + sum(no*(y-mu)^2)/sigma^3 -0.7\n  )\n}"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#mala-compute-maximum-a-posteriori",
    "href": "slides/bayesmod-slides5.html#mala-compute-maximum-a-posteriori",
    "title": "Bayesian modelling",
    "section": "MALA: compute maximum a posteriori",
    "text": "MALA: compute maximum a posteriori\n\n# Starting values - MAP\nmap &lt;- optim(\n  par = c(mean(qdata$y), 0.5),\n  fn = function(x){-logpost(x, data = qdata)},\n  gr = function(x){-logpost_grad(x, data = qdata)},  \n  hessian = TRUE,\n  method = \"BFGS\")\n# Check convergence \nlogpost_grad(map$par, data = qdata)"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#mala-starting-values-and-mass-matrix",
    "href": "slides/bayesmod-slides5.html#mala-starting-values-and-mass-matrix",
    "title": "Bayesian modelling",
    "section": "MALA: starting values and mass matrix",
    "text": "MALA: starting values and mass matrix\n\n# Set initial parameter values\ncurr &lt;- map$par \n# Compute a mass matrix\nAmat &lt;- solve(map$hessian)\n# Cholesky root - for random number generation\ncholA &lt;- chol(Amat)"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#mala-containers-and-setup",
    "href": "slides/bayesmod-slides5.html#mala-containers-and-setup",
    "title": "Bayesian modelling",
    "section": "MALA: containers and setup",
    "text": "MALA: containers and setup\n\n# Create containers for MCMC\nB &lt;- 1e4L # number of iterations\nwarmup &lt;- 1e3L # adaptation period\nnpar &lt;- 2L\nprop_sd &lt;- rep(1, npar) # tuning parameter\nchains &lt;- matrix(nrow = B, ncol = npar)\ndamping &lt;- 0.8\nacceptance &lt;- attempts &lt;- 0 \ncolnames(chains) &lt;- names(curr) &lt;- c(\"mu\",\"sigma\")\n# Proposal variance proportional to inverse hessian at MAP\nprop_var &lt;- diag(prop_sd) %*% Amat %*% diag(prop_sd)"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#mala-sample-proposal-with-newton-step",
    "href": "slides/bayesmod-slides5.html#mala-sample-proposal-with-newton-step",
    "title": "Bayesian modelling",
    "section": "MALA: sample proposal with Newton step",
    "text": "MALA: sample proposal with Newton step\n\nfor(i in seq_len(B + warmup)){\n  ind &lt;- pmax(1, i - warmup)\n  # Compute the proposal mean for the Newton step\n  prop_mean &lt;- c(curr + damping * \n     Amat %*% logpost_grad(curr, data = qdata))\n  # prop &lt;- prop_sd * c(rnorm(npar) %*% cholA) + prop_mean\n  prop &lt;- c(mvtnorm::rmvnorm(\n    n = 1,\n    mean = prop_mean, \n    sigma = prop_var))\n#  [...]"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#mala-reverse-step",
    "href": "slides/bayesmod-slides5.html#mala-reverse-step",
    "title": "Bayesian modelling",
    "section": "MALA: reverse step",
    "text": "MALA: reverse step\n\n  # Compute the reverse step\n  curr_mean &lt;- c(prop + damping * \n     Amat %*% logpost_grad(prop, data = qdata))\n  # log of ratio of bivariate Gaussian densities\n  logmh &lt;- mvtnorm::dmvnorm(\n    x = curr, mean = prop_mean, \n    sigma = prop_var, \n    log = TRUE) - \n    mvtnorm::dmvnorm(\n      x = prop, \n      mean = curr_mean, \n      sigma = prop_var, \n      log = TRUE) + \n  logpost(prop, data = qdata) - \n    logpost(curr, data = qdata)"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#mala-metropolishastings-ratio",
    "href": "slides/bayesmod-slides5.html#mala-metropolishastings-ratio",
    "title": "Bayesian modelling",
    "section": "MALA: Metropolis–Hastings ratio",
    "text": "MALA: Metropolis–Hastings ratio\n\n  if(logmh &gt; log(runif(1))){\n    curr &lt;- prop\n    acceptance &lt;- acceptance + 1L\n  }\n  attempts &lt;- attempts + 1L\n  # Save current value\n  chains[ind,] &lt;- curr"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#mala-adaptation",
    "href": "slides/bayesmod-slides5.html#mala-adaptation",
    "title": "Bayesian modelling",
    "section": "MALA: adaptation",
    "text": "MALA: adaptation\n\n  if(i %% 100 & i &lt; warmup){\n    # Check acceptance rate and increase/decrease variance\n    out &lt;- hecbayes::adaptive(\n      attempts = attempts, # counter for number of attempts\n      acceptance = acceptance, \n      sd.p = prop_sd, #current proposal standard deviation\n      target = 0.574) # target acceptance rate\n    prop_sd &lt;- out$sd # overwrite current std.dev\n    acceptance &lt;- out$acc # if we change std. dev, this is set to zero\n    attempts &lt;- out$att # idem, otherwise unchanged\n    prop_var &lt;- diag(prop_sd) %*% Amat %*% diag(prop_sd)\n  }\n} # End of MCMC for loop"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#gibbs-sampling",
    "href": "slides/bayesmod-slides5.html#gibbs-sampling",
    "title": "Bayesian modelling",
    "section": "Gibbs sampling",
    "text": "Gibbs sampling\nThe Gibbs sampling algorithm builds a Markov chain by iterating through a sequence of conditional distributions.\n\n\nFigure 3: Sampling trajectory for a bivariate target using Gibbs sampling."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#gibbs-sampler",
    "href": "slides/bayesmod-slides5.html#gibbs-sampler",
    "title": "Bayesian modelling",
    "section": "Gibbs sampler",
    "text": "Gibbs sampler\nSplit the parameter vector \\(\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta} \\subseteq \\mathbb{R}^p\\) into \\(m \\leq p\\) blocks, \\[\\boldsymbol{\\theta}^{[j]}\\quad j=1, \\ldots, m\\] such that, conditional on the remaining components of the parameter vector \\(\\boldsymbol{\\theta}^{-[j]}\\), the conditional posterior \\[p(\\boldsymbol{\\theta}^{[j]} \\mid \\boldsymbol{\\theta}^{-[j]}, \\boldsymbol{y})\\] is from a known distribution from which we can easily simulate."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#gibbs-sampling-update",
    "href": "slides/bayesmod-slides5.html#gibbs-sampling-update",
    "title": "Bayesian modelling",
    "section": "Gibbs sampling update",
    "text": "Gibbs sampling update\nAt iteration \\(t\\), we can update each block in turn: note that the \\(k\\)th block uses the partially updated state \\[\\begin{align*}\n\\boldsymbol{\\theta}^{-[k]\\star} = (\\boldsymbol{\\theta}_{t}^{[1]}, \\ldots, \\boldsymbol{\\theta}_{t}^{[k-1]},\\boldsymbol{\\theta}_{t-1}^{[k+1]}, \\boldsymbol{\\theta}_{t-1}^{[m]})\n\\end{align*}\\] which corresponds to the current value of the parameter vector after the updates."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#notes-on-gibbs-sampling",
    "href": "slides/bayesmod-slides5.html#notes-on-gibbs-sampling",
    "title": "Bayesian modelling",
    "section": "Notes on Gibbs sampling",
    "text": "Notes on Gibbs sampling\n\nSpecial case of Metropolis–Hastings with conditional density as proposal \\(q\\).\nThe benefit is that all proposals get accepted, \\(R=1\\)!\nNo tuning parameter, but parametrization matters.\nAutomatic acceptance does not equal efficiency.\n\nTo check the validity of the Gibbs sampler, see the methods proposed in Geweke (2004)."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#efficiency-of-gibbs-sampling",
    "href": "slides/bayesmod-slides5.html#efficiency-of-gibbs-sampling",
    "title": "Bayesian modelling",
    "section": "Efficiency of Gibbs sampling",
    "text": "Efficiency of Gibbs sampling\nAs the dimension of the parameter space increases, and as the correlation between components becomes larger, the efficiency of the Gibbs sampler degrades\n\n\nFigure 4: Trace plots (top) and correlograms (bottom) for the first component of a Gibbs sampler with \\(d=20\\) equicorrelated Gaussian variates with correlation \\(\\rho=0.9\\) (left) and \\(d=3\\) with equicorrelation \\(\\rho=0.5\\) (right)."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#gibbs-sampling-requires-work",
    "href": "slides/bayesmod-slides5.html#gibbs-sampling-requires-work",
    "title": "Bayesian modelling",
    "section": "Gibbs sampling requires work!",
    "text": "Gibbs sampling requires work!\n\nYou need to determine all of the relevant conditional distributions, which often relies on setting conditionally conjugate priors.\nIn large models with multiple layers, full conditionals may only depend on a handful of parameters (via directed acyclic graph and moral graph of the model; not covered)."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#example-of-gibbs-sampling",
    "href": "slides/bayesmod-slides5.html#example-of-gibbs-sampling",
    "title": "Bayesian modelling",
    "section": "Example of Gibbs sampling",
    "text": "Example of Gibbs sampling\nConsider independent and identically distributed observations, with \\[\\begin{align*}\nY_i &\\sim \\mathsf{Gauss}(\\mu, \\tau), \\qquad i=1, \\ldots, n)\n\\\\\\mu &\\sim \\mathsf{Gauss}(\\nu, \\omega)\\\\\n\\tau &\\sim \\mathsf{inv. gamma}(\\alpha, \\beta)\n\\end{align*}\\]\nThe joint posterior is not available in closed form, but the independent priors for the mean and variance of the observations are conditionally conjugate."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#joint-posterior-for-gibbs-sample",
    "href": "slides/bayesmod-slides5.html#joint-posterior-for-gibbs-sample",
    "title": "Bayesian modelling",
    "section": "Joint posterior for Gibbs sample",
    "text": "Joint posterior for Gibbs sample\nWrite the posterior density as usual, \\[\\begin{align*}\n&p(\\mu, \\tau \\mid \\boldsymbol{y}) \\propto \\tau^{-\\alpha-1}\\exp(-\\beta/\\tau)\\\\ &\\quad \\times \\tau^{-n/2}\\exp\\left\\{-\\frac{1}{2\\tau}\\left(\\sum_{i=1}^n y_i^2 - 2\\mu \\sum_{i=1}^n y_i+n\\mu^2 \\right)\\right\\}\\\\&\\quad \\times \\exp\\left\\{-\\frac{(\\mu-\\nu)^2}{2\\omega}\\right\\}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#recognizing-distributions-from-posterior",
    "href": "slides/bayesmod-slides5.html#recognizing-distributions-from-posterior",
    "title": "Bayesian modelling",
    "section": "Recognizing distributions from posterior",
    "text": "Recognizing distributions from posterior\nConsider the conditional densities of each parameter in turn (up to proportionality): \\[\\begin{align*}\np(\\mu \\mid \\tau, \\boldsymbol{y}) &\\propto \\exp\\left\\{-\\frac{1}{2} \\left( \\frac{\\mu^2-2\\mu\\overline{y}}{\\tau/n} + \\frac{\\mu^2-2\\nu \\mu}{\\omega}\\right)\\right\\}\\\\\np(\\tau \\mid \\mu, \\boldsymbol{y}) & \\propto \\tau^{-n/2-\\alpha-1}\\exp\\left[-\\frac{\\left\\{\\frac{\\sum_{i=1}^n (y_i-\\mu)^2}{2} + \\beta \\right\\}}{\\tau}\\right]\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#gibs-sample",
    "href": "slides/bayesmod-slides5.html#gibs-sample",
    "title": "Bayesian modelling",
    "section": "Gibs sample",
    "text": "Gibs sample\nWe can simulate in turn \\[\\begin{align*}\n\\mu_t \\mid \\tau_{t-1}, \\boldsymbol{y} &\\sim \\mathsf{Gauss}\\left(\\frac{n\\overline{y}\\omega+\\tau \\nu}{\\tau + n\\omega}, \\frac{\\omega \\tau}{\\tau + n\\omega}\\right)\\\\\n\\tau_t \\mid \\mu_t, \\boldsymbol{y} &\\sim \\mathsf{inv. gamma}\\left\\{\\frac{n}{2}+\\alpha, \\frac{\\sum_{i=1}^n (y_i-\\mu)^2}{2} + \\beta\\right\\}.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#data-augmentation-and-auxiliary-variables",
    "href": "slides/bayesmod-slides5.html#data-augmentation-and-auxiliary-variables",
    "title": "Bayesian modelling",
    "section": "Data augmentation and auxiliary variables",
    "text": "Data augmentation and auxiliary variables\nWhen the likelihood \\(p(\\boldsymbol{y}; \\boldsymbol{\\theta})\\) is intractable or costly to evaluate (e.g., mixtures, missing data, censoring), auxiliary variables are introduced to simplify calculations.\nConsider auxiliary variables \\(\\boldsymbol{U} \\in \\mathbb{R}^k\\) such that \\[\\int_{\\mathbb{R}^k} p(\\boldsymbol{U}, \\boldsymbol{\\theta}\\mid \\boldsymbol{y}) \\mathrm{d} \\boldsymbol{U} = p(\\boldsymbol{\\theta}\\mid \\boldsymbol{y}),\\] i.e., the marginal distribution is that of interest, but evaluation of \\(p(\\boldsymbol{U}, \\boldsymbol{\\theta}; \\boldsymbol{y})\\) is cheaper."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#bayesian-augmentation",
    "href": "slides/bayesmod-slides5.html#bayesian-augmentation",
    "title": "Bayesian modelling",
    "section": "Bayesian augmentation",
    "text": "Bayesian augmentation\nThe data augmentation algorithm (Tanner & Wong, 1987) consists in running a Markov chain on the augmented state space \\((\\Theta, \\mathbb{R}^k)\\), simulating in turn from the conditionals\n\n\\(p(\\boldsymbol{U}\\mid \\boldsymbol{\\theta}, \\boldsymbol{y})\\) and\n\\(p(\\boldsymbol{\\theta}\\mid \\boldsymbol{U}, \\boldsymbol{y})\\)\n\nFor more details and examples, see Dyk & Meng (2001) and Hobert (2011)."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#data-augmentation-probit-example",
    "href": "slides/bayesmod-slides5.html#data-augmentation-probit-example",
    "title": "Bayesian modelling",
    "section": "Data augmentation: probit example",
    "text": "Data augmentation: probit example\nConsider independent binary responses \\(\\boldsymbol{Y}_i\\), with \\[\\begin{align*}\np_i = \\Pr(Y_i=1) = \\Phi(\\beta_0 + \\beta_1 \\mathrm{X}_{i1} + \\cdots + \\beta_p\\mathrm{X}_{ip}),\n\\end{align*}\\] where \\(\\Phi\\) is the distribution function of the standard Gaussian distribution. The likelihood of the probit model is \\[L(\\boldsymbol{\\beta}; \\boldsymbol{y}) = \\prod_{i=1}^n p_i^{y_i}(1-p_i)^{1-y_i},\\] and this prevents easy simulation."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#probit-augmentation",
    "href": "slides/bayesmod-slides5.html#probit-augmentation",
    "title": "Bayesian modelling",
    "section": "Probit augmentation",
    "text": "Probit augmentation\nWe can consider a data augmentation scheme where \\(Y_i = \\mathrm{I}(Z_i &gt; 0)\\), where \\(Z_i \\sim \\mathsf{Gauss}(\\mathbf{x}_i\\boldsymbol{\\beta}, 1)\\), where \\(\\mathbf{x}_i\\) is the \\(i\\)th row of the design matrix.\nThe augmented data likelihood is \\[\\begin{align*}\np(\\boldsymbol{z}, \\boldsymbol{y} \\mid \\boldsymbol{\\beta}) &\\propto \\exp\\left\\{-\\frac{1}{2}(\\boldsymbol{z} - \\mathbf{X}\\boldsymbol{\\beta})^\\top(\\boldsymbol{z} - \\mathbf{X}\\boldsymbol{\\beta})\\right\\} \\\\&\\quad \\times \\prod_{i=1}^n \\mathrm{I}(z_i &gt; 0)^{y_i}\\mathrm{I}(z_i \\le 0)^{1-y_i}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#conditional-distributions-for-probit-regression",
    "href": "slides/bayesmod-slides5.html#conditional-distributions-for-probit-regression",
    "title": "Bayesian modelling",
    "section": "Conditional distributions for probit regression",
    "text": "Conditional distributions for probit regression\n\\[\\begin{align*}\n\\boldsymbol{\\beta} \\mid \\boldsymbol{z}, \\boldsymbol{y} &\\sim \\mathsf{Gauss}\\left\\{\\widehat{\\boldsymbol{\\beta}}, (\\mathbf{X}^\\top\\mathbf{X})^{-1}\\right\\}\\\\\nZ_i \\mid y_i, \\boldsymbol{\\beta} &\\sim \\begin{cases}\n\\mathsf{trunc. Gauss}(\\mathbf{x}_i\\boldsymbol{\\beta}, -\\infty, 0) & y_i =0 \\\\\n\\mathsf{trunc. Gauss}(\\mathbf{x}_i\\boldsymbol{\\beta}, 0, \\infty) & y_i =1.\n\\end{cases}\n\\end{align*}\\] with \\(\\widehat{\\boldsymbol{\\beta}}=(\\mathbf{X}^\\top\\mathbf{X})^{-1}\\mathbf{X}^\\top\\boldsymbol{z}\\) the ordinary least square estimator."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#data-augmentation-with-scale-mixture-of-gaussian",
    "href": "slides/bayesmod-slides5.html#data-augmentation-with-scale-mixture-of-gaussian",
    "title": "Bayesian modelling",
    "section": "Data augmentation with scale mixture of Gaussian",
    "text": "Data augmentation with scale mixture of Gaussian\nThe Laplace distribution with mean \\(\\mu\\) and scale \\(\\sigma\\) has density \\[\\begin{align*}\nf(x; \\mu, \\sigma) = \\frac{1}{2\\sigma}\\exp\\left(-\\frac{|x-\\mu|}{\\sigma}\\right),\n\\end{align*}\\] and can be expressed as a scale mixture of Gaussians, where \\(Y \\mid \\tau \\sim \\mathsf{Laplace}(\\mu, \\tau)\\) is equivalent to \\(Z \\mid \\tau \\sim \\mathsf{Gauss}(\\mu, \\tau)\\) and \\(\\tau \\sim \\mathsf{expo}\\{(2\\sigma)^{-1}\\}\\)."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#joint-posterior-for-laplace-model",
    "href": "slides/bayesmod-slides5.html#joint-posterior-for-laplace-model",
    "title": "Bayesian modelling",
    "section": "Joint posterior for Laplace model",
    "text": "Joint posterior for Laplace model\nWith \\(p(\\mu, \\sigma) \\propto \\sigma^{-1}\\), the joint posterior for the i.i.d. sample is \\[\\begin{align*}\np(\\boldsymbol{\\tau}, \\mu, \\sigma \\mid \\boldsymbol{y}) &\\propto \\left(\\prod_{i=1}^n \\tau_i\\right)^{-1/2}\\exp\\left\\{-\\frac{1}{2}\\sum_{i=1}^n \\frac{(y_i-\\mu)^2}{\\tau_i}\\right\\} \\\\&\\quad \\times \\frac{1}{\\sigma^{n+1}}\\exp\\left(-\\frac{1}{2\\sigma}\\sum_{i=1}^n \\tau_i\\right)\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#conditional-distributions",
    "href": "slides/bayesmod-slides5.html#conditional-distributions",
    "title": "Bayesian modelling",
    "section": "Conditional distributions",
    "text": "Conditional distributions\nThe conditionals for \\(\\mu \\mid \\cdots\\) and \\(\\sigma \\mid \\cdots\\) are, as usual, Gaussian and inverse gamma, respectively. The variances, \\(\\tau_j\\), are conditionally independent of one another, with \\[\\begin{align*}\np(\\tau_j \\mid \\mu, \\sigma, y_j) &\\propto \\tau_j^{-1/2}\\exp\\left\\{-\\frac{1}{2}\\frac{(y_j-\\mu)^2}{\\tau_j} -\\frac{1}{2} \\frac{\\tau_j}{\\sigma}\\right\\}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#inverse-transformation",
    "href": "slides/bayesmod-slides5.html#inverse-transformation",
    "title": "Bayesian modelling",
    "section": "Inverse transformation",
    "text": "Inverse transformation\nWith the change of variable \\(\\xi_j=1/\\tau_j\\), we have \\[\\begin{align*}\np(\\xi_j \\mid \\mu, \\sigma, y_j) &\\propto \\xi_j^{-3/2}\\exp\\left\\{-\\frac{1}{2\\sigma}\\frac{\\xi_j(y_j-\\mu)^2}{\\sigma} -\\frac{1}{2} \\frac{1}{\\xi_j}\\right\\}\\\\\n\\end{align*}\\] and we recognize the Wald (or inverse Gaussian) density, where \\(\\xi_i \\sim \\mathsf{Wald}(\\nu_i, \\lambda)\\) with \\(\\nu_i=\\{\\sigma/(y_i-\\mu)^2\\}^{1/2}\\) and \\(\\lambda=\\sigma^{-1}\\)."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#bayesian-lasso",
    "href": "slides/bayesmod-slides5.html#bayesian-lasso",
    "title": "Bayesian modelling",
    "section": "Bayesian LASSO",
    "text": "Bayesian LASSO\nPark & Casella (2008) use this hierarchical construction to defined the Bayesian LASSO. With a model matrix \\(\\mathbf{X}\\) whose columns are standardized to have mean zero and unit standard deviation, we may write \\[\\begin{align*}\n\\boldsymbol{Y} \\mid \\mu, \\boldsymbol{\\beta}, \\sigma^2 &\\sim  \\mathsf{Gauss}_n(\\mu \\boldsymbol{1}_n + \\mathbf{X}\\boldsymbol{\\beta}, \\sigma \\mathbf{I}_n)\\\\\n\\beta_j \\mid \\sigma, \\tau &\\sim \\mathsf{Gauss}(0, \\sigma\\tau)\\\\\n\\tau &\\sim \\mathsf{expo}(\\lambda/2)\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#comment-about-bayesian-lasso",
    "href": "slides/bayesmod-slides5.html#comment-about-bayesian-lasso",
    "title": "Bayesian modelling",
    "section": "Comment about Bayesian LASSO",
    "text": "Comment about Bayesian LASSO\n\nIf we set an improper prior \\(p(\\mu, \\sigma) \\propto \\sigma^{-1}\\), the resulting conditional distributions are all available and thus the model is amenable to Gibbs sampling.\nThe Bayesian LASSO places a Laplace penalty on the regression coefficients, with lower values of \\(\\lambda\\) yielding more shrinkage.\nContrary to the frequentist setting, none of the posterior draws of \\(\\boldsymbol{\\beta}\\) are exactly zero."
  },
  {
    "objectID": "slides/bayesmod-slides5.html#summary",
    "href": "slides/bayesmod-slides5.html#summary",
    "title": "Bayesian modelling",
    "section": "Summary",
    "text": "Summary\n\nGibbs sampling is a special case of Metropolis–Hastings algorithm that leads to acceptance\nWe need to get the conditional distribution"
  },
  {
    "objectID": "slides/bayesmod-slides5.html#references",
    "href": "slides/bayesmod-slides5.html#references",
    "title": "Bayesian modelling",
    "section": "References",
    "text": "References\n\n\n\n\nDyk, D. A. van, & Meng, X.-L. (2001). The art of data augmentation. Journal of Computational and Graphical Statistics, 10(1), 1–50. https://doi.org/10.1198/10618600152418584\n\n\nGeweke, J. (2004). Getting it right: Joint distribution tests of posterior simulators. Journal of the American Statistical Association, 99(467), 799–804. https://doi.org/10.1198/016214504000001132\n\n\nHobert, J. P. (2011). The data augmentation algorithm: Theory and methodology. In S. Brooks, A. Gelman, G. Jones, & X. L. Meng (Eds.), Handbook of Markov chain Monte Carlo (pp. 253–294). CRC Press. https://doi.org/10.1201/b10905\n\n\nPark, T., & Casella, G. (2008). The Bayesian Lasso. Journal of the American Statistical Association, 103(482), 681–686. https://doi.org/10.1198/016214508000000337\n\n\nRue, H., & Held, L. (2005). Gaussian Markov random fields: Theory and applications (p. 280). CRC Press.\n\n\nSherlock, C. (2013). Optimal scaling of the random walk Metropolis: General criteria for the 0.234 acceptance rule. Journal of Applied Probability, 50(1), 1–15. https://doi.org/10.1239/jap/1363784420\n\n\nTanner, M. A., & Wong, W. H. (1987). The calculation of posterior distributions by data augmentation. Journal of the American Statistical Association, 82(398), 528–540. https://doi.org/10.1080/01621459.1987.10478458"
  },
  {
    "objectID": "slides/bayesmod-slides7.html#curse-of-dimensionality",
    "href": "slides/bayesmod-slides7.html#curse-of-dimensionality",
    "title": "Bayesian modelling",
    "section": "Curse of dimensionality",
    "text": "Curse of dimensionality\nThis material is drawn from\n\nNeal (2011),\nBetancourt (2017)\n\nCheck out these animations by Chi Feng"
  },
  {
    "objectID": "slides/bayesmod-slides7.html#motivation",
    "href": "slides/bayesmod-slides7.html#motivation",
    "title": "Bayesian modelling",
    "section": "Motivation",
    "text": "Motivation\nWe are interested in calculating expectations of some function \\(g\\) against the posterior. \\[\\begin{align*}\n\\int_{\\mathbb{R}^d} g(\\boldsymbol{\\theta}) p(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}) \\mathrm{d} \\boldsymbol{\\theta}.\n\\end{align*}\\]\nThe integral is determined by the product of the ``volume’’ of \\(g(\\cdot)\\) and the density."
  },
  {
    "objectID": "slides/bayesmod-slides7.html#curse-of-dimensionality-1",
    "href": "slides/bayesmod-slides7.html#curse-of-dimensionality-1",
    "title": "Bayesian modelling",
    "section": "Curse of dimensionality",
    "text": "Curse of dimensionality\nAs the dimension of the posterior, \\(d\\), grows, the mass concentrates in a small region, the so-called typical set. The number of regions/directions to consider increases exponentially in \\(d\\).\nIf we start at the stationary distribution, most proposals from a random walk Metropolis will fall outside of the typical set and get rejected.\nThis phenomenon also explains the decrease in performance of numerical integration schemes (quadrature)."
  },
  {
    "objectID": "slides/bayesmod-slides7.html#better-informed-proposals",
    "href": "slides/bayesmod-slides7.html#better-informed-proposals",
    "title": "Bayesian modelling",
    "section": "Better informed proposals",
    "text": "Better informed proposals\nFor differentiable targets, we saw that we can do better than random walk Metropolis–Hastings.\n\nIdea: use the gradient to make an informed proposal (e.g., in MALA)\nThere are two remaining challenges.\n\nit makes a single step from the current position. But why stop at one?\nthe gradient needs not be aligned with the typical set (Betancourt analogy with satellite in orbit)."
  },
  {
    "objectID": "slides/bayesmod-slides7.html#hamiltonian-monte-carlo",
    "href": "slides/bayesmod-slides7.html#hamiltonian-monte-carlo",
    "title": "Bayesian modelling",
    "section": "Hamiltonian Monte Carlo",
    "text": "Hamiltonian Monte Carlo\nHamitonian Monte Carlo borrows ideas from Hamiltonian dynamics.\nConsider the evolution over time of a particle characterized by a\n\nposition \\(\\boldsymbol{\\theta} \\in \\mathbb{R}^d\\) along with potential energy \\(U(\\boldsymbol{\\theta})=- \\log p(\\boldsymbol{\\theta} \\mid \\boldsymbol{y})\\)\nan added auxiliary vector \\(\\boldsymbol{s} \\in \\mathbb{R}^d\\) of momentum (describing mass and velocity) with accompaying kinetic energy \\(K(\\boldsymbol{s})= -\\log p(\\boldsymbol{s})\\)."
  },
  {
    "objectID": "slides/bayesmod-slides7.html#hamiltonian",
    "href": "slides/bayesmod-slides7.html#hamiltonian",
    "title": "Bayesian modelling",
    "section": "Hamiltonian",
    "text": "Hamiltonian\nWrite the negative of the log of the joint density as \\[H(\\boldsymbol{\\theta}, \\boldsymbol{s}) = -\\log p(\\boldsymbol{s}) - \\log p(\\boldsymbol{\\theta}) = U(\\boldsymbol{\\theta}) + K(\\boldsymbol{s}).\\]\nThe partial derivatives of the Hamiltonian give the evolution over time of the system: \\[\\begin{align*}\n\\frac{\\mathrm{d} \\theta_j}{\\mathrm{d} t} = \\frac{\\partial H}{\\partial s_j} &= \\frac{\\partial K}{\\partial s_j}\\\\\n\\frac{\\mathrm{d} s_j}{\\mathrm{d} t}= - \\frac{\\partial H}{\\partial \\theta_j} &= - \\frac{\\partial U}{\\partial \\theta_j}, \\quad j =1, \\ldots, d.\n\\end{align*}\\]\nThere is no explicit solution to these differential equations in most settings."
  },
  {
    "objectID": "slides/bayesmod-slides7.html#kinetic-energy",
    "href": "slides/bayesmod-slides7.html#kinetic-energy",
    "title": "Bayesian modelling",
    "section": "Kinetic energy",
    "text": "Kinetic energy\nThe most popular choice of kinetic energy is the Gaussian, \\[\\begin{align*}\nK(\\boldsymbol{s}) = \\frac{1}{2} \\boldsymbol{s}^\\top \\mathbf{M}^{-1}\\boldsymbol{s}\n\\end{align*}\\] the negative of a mean zero log Gaussian density with positive-definite covariance matrix \\(\\mathbf{M}.\\)\nTypically, we take \\(\\mathbf{M}=\\mathrm{diag}\\{m_1, \\ldots, m_d\\}\\) diagonal, or else proportional \\(\\mathbf{M} = m \\mathbf{I}_d\\)."
  },
  {
    "objectID": "slides/bayesmod-slides7.html#properties-of-hamiltonian-dynamics",
    "href": "slides/bayesmod-slides7.html#properties-of-hamiltonian-dynamics",
    "title": "Bayesian modelling",
    "section": "Properties of Hamiltonian dynamics",
    "text": "Properties of Hamiltonian dynamics\nThe mapping \\(T_s\\) from time \\(t\\) at \\((\\boldsymbol{\\theta}(t), \\boldsymbol{s}(t))\\) to time \\(t + \\varepsilon\\), \\((\\boldsymbol{\\theta}(t + \\varepsilon), \\boldsymbol{s}(t + \\varepsilon))\\) satisfies the following properties:\n\nReversible: MCMC will thus preserve the invariant target distribution\nConservation of energy: proposals from Hamiltonian dynamics would lead to acceptance probability of 1.\nSymplecticness/volume preserving: the Jacobian of \\(T_s\\) is one — no need to calculate it."
  },
  {
    "objectID": "slides/bayesmod-slides7.html#a-necessary-discretization-step",
    "href": "slides/bayesmod-slides7.html#a-necessary-discretization-step",
    "title": "Bayesian modelling",
    "section": "A necessary discretization step",
    "text": "A necessary discretization step\nThere is no explicit solution to the Hamiltonian differential equation. We must move away from continuous time…\n\nFor solving the differential equation numerically, Euler’s method doesn’t work because it does not preserve volume, and this leads to divergences."
  },
  {
    "objectID": "slides/bayesmod-slides7.html#leapfrog-integrator",
    "href": "slides/bayesmod-slides7.html#leapfrog-integrator",
    "title": "Bayesian modelling",
    "section": "Leapfrog integrator",
    "text": "Leapfrog integrator\nThe leapfrog integrator performs a half step for momentum, then does a full step for the position using the updated components, etc.\n\\[\\begin{align*}\ns_j(t+\\varepsilon/2) &= s_j(t) - \\frac{\\varepsilon}{2}  \\left.\\frac{\\partial U(\\boldsymbol{\\theta})}{\\partial \\theta_j}\\right|_{\\boldsymbol{\\theta}(t)}\n\\\\\n\\theta_j(t+\\varepsilon) &= \\theta_j(t)  + \\varepsilon \\frac{s_j(t+\\varepsilon/2)}{m_j} \\\\\ns_j(t+\\varepsilon) &= s_j(t+\\varepsilon/2) - \\frac{\\varepsilon}{2}  \\left.\\frac{\\partial U(\\boldsymbol{\\theta})}{\\partial \\theta_j}\\right|_{\\boldsymbol{\\theta}(t + \\varepsilon)}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/bayesmod-slides7.html#hamiltonian-monte-carlo-algorithm",
    "href": "slides/bayesmod-slides7.html#hamiltonian-monte-carlo-algorithm",
    "title": "Bayesian modelling",
    "section": "Hamiltonian Monte Carlo algorithm",
    "text": "Hamiltonian Monte Carlo algorithm\nConsider the joint distribution with positions \\(\\boldsymbol{\\theta}\\) and momentum variables \\(\\boldsymbol{s}\\), \\(p(\\boldsymbol{\\theta}, \\boldsymbol{s}) \\propto \\exp \\{- H(\\boldsymbol{\\theta}, \\boldsymbol{s})\\}.\\)\nWe start with a position vector \\(\\boldsymbol{\\theta}_{t-1}\\) at step \\(t-1\\):\n\nSample a new momentum vector \\(\\boldsymbol{s}_{t-1} \\sim \\mathsf{Gauss}(\\boldsymbol{0}_d, \\mathbf{M}).\\)\nUse Verlet’s (leapfrog) integrator to evolve the state vector for \\(L=\\lfloor\\tau/\\varepsilon\\rfloor\\) steps of size \\(\\varepsilon\\) to get a proposal tuple \\((\\boldsymbol{\\theta}_t^{\\star}, \\boldsymbol{s}_t^{\\star})\\)"
  },
  {
    "objectID": "slides/bayesmod-slides7.html#hamiltonian-monte-carlo-algorithm-1",
    "href": "slides/bayesmod-slides7.html#hamiltonian-monte-carlo-algorithm-1",
    "title": "Bayesian modelling",
    "section": "Hamiltonian Monte Carlo algorithm",
    "text": "Hamiltonian Monte Carlo algorithm\n\nFlip the momentum variable, \\(\\boldsymbol{s} \\mapsto - \\boldsymbol{s}.\\)\nMetropolis step: if \\(U \\sim \\mathsf{unif}(0,1) &lt;R\\), where \\[\\log R = -H(\\boldsymbol{\\theta}^{\\star}, \\boldsymbol{s}^{\\star}_{t}) + H(\\boldsymbol{\\theta}_{t-1}, \\boldsymbol{s}_{t-1}),\\] set \\(\\boldsymbol{\\theta}_t = \\boldsymbol{\\theta}_t^{\\star}\\), else keep the previous value and set \\(\\boldsymbol{\\theta}_t = \\boldsymbol{\\theta}_{t-1}\\).\nDiscard the momentum vector"
  },
  {
    "objectID": "slides/bayesmod-slides7.html#tuning",
    "href": "slides/bayesmod-slides7.html#tuning",
    "title": "Bayesian modelling",
    "section": "Tuning",
    "text": "Tuning\nHamiltonian Monte Carlo (HMC) has numerous tuning parameters\n\nsize of the leapfrog step \\(\\varepsilon\\).\nlength of the integration time \\(\\tau\\) (or equivalently the number of steps \\(L=\\lfloor \\tau / \\varepsilon \\rfloor\\)).\n\ntoo small leads HMC to bear close resemblance to random walk,\ntoo large leads to wasteful calculations.\n\nchoice of the mass matrix \\(\\mathbf{M}\\) (pre-conditioner obtained during warmup period)."
  },
  {
    "objectID": "slides/bayesmod-slides7.html#leapfrog-and-error",
    "href": "slides/bayesmod-slides7.html#leapfrog-and-error",
    "title": "Bayesian modelling",
    "section": "Leapfrog and error",
    "text": "Leapfrog and error\nThe Störmer–Verlet (leapfrog) integrator is a second order method, so for step size \\(\\varepsilon\\):\n\nlocal error \\(\\mathrm{O}(\\varepsilon^3)\\) and\nglobal error of size \\(\\mathrm{O}(\\varepsilon^2)\\) (accumulated error over \\(L\\) steps).\n\nLeapfrog updates one variable at a time, a shear transformation.\nLeapfrog step should be \\(\\mathrm{O}(d^{-1/4})\\) (Beskos et al., 2013)"
  },
  {
    "objectID": "slides/bayesmod-slides7.html#optimal-acceptance-rate",
    "href": "slides/bayesmod-slides7.html#optimal-acceptance-rate",
    "title": "Bayesian modelling",
    "section": "Optimal acceptance rate",
    "text": "Optimal acceptance rate\nIn practice, we use a Metropolis step to adjust for the discretization of the system.\n\nThis leads to acceptance rates less than the theoretical value of 1.\nwith optimal acceptance rate of \\(0.651\\) (Beskos et al., 2013); see Neal (2011) for heuristics.\nsoftware like Stan tunes to around 0.8, but can be adjusted in settings."
  },
  {
    "objectID": "slides/bayesmod-slides7.html#its-nuts",
    "href": "slides/bayesmod-slides7.html#its-nuts",
    "title": "Bayesian modelling",
    "section": "It’s nuts!",
    "text": "It’s nuts!\n\nHoman & Gelman (2014) propose the no \\(U\\)-turn sampler (NUTS), which continues the trajectory until the sampler turns back, to determine the number of steps \\(L\\), along with tuning of \\(\\varepsilon.\\)\nStan uses an adaptation of NUTS due to Betancourt (2016)"
  },
  {
    "objectID": "slides/bayesmod-slides7.html#hmc-and-divergences",
    "href": "slides/bayesmod-slides7.html#hmc-and-divergences",
    "title": "Bayesian modelling",
    "section": "HMC and divergences",
    "text": "HMC and divergences\nIn theory, the energy of the Hamiltonian should stay constant, but the numerical scheme leads to small perturbations (hence the rejection step).\n\nIf the value of the Hamiltonian changes too much, this is identified as a divergence. These occur when the geometry of the posterior is heavily constrained (funnel shaped).\nReparametrization of the model can help improve this: see the Stan manual."
  },
  {
    "objectID": "slides/bayesmod-slides7.html#neals-funnel",
    "href": "slides/bayesmod-slides7.html#neals-funnel",
    "title": "Bayesian modelling",
    "section": "Neal’s funnel",
    "text": "Neal’s funnel"
  },
  {
    "objectID": "slides/bayesmod-slides7.html#achieving-independence",
    "href": "slides/bayesmod-slides7.html#achieving-independence",
    "title": "Bayesian modelling",
    "section": "Achieving independence",
    "text": "Achieving independence\nWe have seen that for differentiable posterior \\(p(\\boldsymbol{\\theta} \\mid \\boldsymbol{y})\\), using the gradient information can improve convergence by informing about the direction of the mode.\n\nNeal (2011) discusses how informally, random walk Metropolis requires \\(\\mathrm{O}(d^2)\\) steps to get an independent draw, compared to \\(\\mathrm{O}(d^{4/3})\\) for MALA.\nHMC scales like \\(\\mathrm{O}(d^{5/4})\\), a notable improvement in performance.\nIt however comes at the cost of repeated gradient evaluations (\\(L\\) by update)."
  },
  {
    "objectID": "slides/bayesmod-slides7.html#take-home",
    "href": "slides/bayesmod-slides7.html#take-home",
    "title": "Bayesian modelling",
    "section": "Take-home",
    "text": "Take-home\n\nHMC is more efficient than what we have seen, but not a silver bullet: it works very well for not overly complicated models and moderate sample sizes.\nHMC works better than many MCMC, but requires special tuning best left to specialized implementations already available in software.\nMost implementations don’t cover the case of discrete random variables (Nishimura et al., 2020)."
  },
  {
    "objectID": "slides/bayesmod-slides7.html#probabilistic-programming",
    "href": "slides/bayesmod-slides7.html#probabilistic-programming",
    "title": "Bayesian modelling",
    "section": "Probabilistic programming",
    "text": "Probabilistic programming\nThere are several languages and interfaces that implement probabilistic programming where the user has only to specify the likelihood and prior.\nHistorically, Bugs paved the way to practitioners.\nIt relies on Gibbs sampling (updating one parameter at the time), but is not actively developed. Still the source of many exercises and inspiration for the syntax of other implementations (e.g., Nimble, JAGS)."
  },
  {
    "objectID": "slides/bayesmod-slides7.html#other-mcmc-software",
    "href": "slides/bayesmod-slides7.html#other-mcmc-software",
    "title": "Bayesian modelling",
    "section": "Other MCMC software",
    "text": "Other MCMC software\n\nNimble, C++ with R interface\nTuring.jl, Julia\nPyMC, Python\nPigeons, Julia"
  },
  {
    "objectID": "slides/bayesmod-slides7.html#stochastic-volatility-model",
    "href": "slides/bayesmod-slides7.html#stochastic-volatility-model",
    "title": "Bayesian modelling",
    "section": "Stochastic volatility model",
    "text": "Stochastic volatility model\nFinancial returns \\(Y_t\\) typically exhibit time-varying variability. The stochastic volatility model is a parameter-driven model that specifies \\[\\begin{align*}\nY_t = \\exp(h_t/2) Z_t \\\\\nh_t = \\gamma + \\phi (h_{t-1} - \\gamma) + \\sigma U_t\n\\end{align*}\\] where \\(U_t \\stackrel{\\mathrm{iid}}{\\sim} \\mathsf{Gauss}(0,1)\\) and \\(Z_t \\sim  \\stackrel{\\mathrm{iid}}{\\sim} \\mathsf{Gauss}(0,1).\\)\nIt is possible to introduce leverage by adding \\(\\mathsf{Cor}(Z_t, U_t) = \\rho.\\)"
  },
  {
    "objectID": "slides/bayesmod-slides7.html#references",
    "href": "slides/bayesmod-slides7.html#references",
    "title": "Bayesian modelling",
    "section": "References",
    "text": "References\n\n\n\n\nBeskos, A., Pillai, N., Roberts, G., Sanz-Serna, J.-M., & Stuart, A. (2013). Optimal tuning of the hybrid Monte Carlo algorithm. Bernoulli, 19(5A), 1501–1534. https://doi.org/10.3150/12-BEJ414\n\n\nBetancourt, M. (2016). Identifying the optimal integration time in Hamiltonian Monte Carlo. arXiv. https://doi.org/10.48550/arXiv.1601.00225\n\n\nBetancourt, M. (2017). A conceptual introduction to Hamiltonian Monte Carlo. arXiv Preprint. https://doi.org/10.48550/arXiv.1701.02434\n\n\nHoman, M. D., & Gelman, A. (2014). The no-U-turn sampler: Adaptively setting path lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research, 15(1), 1593–1623.\n\n\nNeal, R. M. (2011). MCMC using Hamiltonian dynamics. In S. Brooks, A. Gelman, G. Jones, & X. L. Meng (Eds.), Handbook of Markov chain Monte Carlo (pp. 113–162). CRC Press. https://doi.org/10.1201/b10905-5\n\n\nNishimura, A., Dunson, D. B., & Lu, J. (2020). Discontinuous Hamiltonian Monte Carlo for discrete parameters and discontinuous likelihoods. Biometrika, 107(2), 365–380. https://doi.org/10.1093/biomet/asz083"
  }
]