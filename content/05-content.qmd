---
title: "Markov chain Monte Carlo: Gibbs sampling"
draft: true
---


## Content


- Gibbs sampling and data augmentation
- Bayesian worflow and diagnostics for MCMC

## Learning objectives

At the end of the chapter, students should be able to

- implement MALA and Gibbs sampling
- derive the conditional distributions of a model for Gibbs sampling
- diagnose performance of MCMC algorithms and implement potential remedies



## Readings

:::{.callout-warning}

These readings should be completed before class, to ensure timely understanding and let us discuss the concepts together through various examples and case studies --- the strict minimum being the course notes.

:::

- [@Geyer:2011](https://www.mcmchandbook.net/HandbookChapter1.pdf)
- [Chapter 3 of the course notes](https://lbelzile.github.io/MATH80601A/mcmc.html)


## Complementary readings

:::{.callout-warning}
Complementary readings are additional sources of information that are not required readings, but may be useful substitutes. Sometimes, they go beyond the scope of what we cover and provide more details.
:::

- @Albert:2009, chapters 6 and 10 (several examples)
- @McElreath:2020, chapter 9 (non technical)


## Slides


<p class="text-center"><a class="btn btn-success btn-lg" target="_blank" href="../slides/bayesmod-slides5.html">{{< fa arrow-up-right-from-square >}} &ensp;View all slides in new window</a> <a class="btn btn-success btn-lg" target="_blank" href="../slides/bayesmod-slides5.pdf" role="button">{{< fa file-pdf >}} &ensp;Download PDF of all slides</a></p>


<div class="ratio ratio-16x9">
<iframe class="slide-deck" src="../slides/bayesmod-slides5.html"></iframe>
</div>

