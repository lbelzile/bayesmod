

## Exercise 1.1

**For credit**

Consider the geometric distribution $\mathsf{geom}(p)$ with mass function
\begin{align*}
f(y; p) = p(1-p)^{y}, \qquad y = 0, 1, 2, \ldots;
\end{align*}
the latter is used to model the number of failures $Y$ from independent trials until a first success, which occurs with probability $p$.

a. If $Y \mid P=p \sim \mathsf{geom}(p)$ and $P \sim \mathsf{beta}(\alpha_1, \alpha_2)$, show that $P \mid Y=y$ is beta distributed and obtain the parameters of the latter.
b. Obtain the marginal distribution of $Y$ and show that it is a special case of the beta-negative binomial distribution.
c. Using the tower property, compute the unconditional mean and variance of $Y$.
d. Use forward sampling, draw 10 000 observations from $Y$ by first drawing from $P$, then from $Y \mid P$. Compare the distribution with that of $Y \mid p$ using a bar plot.
e. Verify the formulas for the expected value and variance derived previously using Monte Carlo integration.

## Exercise 1.2

Linear mixed effect regression model specifies that response vectors for individual $i$, $\boldsymbol{Y}_i \in \mathbb{R}^k$, are Gaussian. The model includes model matrix $\mathbf{X}_i$ with fixed effect coefficients $\boldsymbol{\beta}$, and another $k\times l$ model matrix  $\mathbf{Z}_i$ with random effects. The hierarchical formulation of the model is
\begin{align*}
\boldsymbol{Y}_i \mid \mathcal{B}_i=\boldsymbol{b}_i &\sim \mathsf{Gauss}_k(\mathbf{X}_i\boldsymbol{\beta} + \mathbf{Z}_i\boldsymbol{b}_i, \sigma^2 \mathbf{I}_k) \\
\mathcal{B}_i & \sim \mathsf{Gauss}_l(\boldsymbol{0}_k, \boldsymbol{\Omega})
\end{align*}


a. Using the tower property, derive the marginal mean and covariance matrix of $\boldsymbol{Y}_i$
b. Hence obtain the parameters of the joint distribution of $(\boldsymbol{Y}_i^\top, \mathcal{B}_i^\top)^\top$.

## Exercise 1.3

Consider a simple random sample of size $n$ from the Wald distribution, with density
\begin{align*}
f(y; \nu, \lambda) = \left(\frac{\lambda}{2\pi y^{3}}\right)^{1/2} \exp\left\{ - \frac{\lambda (y-\nu)^2}{2\nu^2y}\right\}\mathrm{I}(y > 0)
\end{align*}
for location $\nu >0$ and shape $\tau>0$. You may take for given that the expected value of the Wald distribution is $\mathsf{E}(Y) = \nu$.


a. Write down the likelihood and show that it can be written in terms of the sufficient statistics $\sum_{i=1}^n y_i$ and $\sum_{i=1} y_i^{-1}$.
b. Derive the Fisher information matrix



<!--
The ratio-of-uniform method, implemented in the [`rust` **R** package](https://paulnorthrop.github.io/rust/index.html), can be used to simulate independent draws from an unnormalized density function assuming the latter is bounded after use of a Box--Cox transformation.

```{r}
#| eval: false
#| echo: true
set.seed(80601)
data(waiting, package = "hecbayes")
nobs <- length(waiting) # number of observations
ybar <- mean(waiting)   # average waiting time
B <- 1000L  # number of draws
# Un-normalized log posterior: scaled log likelihood + log prior
upost <- function(x){
  dgamma(x = x, shape = nobs + 1L, rate = nobs*ybar, log = TRUE) +
    log(2) + dt(x = x, df = 1, log = TRUE)}
post_samp <- rust::ru(logf = upost,
                      n = B,
                      d = 1,  # dimension of parameter (scalar)
                      init = nobs/ybar)$sim_vals # initial value of mode
```


Estimate using the Monte Carlo sample:

1. the probability that the waiting time is between 20 and 40 seconds
2. the average waiting time
3. the standard deviation of the waiting time

-->
