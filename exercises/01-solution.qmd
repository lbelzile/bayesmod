---
title: "Solution 1"
draft: true
---


# Exercise 1.1

Consider $\boldsymbol{Y}=(Y_1, \ldots, Y_3)^\top \in \mathbb{S}_{2}$ a trivariate vector, where $\boldsymbol{Y} \sim \mathsf{Dir}(\alpha_1, \alpha_2, \alpha_3)$

a. Derive the marginal distribution of $(Y_1, Y_2)$.
b. Derive the conditional distribution of $Y_3 \mid (Y_1, Y_2)$.

# Exercise 1.2

Consider a simple random sample of size $n$ from the Wald distribution, with density
\begin{align*}
f(y; \nu, \lambda) = \left(\frac{\lambda}{2\pi y^{3}}\right)^{1/2} \exp\left\{ - \frac{\lambda (y-\nu)^2}{2\nu^2y}\right\}\mathrm{I}(y > 0)
\end{align*}
for location $\nu >0$ and shape $\tau>0$.


Write down the likelihood and show that it can be written in terms of the sufficient statistics $\sum_{i=1}^n y_i$ and $\sum_{i=1} y_i^{-1}$.

::: {.solution}

The log likelihood for an independent and identically distributed sample is, up to terms not depending on the parameters,
\begin{align*}
\ell(\nu, \lambda) \stackrel{\nu, \lambda}{\propto} \frac{n}{2} \ln(\lambda) -  - \frac{\lambda}{2\nu^2} \sum_{i=1}^n (y_i - 2\nu + \nu^2/y_i)
\end{align*}
and we readily see that the model is an exponential family with sufficient statistics $t_1(\boldsymbol{y}) = \sum_{i=1}^n y_i$ and $t_2(\boldsymbol{y}) = \sum_{i=1}^n y_i^{-1}$.

The joint prior is of the form
\begin{align*}
p(\lambda) &\propto \lambda^{\alpha-1}\exp(-\lambda \beta) \\
p(\nu \mid \lambda) & \propto \frac{(\lambda \tau)^{1/2}}{\nu^2}\exp\left\{-\frac{\lambda\tau }{2}(\nu^{-1}-\mu)^2\right\},
\end{align*}
where the last step follows from a change of variable.


:::


## Exercise 1.3

Consider the Laplace family of distribution, $\mathsf{La}(\nu, \tau)$, with density
\begin{align*}
g(x; \nu, \tau) = \frac{1}{2\tau} \exp\left(- \frac{|x-\nu|}{\tau}\right), \qquad \nu \in \mathbb{R}, \tau > 0
\end{align*}
as a candidate distribution for rejection sampling from $\mathsf{No}(0,1)$.

1. Provide an inversion sampling algorithm to generate from $\mathsf{La}(\nu, \tau)$.
2. Can you use the proposal to generate from a standard Gaussian? for Student-$t$ with 1 degree of freedom? Justify your answer.
3. Consider as proposal a location-scale version of the Student-t with $\nu=3$
 degrees of freedom. Find the optimal location and scale parameters and the upper bound $C$ for your choice.
4. Use the accept-reject to simulate 1000 independent observations and compute the empirical acceptance rate.

## Exercise 1.4

The ratio-of-uniform method, implemented in the [`rust` **R** package](https://paulnorthrop.github.io/rust/index.html), can be used to simulate independent draws from an unnormalized density function assuming the latter is bounded after use of a Box--Cox transformation.

The following code produces independent draws from a univeriate distribution
```{r}
#| eval: true
#| echo: true
set.seed(80601)
nobs <- 10L # number of observations
ybar <- 8   # average waiting time
B <- 1000L  # number of draws
# Un-normalized log posterior: scaled log likelihood + log prior
upost <- function(x){
  dgamma(x = x, shape = nobs + 1L, rate = nobs*ybar, log = TRUE) +
    log(2) + dt(x = x, df = 1, log = TRUE)}
post_samp <- rust::ru(logf = upost,
                      n = B,
                      d = 1,  # dimension of parameter (scalar)
                      init = nobs/ybar)$sim_vals # initial value of mode
```

Estimate using the Monte Carlo sample:

1. the probability that the waiting time is between 3 and 15 minutes
2. the average waiting time
3. the standard deviation of the waiting time
