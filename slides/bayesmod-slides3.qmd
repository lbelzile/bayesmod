---
title: "Simulation-based inference"
author: "LÃ©o Belzile"
subtitle: "Priors"
date: today
date-format: YYYY
eval: true
echo: true
cache: true
format:
  revealjs:
    slide-number: true
    preview-links: auto
    theme: [simple, hecmontreal.scss]
    title-slide-attributes:
      data-background-color: "#ff585d"
    logo: "fig/logo_hec_montreal_bleu_web.png"
---


```{r include=FALSE}

hecbleu <- c("#002855")
fcols <- c(gris = "#888b8d",
           bleu = "#0072ce",
           aqua = "#00aec7",
           vert = "#26d07c",
           rouge = "#ff585d",
           rose = "#eb6fbd",
           jaune = "#f3d03e")
pcols <- c(gris = "#d9d9d6",
           bleu = "#92c1e9",
           agua = "#88dbdf",
           vert = "#8fe2b0",
           rouge = "#ffb1bb",
           rose = "#eab8e4",
           jaune = "#f2f0a1")
library(ggplot2)
theme_set(theme_classic())
library(patchwork)
knitr::opts_chunk$set(fig.retina = 3, collapse = TRUE)
options(digits = 3, width = 75)
```

## Bayesian inference beyond conjugate models

How to circumvent the problem of intractable posteriors?

- simulation-based methods: accept-reject, Markov chain Monte Carlo, particle filters, etc.
- deterministic methods: (integrated nested) Laplace approximations, variational Bayes, expectation propagation, etc.

We focus on the Monte Carlo methods in the sequel.

## Objective of methods

Suppose we can simulate $B$ i.i.d. variables with the same distribution, $X_b \sim F$ $(b=1, \ldots, B).$

We want to compute $\mathsf{E}\{g(X)\}=\mu_g$ for some functional $g(\cdot)$

- $g(x)=x$ (posterior mean)
- $g(x) = \mathsf{I}(x \in A)$ (probability of event)
- etc.

## Monte Carlo methods

We substitute expected value by sample average 
$$\widehat{\mu}_g = \frac{1}{B} \sum_{b=1}^B g(X_b), \qquad X_b \sim F$$

- law of large number guarantees convergence of $\widehat{\mu}_g \to \mu_g$ if the latter is finite.
- central limit theorem applies: $$\sqrt{B}(\widehat{\mu}_g - \mu_g) \sim \mathsf{No}(0, \sigma^2_g).$$


## Ordinary Monte Carlo

We want to have an estimator as precise as possible.

- but we can't control the variance of $g(X)$, say $\sigma_g^2$
- the more simulations $B$, the lower the variance of the mean. 
- sample average for i.i.d. data has variance $\sigma^2_g/B$
- to reduce the standard deviation by a factor 10, we need $100 \times B$ draws!


Remember: the answer is **random**.

## Example: functionals of gamma distribution

```{r}
#| label: fig-monte-carlo-path
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Running mean trace plots for $g(x)=\\mathrm{I}(x<1)$ (left), $g(x)=x$ (middle) and $g(x)=1/x$ (right) for a Gamma distribution with shape 0.5 and rate 2, as a function of the Monte Carlo sample size."
set.seed(80601)
B <- 1e5L
Bseq <- seq_len(B)
alpha <- 0.5; beta <- 2
pv <- pgamma(1, shape = alpha, rate = beta)
samp <- rgamma(n = B, shape = alpha, rate = beta)
int1 <- cumsum(samp < 1)/Bseq
int2 <- cumsum(samp)/Bseq
int3 <- cumsum(1/samp)/Bseq
g1 <- ggplot(data = data.frame(
  nsim = Bseq, 
  y = int1,
  mu = pv,
  interv = qnorm(0.975)*sqrt(pv*(1-pv)/Bseq))) +
  geom_ribbon(mapping = aes(x = nsim, 
                           y = mu,
                           ymin = mu - interv,
                           ymax = interv + mu),
               alpha = 0.1) + 
  geom_hline(yintercept = pv, alpha = 0.5) +
  geom_line(aes(x = nsim, y = y)) +
  scale_x_continuous(limits = c(10, NA), trans = "sqrt",
                     labels = scales::unit_format(unit = "K", scale = 1e-3)) +
  scale_y_continuous(limits = c(0.9, 1), expand = c(0,0)) +
  labs(x = "number of simulations",
       y = "",
       subtitle = "Pr(X < 1)")
g2 <- ggplot(data = data.frame(
  nsim = Bseq, 
  y = int2,
  mu = alpha/beta,
  interv = qnorm(0.975)*sqrt(alpha/beta^2/Bseq))) +
  geom_ribbon(mapping = aes(x = nsim, 
                             y = mu,
                           ymin = -interv + mu,
                           ymax = interv + mu),
               alpha = 0.1) + 
  geom_hline(yintercept = alpha/beta, alpha = 0.5) +
  geom_line(mapping = aes(
               x = nsim, 
               y = y)) +
  scale_x_continuous(limits = c(10, NA), trans = "sqrt",
                     labels = scales::unit_format(unit = "K", scale = 1e-3)) +
  scale_y_continuous(limits = c(0.1, 0.4), expand = c(0,0)) +
  labs(x = "number of simulations",
       y = "",
       subtitle = "E(X)")
g3 <- ggplot(data = data.frame(nsim = Bseq, y = int3),
             mapping = aes(x = nsim, y = y)) +
  geom_line() +
  scale_x_continuous(limits = c(10, NA), trans = "sqrt",
                     labels = scales::unit_format(unit = "K", scale = 1e-3)) +
  labs(x = "number of simulations",
       y = "",
       subtitle = "E(1/X) (divergent)")
g1 + g2 + g3 & theme_classic()
```

## Simulation algorithms: inversion method

If $F$ is an absolutely continuous distribution function, then 
$$F(X) \sim \mathsf{U}(0,1).$$
The inversion method consists in applying the quantile function $F^{-1}$ to $U \sim \mathsf{U}(0,1)$, viz. $$F^{-1}(U) \sim X.$$

## Inversion method for truncated distributions

Consider a random variable $Y$ with distribution function $F$.

If $X$ follows the same distribution as $Y$, but restricted over the interval $[a,b]$, then 
$$\Pr(X \leq x) = \frac{F(x) - F(a)}{F(b)-F(a)}, \qquad a \leq x \leq b,$$

Therefore, $$F^{-1}[F(a) + \{F(b)-F(a)\}U] \sim X$$



## Simulation algorithms: accept-reject

- **Target**: sample from density $p(x)$ (hard to sample from)
- **Proposal**: find a density $q(x)$ with nested support, $\mathrm{supp}(p) \subset \mathrm{supp}(q)$, such that 
$$\frac{p(x)}{q(x)} \leq C, \quad C \geq 1.$$


:::{.callout-important}

## Rejection sampling algorithm

1. Generate $X$ from proposal with density $q(x)$.
2. Compute the ratio $R \gets p(X)/ q(X)$.
3. If $R \leq CU$ for $U \sim \mathsf{U}(0,1)$, return $X$, else go back to step 1.

:::

## Remarks on rejection sampling

- Acceptance rate is $1/C$
   - we need on average $C$ draws from $q$ to get one from $p$
- $q$ must be more heavy-tailed than $p$
   - e.g., $q(x)$ Student-$t$ for $p(x)$ Gaussian
- $q$ should be cheap and easy to sample from!

## Designing a good proposal density

Good choices must satisfy the following constraints: 

- pick a family $q(x)$ so that $$C = \mathrm{sup}_x \frac{p(x)}{q(x)}$$ is as close to 1 as possible.
- you can use numerical optimization with $f(x) =\log p(x) - \log q(x)$ to find the mode $x^\star$ and the upper bound $C = \exp f(x^\star)$.

## Example of accept-reject (1)

Consider sampling $Y \sim \mathsf{No}(\mu, \sigma^2)$, but truncated in the interval $(a, b)$. The target density is
\begin{align*}
p(x; \mu, \sigma, a, b) = \frac{1}{\sigma}\frac{\phi\left(\frac{x-\mu}{\sigma}\right)}{\Phi(\beta)-\Phi(\alpha)}.
\end{align*}
for $\alpha= (a-\mu)/\sigma$ and $\beta = (b-\mu)/\sigma$.
where $\phi(\cdot), \Phi(\cdot)$ are respectively the density and distribution function of the standard Gaussian distribution.

## Accept-reject (crude version)

1. Simulate $X \sim \mathsf{No}(\mu, \sigma^2)$
2. reject any draw if $X < a$ or $X> b$. 

The acceptance rate is $C^{-1} = \{\Phi(\beta) - \Phi(\alpha)\}$

```{r}
#| eval: true
#| echo: true
# Standard Gaussian truncated on [0,1]
candidate <- rnorm(1e5)
trunc_samp <- candidate[candidate >= 0 & candidate <= 1]
# Acceptance rate
length(trunc_samp)/1e5
# Theoretical acceptance rate
pnorm(1)-pnorm(0)
```

## Accept-reject for truncated Gaussian  {.smaller}

Since the Gaussian is a location scale family, the inversion method gives
\begin{align*}
X \sim \mu + \sigma\Phi^{-1}\left[\Phi(\alpha) + \{\Phi(\beta)-\Phi(\alpha)\}U\right]
\end{align*}

We however need to evaluate $\Phi$ numerically (no closed-form expression).

The method fails for *rare event* simulation because the computer returns

- $\Phi(x) = 0$ for $x \leq -39$
- $\Phi(x)=1$ for $x \geq 8.3$,

implying that $a \leq 8.3$ for this approach to work [@LEcuyer.Botev:2017].

## Simulating tails of Gaussian variables {.smaller}

We consider simulation from a standard Gaussian truncated above $a>0$ [@Devroye:1986, p.381].

Write the density of the truncated Gaussian as $$f(x) = \frac{\exp(-x^2/2)}{\int_{a}^{\infty}\exp(-z^2/2)\mathrm{d} z}  =\frac{\exp(-x^2/2)}{c_1}.$$

Note that, for $x \geq a$, 
$$c_1f(x) \leq \frac{x}{a}\exp\left(-\frac{x^2}{2}\right)= a^{-1}\exp\left(-\frac{a^2}{2}\right)g(x);$$
where $g(x)$ is the density of a Rayleigh variable shifted by $a$.^[The constant $C= \exp(-a^2/2)(c_1a)^{-1}$ approaches 1 quickly as $a \to \infty$ (asymptotically optimality). ]

## Accept-reject: truncated Gaussian with Rayleigh  {.smaller}

The shifted Rayleigh has distribution function $$G(x) = 1-\exp\{(a^2-x^2)/2\}, x \geq a.$$ 




:::{.callout-important}

## Marsaglia algorithm
1. Generate a shifted Rayleigh  above $a$, $X \gets  \{a^2 - 2\log(U)\}^{1/2}$ for $U \sim \mathsf{U}(0,1)$
2. Accept $X$ if $XV \leq a$, where $V \sim \mathsf{U}(0,1)$.
:::

For sampling on $[a,b]$, propose from a Rayleigh truncated above at $b$ [@LEcuyer.Botev:2017].

```{r}
#| eval: true
#| echo: true
#| label: marsaglia-algo
a <- 8.3
niter <- 1000L
X <- sqrt(a^2 + 2*rexp(niter))
samp <- X[runif(niter)*X <= a]
```


## Markov chains

Plain ordinary Monte Carlo is great, but few algorithms are generic enough to be useful in complex high-dimensional problems.

We will instead typically build Markov chains that target an invariant stationary distribution. 


## Caveats?

Markov chain Monte Carlo methods generate **correlated** draws. 

**Questions**: 

1. can we use them as ordinary independent samples? 
2. what is the price to pay?

We need to do a little theoretical detour to answer these questions.

## Stationarity and Markov property


A stochastic process is **(weakly) stationary** if 

- the distribution of $\{X_1, \ldots, X_t\}$ is the same as that of $\{X_{n+1}, \ldots X_{t+n}\}$ for any value of $n$ and given $t$.

A stochastic process is **Markov** if 

- it satisfies the Markov property: given the current state of the chain, the future only depends on the current state and not on the past.

## Autoregressive process of order 1

Consider a first-order autoregressive process, or $\mathsf{AR}(1)$, 

$$Y_t = \mu + \phi(Y_{t-1} - \mu) + \varepsilon_t,$$ where 

- $\phi$ is the lag-one correlation, 
- $\mu$ the global mean
- $\varepsilon_t$ is an iid innovation with mean zero and variance $\sigma^2$

If $|\phi| < 1$, the process is stationary, otherwise variance increases with $t$

## Variance of a stationary distribution

For a correlated sequence, the variance of the stationary distribution is \begin{align*}
\tau^2 = \mathsf{Va}(Y_t) + 2 \sum_{k=1}^\infty \mathsf{Co}(Y_t, Y_{t-k}).
\end{align*}

 - for i.i.d. data, $\tau^2 = \mathsf{Va}(Y_t)$
 - for stationary $\mathsf{AR}(1)$ process, we get $\sigma^2/(1-\phi^2)$ (geometric series)

## Variance of sample average

Intuitively, a sample of correlated observations carries less information than an independent sample of draws.

We want the variance of the sample average, which is
\begin{align*}
\mathsf{Va}\left(\overline{Y}_T\right) = \frac{1}{T}\sum_{t=1}^T \mathsf{Va}(Y_t) + \frac{2}{T} \sum_{t=1}^{T-1}\sum_{s = t+1}^T \mathsf{Co}(Y_t, Y_s).
\end{align*}

If the process is stationary, the covariances at lag $k$ are the same regardless of the time index and the unconditional variance is constant.

## Variance of sample average, redux

If a central limit theorem applies, the limiting variance of the sample mean is 
\begin{align*}
\lim_{T \to \infty} T\mathsf{Va}\left(\overline{Y}_T\right) = \tau^2 \left\{1+2\sum_{t=1}^\infty \gamma_t\right\}.
\end{align*}
which is a function of 

- the unconditional variance $\tau^2$
- the lag-$k$ autocorrelation $\mathsf{Cor}(Y_{t}, Y_{t+k})=\gamma_k$

## Variance of sample mean of AR(1)

The lag-$k$ correlation of the stationary autoregressive process of order 1 is $\phi^k$, so $$T\mathsf{Va}\left(\overline{Y}_T\right)=\sigma^2(1+\phi)/(1-\phi).$$

For an independent sample, we have $$T\mathsf{Va}\left(\overline{Y}_T\right)=\sigma^2/(1-\phi^2).$$ 

## Morale of the story {.center}

The price to pay for having correlated samples is 

:::{style="font-size: 2em; color: #ff585d; text-align: center"}

**inefficiency**

:::

The higher the autocorrelation, the larger the variability of our estimators.



## Inefficiency curve {.smaller}

```{r}
#| label: fig-ar1-variance
#| fig-width: 8
#| fig-height: 4
#| fig-cap: "Scaled asymptotic variance of the sample mean for AR(1) (dashed) and independent observations with the same marginal variance (full line). The plot on the right gives the variance ratio for positive correlations."
#| message: false
#| warning: false
#| echo: false
#| eval: true
var2 <- function(rho){(1+rho)/(1-rho)}
var1 <- function(rho){1/(1-rho^2)}
var_ratio <- function(rho){var2(rho)/var1(rho)}
g1 <- ggplot() +
  stat_function(fun = var1, xlim = c(-0.9,0.9), n = 1001L, linetype = "dashed") +
  stat_function(fun = var2, xlim = c(-0.9,0.9), n = 1001L) +
  labs(y = "", x = expression(phi)) +
  theme_classic()
g2 <- ggplot() +
  stat_function(fun = var_ratio,
                xlim = c(0,1), 
                n = 1001L) +
  labs(y = "") + 
  theme_classic()  
g1 + g2
```


To get the same precision for the mean of $\mathsf{AR}(1)$ process with $\phi \approx 0.75$ than with i.i.d. data, we would need 9 times as many observations.


## When can we use Markov chains?

If a Markov chain is irreducible and aperiodic, it has a unique stationary distribution.

- irreducibility: means that the chain can move from anywhere to anywhere, so it doesn't get stuck in part of the space forever.
- acyclic: cyclical chains loop around and visit periodically a state

Ergodic theorem is our guarantee of convergence.

## Examples

Consider discrete Markov chains over the integers $1, 2, 3$ with transition matrices

$$
P_1 = \begin{pmatrix}
0.5 & 0.3 & 0.2 \\
0 & 0.4 & 0.6 \\
0 & 0.5 & 0.5
\end{pmatrix}, 
\quad 
P_2 = \begin{pmatrix}
0 & 0 & 1 \\
1 & 0 & 0 \\
0 & 1 & 0
\end{pmatrix}.
$$
Chain 1 is reducible to $\{2, 3\}$, chain 2 is cyclical.

## Convergence of Markov chains


```{r}
#| label: fig-discrete-markov-chain
#| eval: true
#| echo: false
#| cache: true
#| fig-cap: "Discrete Markov chain on integers from 1 to 5, with traceplot of 1000 first iterations (left) and running mean plots of sample proportion of each state visited (right)."
set.seed(1234)
P3 <- rbind(c(4,2,0,0,0),
            c(1,4,1,0,0),
            c(0,1,4,1,0),
            c(0,0,1,4,1),
            c(0,0,0,2,4)) / 6
chain <- integer(1e5L)
state <- sample.int(n = 5, size = 1)
for(i in seq_along(chain)){
  state <- sample.int(n = 5, size = 1, prob = P3[state,])
  chain[i] <- state
}
library(ggplot2)
library(patchwork)
g1 <- ggplot(data = data.frame(iteration = 1:1000,
                               state = chain[1:1000]),
             mapping = aes(x = iteration, y = state)) +
  geom_line() +
  theme_classic() +
  labs(y = "", subtitle = "state")
iter <- seq(from = 100, to = length(chain), by = 100)
sub <- sapply(iter,
              function(n){
                as.numeric(table(chain[seq_len(n)])/n)
                }) 
g2 <- ggplot(
  data = data.frame(
    x = rep(iter, each =5),
    y = c(sub),
    state = factor(rep(1:5, length.out = length(sub)))),
  mapping = aes(x = x, group = state, color = state, y = y)) +
  geom_line() +
  scale_x_continuous(trans = "sqrt", labels = scales::unit_format(unit = "K", scale = 1e-3)) + 
  labs(y = "",
       subtitle = "probability of state", 
       x = "iteration") +
  MetBrewer:::scale_color_met_d("Hiroshige") +
  theme_classic() +
  theme(legend.position = "bottom")
g1 + g2
```

## Markov chain Monte Carlo

We consider simulating from a distribution with associated density function $\propto p(\boldsymbol{\theta})$.

- known up to a normalizing factor not depending on $\boldsymbol{\theta}$.

We use $q(\boldsymbol{\theta} \mid \boldsymbol{\theta}^*)$ as transition kernel to generate proposals.


## Metropolis--Hastings algorithm 

Starting from an initial value $\boldsymbol{\theta}_0$:

1.  draw a proposal value $\boldsymbol{\theta}_t^{\star} \sim q(\boldsymbol{\theta} \mid \boldsymbol{\theta}_{t-1})$.
2.  Compute the acceptance ratio $$
    R = \frac{p(\boldsymbol{\theta}_t^{\star})}{p(\boldsymbol{\theta}_{t-1})}\frac{q(\boldsymbol{\theta}_{t-1} \mid \boldsymbol{\theta}_t^{\star} )}{q(\boldsymbol{\theta}_t^{\star} \mid \boldsymbol{\theta}_{t-1})}
    $$
3.  With probability $\max\{R, 1\}$, accept the proposal and set $\boldsymbol{\theta}_t \gets \boldsymbol{\theta}_t^{\star}$, otherwise set the value to the previous state, $\boldsymbol{\theta}_t \gets \boldsymbol{\theta}_{t-1}$.

## Interpretation

- If $R>1$, the proposal has higher density and we always accept the move. If the ratio is less than one, the proposal is in a lower probability region.
- If we reject the move, the Markov chain stays at the current value, which induces autocorrelation.
- Since the acceptance probability depends only on the density through ratios, we can work with unnormalized density functions.


## References

