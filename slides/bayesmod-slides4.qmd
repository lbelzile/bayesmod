---
title: "Bayesian modelling"
author: "LÃ©o Belzile"
subtitle: "Monte Carlo methods, Markov chains and the Metropolis--Hastings algorithm"
date: today
date-format: "[Last compiled] dddd MMM D, YYYY"
eval: true
echo: true
cache: true
width: 1200
height: 900
bibliography: MATH80601A.bib
format:
  revealjs:
    slide-number: true
    preview-links: auto
    theme: [simple, hecmontreal.scss]
    title-slide-attributes:
      data-background-color: "#ff585d"
    logo: "fig/logo_hec_montreal_bleu_web.png"
---


```{r}
#| include: false
#| eval: true
#| echo: false
hecbleu <- c("#002855")
fcols <- c(gris = "#888b8d",
           bleu = "#0072ce",
           aqua = "#00aec7",
           vert = "#26d07c",
           rouge = "#ff585d",
           rose = "#eb6fbd",
           jaune = "#f3d03e")
pcols <- c(gris = "#d9d9d6",
           bleu = "#92c1e9",
           agua = "#88dbdf",
           vert = "#8fe2b0",
           rouge = "#ffb1bb",
           rose = "#eab8e4",
           jaune = "#f2f0a1")
library(ggplot2)
theme_set(theme_classic())
library(patchwork)
knitr::opts_chunk$set(fig.retina = 3, collapse = TRUE)
options(digits = 3, width = 75)
```

## Bayesian inference beyond conjugate models

How to circumvent the problem of intractable posteriors?

- simulation-based methods: accept-reject, Markov chain Monte Carlo, particle filters, etc.
- deterministic methods: (integrated nested) Laplace approximations, variational Bayes, expectation propagation, etc.

We focus on Monte Carlo methods.


## Simulation algorithms: inversion method

If $F$ is an absolutely continuous distribution function, then 
$$F(X) \sim \mathsf{U}(0,1).$$
The inversion method consists in applying the quantile function $F^{-1}$ to $U \sim \mathsf{U}(0,1)$, viz. $$F^{-1}(U) \sim X.$$



## Inversion method for truncated distributions

Consider a random variable $Y$ with distribution function $F$.

If $X$ follows the same distribution as $Y$, but restricted over the interval $[a,b]$, then
$$\Pr(X \leq x) = \frac{F(x) - F(a)}{F(b)-F(a)}, \qquad a \leq x \leq b,$$

Therefore, $$F^{-1}[F(a) + \{F(b)-F(a)\}U] \sim X$$


## Fundamental theorem of simulation

Consider a $d$-variate random vector $\boldsymbol{X},$ independent of $U \sim \mathsf{unif}(0,1)$ and $c>0$.
If $(\boldsymbol{X}, U)$ is uniformly distributed on the set
\begin{align*}
\mathcal{A}_{f}=\{(\boldsymbol{x}, u): 0 \leq u \leq  c f(\boldsymbol{x})\},
\end{align*}
then $\boldsymbol{X}$ has density $f(\boldsymbol{x}).$ Conversely, if $\boldsymbol{X}$ has density $f(\boldsymbol{x})$ and $U\sim\mathsf{unif}(0,1)$ independently, then $[\boldsymbol{X}, cUf(\boldsymbol{X})]$ is uniformly distributed on $\mathcal{A}_f$

- $f$ is the marginal density of $\boldsymbol{X}$ since $f(\boldsymbol{x}) = \int_0^{f(\boldsymbol{x})} \mathrm{d} u.$
- If we can simulate uniformly from $\mathcal{A}_{f},$ then, we can discard the auxiliary variable $u.$ See @Devroye:1986, Theorem 3.1.

## Fundamental theorem of simulation in picture


```{r}
#| eval: true
#| echo: false
#| label: fig-fundamental-theorem
#| fig-cap: "Illustration of the fundamental theorem of simulation. All points in blue below the density curve belong to $\\mathcal{A}_f.$"
a = 4
b = 1.25
# curve(dbeta(x, shape1 = a, shape2 = b))
mode <- (a-1)/(a+b-2)
n <- 300
height <- dbeta(mode, a, b) + 0.1
x <- runif(n)
u <- runif(n) * height
inside <- u < dbeta(x, a, b)
# abline(v = mode, lty = "dashed")
ggplot() +
  stat_function(fun = dbeta, args = c(shape1 = a, shape2 = b), xlim = c(0,1), n = 1001) +
  geom_point(data.frame(u = u, x = x, col = factor(inside)),
               mapping = aes(x = x, y = u, color = col), show.legend = FALSE) +
  MetBrewer::scale_color_met_d("Hiroshige") +
  scale_x_continuous(limits = c(0,1), expand = expansion(add = c(0.02,0.02)), breaks = seq(0, 1, by = 0.25), labels = c("0","0.25","0.5","0.75","1")) +
  scale_y_continuous(limits = c(0, NA), expand = expansion(add = c(0,0.02))) +
  theme_classic()
```


## Simulation algorithms: accept-reject

- **Target**: sample from density $p(x)$ (hard to sample from)
- **Proposal**: find a density $q(x)$ with nested support, $\mathrm{supp}(p) \subseteq \mathrm{supp}(q)$, such that 
$$\frac{p(x)}{q(x)} \leq C, \quad C \geq 1.$$

## Rejection sampling algorithm

1. Generate $X$ from proposal with density $q(x)$.
2. Compute the ratio $R \gets p(X)/ q(X)$.
3. If $CU \leq R$ for $U \sim \mathsf{U}(0,1)$, return $X$, else go back to step 1.


## Remarks on rejection sampling

- Acceptance rate is $1/C$
   - we need on average $C$ draws from $q$ to get one from $p$
- $q$ must be more heavy-tailed than $p$
   - e.g., $q(x)$ Student-$t$ for $p(x)$ Gaussian
- $q$ should be cheap and easy to sample from!

## Designing a good proposal density

Good choices must satisfy the following constraints: 

- pick a family $q(x)$ so that $$C = \mathrm{sup}_x \frac{p(x)}{q(x)}$$ is as close to 1 as possible.
- you can use numerical optimization with $f(x) =\log p(x) - \log q(x)$ to find the mode $x^\star$ and the upper bound $C = \exp f(x^\star)$.

## Accept-reject illustration


```{r}
#| eval: true
#| echo: false
#| label: fig-acceptreject
#| fig-cap: "Target density (full) and scaled proposal density (dashed): the vertical segment at $x=1$ shows the percentage of acceptance for a uniform slice under the scaled proposal, giving an acceptance ratio of 0.58."
ptarget <- function(x){
  0.3*TruncatedNormal::dtmvnorm(x = cbind(x), mu = 2, sigma = matrix(0.25),lb = 0) + 
    0.4*TruncatedNormal::dtmvnorm(x = cbind(x), mu = 0, sigma = matrix(0.5),lb = 0, ub = 3) + 0.3*TruncatedNormal::dtmvnorm(x = cbind(x), mu = 0, sigma = matrix(4),lb = 0, ub = 5)
}

Cst <- dgamma(x = 4, shape = 4, rate = 1/0.75)/ptarget(2)
qprop <- function(x){1.02*dgamma(x = x+2, shape = 4, rate = 1/0.75)/Cst}
# curve(ptarget, from = -0.2, to = 4, n = 1001, ylim = c(0, 2))
# curve(qprop, from = 0, to = 4, add = TRUE, lty = 2)
ggplot() +
  stat_function(fun = ptarget, n = 1001, xlim = c(0, 5)) +
  stat_function(fun = qprop, n = 1001, xlim = c(0, 5), linetype = "dashed") +
  geom_segment(data = data.frame(
    x0 = 1, x1 = 1, y0 = 0, y1 = qprop(1)),
               mapping = aes(
                 x = x0, y = y0, xend = x1, yend = y1), 
    linewidth = 2) +
  geom_segment(data = data.frame(
    x0 = 1, x1 = 1, y0 = 0, y1 = ptarget(1)),
               mapping = aes(
                 x = x0, y = y0, xend = x1, yend = y1),
    linewidth = 2, col = "grey") +
  labs(x = "x", 
       y = "", 
       subtitle = "scaled proposal and target densities") +
    scale_y_continuous(limits = c(0, 0.62), expand = c(0,0)) + 
    scale_x_continuous(expand = c(0,0)) + 
  theme_classic() 
```

## Truncated Gaussian via accept-reject

Consider sampling $Y \sim \mathsf{No}(\mu, \sigma^2)$, but truncated in the interval $(a, b)$. The target density is
\begin{align*}
p(x; \mu, \sigma, a, b) = \frac{1}{\sigma}\frac{\phi\left(\frac{x-\mu}{\sigma}\right)}{\Phi(\beta)-\Phi(\alpha)}.
\end{align*}
for $\alpha= (a-\mu)/\sigma$ and $\beta = (b-\mu)/\sigma$.
where $\phi(\cdot), \Phi(\cdot)$ are respectively the density and distribution function of the standard Gaussian distribution.

## Accept-reject (crude version)

1. Simulate $X \sim \mathsf{No}(\mu, \sigma^2)$
2. reject any draw if $X < a$ or $X> b$. 

The acceptance rate is $C^{-1} = \{\Phi(\beta) - \Phi(\alpha)\}$

```{r}
#| eval: true
#| echo: true
# Standard Gaussian truncated on [0,1]
candidate <- rnorm(1e5)
trunc_samp <- candidate[candidate >= 0 & candidate <= 1]
# Acceptance rate
length(trunc_samp)/1e5
# Theoretical acceptance rate
pnorm(1)-pnorm(0)
```

## Accept-reject for truncated Gaussian  {.smaller}

Since the Gaussian is a location scale family, the inversion method gives
\begin{align*}
X \sim \mu + \sigma\Phi^{-1}\left[\Phi(\alpha) + \{\Phi(\beta)-\Phi(\alpha)\}U\right]
\end{align*}

We however need to evaluate $\Phi$ numerically (no closed-form expression).

The method fails for *rare event* simulation because the computer returns

- $\Phi(x) = 0$ for $x \leq -39$
- $\Phi(x)=1$ for $x \geq 8.3$,

implying that $a \leq 8.3$ for this approach to work [@LEcuyer.Botev:2017].

## Simulating tails of Gaussian variables {.smaller}

We consider simulation from a standard Gaussian truncated above $a>0$

Write the density of the truncated Gaussian as  [@Devroye:1986, p.381]$$f(x) = \frac{\exp(-x^2/2)}{\int_{a}^{\infty}\exp(-z^2/2)\mathrm{d} z}  =\frac{\exp(-x^2/2)}{c_1}.$$

Note that, for $x \geq a$, 
$$c_1f(x) \leq \frac{x}{a}\exp\left(-\frac{x^2}{2}\right)= a^{-1}\exp\left(-\frac{a^2}{2}\right)g(x);$$
where $g(x)$ is the density of a Rayleigh variable shifted by $a$.

::: {style="font-size: 50%;"}

The constant $C= \exp(-a^2/2)(c_1a)^{-1}$ approaches 1 quickly as $a \to \infty$ (asymptotically optimality).


:::

## Accept-reject: truncated Gaussian with Rayleigh  {.smaller}

The shifted Rayleigh has distribution function $$G(x) = 1-\exp\{(a^2-x^2)/2\}, x \geq a.$$ 




:::{.callout-important}

## Marsaglia algorithm
1. Generate a shifted Rayleigh  above $a$, $X \gets  \{a^2 - 2\log(U)\}^{1/2}$ for $U \sim \mathsf{U}(0,1)$
2. Accept $X$ if $XV \leq a$, where $V \sim \mathsf{U}(0,1)$.
:::

For sampling on $[a,b]$, propose from a Rayleigh truncated above at $b$ [@LEcuyer.Botev:2017].

```{r}
#| eval: true
#| echo: true
#| label: marsaglia-algo
a <- 8.3
niter <- 1000L
X <- sqrt(a^2 + 2*rexp(niter))
samp <- X[runif(niter)*X <= a]
```




## Markov chains

Plain ordinary Monte Carlo is great, but few algorithms are generic enough to be useful in complex high-dimensional problems.

We will instead typically build Markov chains that target an invariant stationary distribution. 


## Caveats?

Markov chain Monte Carlo methods generate **correlated** draws. 

**Questions**: 

1. can we use them as ordinary independent samples? 
2. what is the price to pay?

We need to do a little theoretical detour to answer these questions.

## Stationarity and Markov property


A stochastic process is

- **(strongly) stationary** if the distribution of $\{X_1, \ldots, X_t\}$ is the same as that of $\{X_{n+1}, \ldots X_{t+n}\}$ for any value of $n$ and given $t$.
- **weakly stationary** if $\mathsf{E}(X_t) = \mu$ for all $t$, and $\mathsf{Cov}(X_t, X_{t+h}) = \gamma_h$ does not depend on $t$.
- **Markov** if it satisfies the Markov property: given the current state of the chain, the future only depends on the current state and not on the past.

::: {style="font-size: 65%;"}
Strong stationarity implies weak stationarity.
:::

## Autoregressive process of order 1

Consider a first-order autoregressive process, or $\mathsf{AR}(1)$, 

$$Y_t = \mu + \phi(Y_{t-1} - \mu) + \varepsilon_t,$$ where 

- $\phi$ is the lag-one correlation, 
- $\mu$ the global mean
- $\varepsilon_t$ is an iid innovation with mean zero and variance $\sigma^2$

If $|\phi| < 1$, the process is stationary, otherwise the variance increases with $t$.


## Unconditional moments via recursion  {.smaller}


The Gaussian $\mathsf{AR}(1)$ stationarity process follows $Y_t \sim \mathsf{Gauss}(\mu, \sigma^2/(1-\phi^2)$ marginally.
\begin{align*}
Y_t &= \mu (1-\phi) + \varepsilon_t + \phi \{\mu + \phi(Y_{t-2}-\mu) + \varepsilon_{t-1}\}
\\&= \mu + \sum_{j=0}^\infty \phi_j\varepsilon_{t-j}
\end{align*}
whence $\mathsf{E}(Y_t) = \mu$ and
\begin{align*}
\mathsf{Va}(Y_t) &= \mathsf{Va}\left(\sum_{j=0}^\infty \phi_j\varepsilon_{t-j}\right)
= \sum_{j=0}^\infty \phi_j^2 \mathsf{Va}(\varepsilon_{t-j})
=\frac{\sigma^2}{(1-\phi^2)}
\end{align*}
where the geometric series converges if $\phi<1$ and diverges otherwise.

## Unconditional moments via tower law

If the process is weakly stationary, then $\mathsf{E}_{Y_{t}}(Y_t)=\mathsf{E}_{Y_{t-1}}(Y_{t-1})$
\begin{align*}
\mathsf{E}_{Y_{t}}(Y_t) &= \mathsf{E}_{Y_{t-1}}\left\{\mathsf{E}_{Y_{t} \mid Y_{t-1}}(Y_t)\right\}
\\&= \mu(1-\phi) + \phi\mathsf{E}_{Y_{t-1}}(Y_{t-1})
\end{align*}
and so the unconditional mean is $\mu$.
For the variance, we have
\begin{align*}
\mathsf{E}_{Y_{t}}(Y_t) &= \mathsf{E}_{Y_{t-1}}\left\{\mathsf{Va}_{Y_{t} \mid Y_{t-1}}(Y_t)\right\} + \mathsf{Va}_{Y_{t-1}}\left\{\mathsf{E}_{Y_{t} \mid Y_{t-1}}(Y_t)\right\}\\
& = \sigma^2 + \mathsf{Va}_{Y_{t-1}}\left\{\mu + \phi(Y_{t-1} - \mu)\right\}
\\&= \sigma^2 + \phi^2 \mathsf{Va}_{Y_{t-1}}(Y_{t-1}).
\end{align*}

## Variance of sample average

Intuitively, a sample of correlated observations carries less information than an independent sample of draws.

We want the variance of the sample average, which is
\begin{align*}
\mathsf{Va}\left(\overline{Y}_T\right) &= \frac{1}{T^2}\sum_{t=1}^T \sum_{s=1}^T \mathsf{Co}(Y_t, Y_s)
\\&= \frac{1}{T^2}\sum_{t=1}^T \mathsf{Va}(Y_t) + \frac{2}{T^2} \sum_{t=1}^{T-1}\sum_{s = t+1}^T \mathsf{Co}(Y_t, Y_s).
\end{align*}


## Autocovariance and Markov property


The covariance at lag $k$, in terms of innovations, gives
\begin{align*}
\gamma_k = \mathsf{Co}(Y_t, Y_{t-k}) = \mathsf{Va}(\phi Y_{t-1}, Y_{t-k}) + \mathsf{Va}(\varepsilon_t, Y_{t-k}) = \phi \gamma_{k-1}
\end{align*}
so by recursion $\gamma_k = \gamma^k\mathsf{Va}(Y_t)$.


The $\mathsf{AR}(1)$ process is first-order Markov since the conditional distribution $p(Y_t \mid Y_{t-1}, \ldots, Y_{t-p})$ equals $p(Y_t \mid Y_{t-1}).$

## Variance of sample average, redux

If a central limit theorem applies, the limiting variance of the sample mean simplifies to
\begin{align*}
\lim_{T \to \infty} T\mathsf{Va}\left(\overline{Y}_T\right) = \tau^2 \left\{1+2\sum_{t=1}^\infty \gamma_t\right\}.
\end{align*}
which is a function of 

- the unconditional variance $\tau^2$
- the lag-$k$ autocorrelation $\mathsf{Cor}(Y_{t}, Y_{t+k})=\gamma_k.$

## Correlogram


```{r}
#| eval: true
#| echo: false
#| fig-height: 4
#| fig-width: 10
#| label: fig-correlograms
#| fig-cap: "Correlogram of two Markov chains. These plots, often called acf or autocorrelation functions, show the lag-k sample autocorrelation against lag number."
chains <- cbind("chain 1" = arima.sim(model = list(ar = c(0.5,-0.1), 
                                       ma = c(0.4)), n = 10000),
                "chain 2" = arima.sim(model = list(ar = 0.99), n = 10000))
bayesplot::mcmc_acf(x = coda::as.mcmc(chains)) + theme_classic()
```

## Variance of sample mean of AR(1)

The lag-$k$ correlation of the stationary autoregressive process of order 1 is $\phi^k$, so $$T\mathsf{Va}\left(\overline{Y}_T\right)=\sigma^2(1+\phi)/(1-\phi).$$

For an independent sample, we have $$T\mathsf{Va}\left(\overline{Y}_T\right)=\sigma^2/(1-\phi^2).$$ 




## Inefficiency curve for AR(1) {.smaller}

```{r}
#| label: fig-ar1-variance
#| fig-width: 8
#| fig-height: 4
#| fig-cap: "Left: scaled asymptotic variance of the sample mean for AR(1) (full line) and independent observations with the same marginal variance (dashed). Right: variance ratio for positive correlations."
#| message: false
#| warning: false
#| echo: false
#| eval: true
var2 <- function(rho){(1+rho)/(1-rho)}
var1 <- function(rho){1/(1-rho^2)}
var_ratio <- function(rho){var2(rho)/var1(rho)}
g1 <- ggplot() +
  stat_function(fun = var1, xlim = c(-0.9,0.9), n = 1001L, linetype = "dashed") +
  stat_function(fun = var2, xlim = c(-0.9,0.9), n = 1001L) +
  labs(y = "", x = expression(phi)) +
  theme_classic()
g2 <- ggplot() +
  stat_function(fun = var_ratio,
                xlim = c(0,1), 
                n = 1001L) +
  labs(y = "") + 
  theme_classic()  
g1 + g2
```


To get the same precision for the mean of $\mathsf{AR}(1)$ process with $\phi \approx 0.75$ than with i.i.d. data, we would need 9 times as many observations.

## Morale of the story 

The price to pay for having correlated samples is 

:::{style="font-size: 2em; color: #ff585d; text-align: center"}

**inefficiency**

:::

The higher the autocorrelation, the larger the variability of our estimators.

## When can we use Markov chains?

If a Markov chain is irreducible and acyclic, it has a unique stationary distribution.

- **irreducibility**: means that the chain can move from anywhere to anywhere, so it doesn't get stuck in part of the space forever.
- **acyclic**: cyclical chains loop around and visit periodically a state

Ergodic theorem is our guarantee of convergence (does not require acyclic).


## Examples of cyclical or reducible chains

Consider discrete Markov chains over the integers $1, 2, 3$ with transition matrices

$$
P_1 = \begin{pmatrix}
0.5 & 0.3 & 0.2 \\
0 & 0.4 & 0.6 \\
0 & 0.5 & 0.5
\end{pmatrix},
\quad
P_2 = \begin{pmatrix}
0 & 0 & 1 \\
1 & 0 & 0 \\
0 & 1 & 0
\end{pmatrix}.
$$
Chain 1 is reducible to $\{2, 3\}$, chain 2 is cyclical.


## Law of large number (ergodic theorem)

Ergodicity means that two segments of a time series far enough apart act as independent.

Let $\{Y_t\}$ is a weakly stationary sequence with mean $\mathsf{E}(Y_t)=\mu$ and $\gamma_h = \mathsf{Cov}(Y_t, Y_{t+h})$. Then, if the autocovariance series is convergent, meaning
$$\sum_{t=0}^\infty |\gamma_h| < \infty,$$
then $\{Y_t\}$ is ergodic for the mean and $\overline{Y} \stackrel{\mathrm{p}}{\to} \mu$.

## Ergodicity and transformations

The ergodic theorem is a law of large numbers for stochastic processes that allows for serial dependence between observations, provided the latter is not too large.

Any transformation $g(\cdot)$ of a stationary and ergodic process $\{Y_t\}$ retains the properties, so $\overline{g} = T^{-1} \sum_{t=1}^T g(Y_t) \to \mathsf{E}\{g(Y_t)\}$ as $T \to \infty$.


## Convergence of Markov chains


```{r}
#| label: fig-discrete-markov-chain
#| eval: true
#| echo: false
#| cache: true
#| fig-cap: "Discrete Markov chain on integers from 1 to 5, with traceplot of 1000 first iterations (left) and running mean plots of sample proportion of each state visited (right)."
set.seed(1234)
P3 <- rbind(c(4,2,0,0,0),
            c(1,4,1,0,0),
            c(0,1,4,1,0),
            c(0,0,1,4,1),
            c(0,0,0,2,4)) / 6
chain <- integer(1e5L)
state <- sample.int(n = 5, size = 1)
for(i in seq_along(chain)){
  state <- sample.int(n = 5, size = 1, prob = P3[state,])
  chain[i] <- state
}
library(ggplot2)
library(patchwork)
g1 <- ggplot(data = data.frame(iteration = 1:1000,
                               state = chain[1:1000]),
             mapping = aes(x = iteration, y = state)) +
  geom_line() +
  theme_classic() +
  labs(y = "", subtitle = "state")
iter <- seq(from = 100, to = length(chain), by = 100)
sub <- sapply(iter,
              function(n){
                as.numeric(table(chain[seq_len(n)])/n)
                }) 
g2 <- ggplot(
  data = data.frame(
    x = rep(iter, each =5),
    y = c(sub),
    state = factor(rep(1:5, length.out = length(sub)))),
  mapping = aes(x = x, group = state, color = state, y = y)) +
  geom_line() +
  scale_x_continuous(trans = "sqrt", labels = scales::unit_format(unit = "K", scale = 1e-3)) + 
  labs(y = "",
       subtitle = "probability of state", 
       x = "iteration") +
  MetBrewer:::scale_color_met_d("Hiroshige") +
  theme_classic() +
  theme(legend.position = "bottom")
g1 + g2
```

## Markov chain Monte Carlo

We consider simulating from a distribution with associated density function $\propto p(\boldsymbol{\theta})$.

- known up to a normalizing factor not depending on $\boldsymbol{\theta}$.

We use a conditional density $q(\boldsymbol{\theta} \mid \boldsymbol{\theta}^{\text{cur}})$ to generate proposals from the current value $\boldsymbol{\theta}^{\text{cur}}$.


## Transition kernel and detailed balanced

:::{style="color: #ff585d; text-align: center"}

**Theoretical details provided for completeness**

:::

A transition kernel  $K(\boldsymbol{\theta}^{\text{cur}}, \boldsymbol{\theta}^{\text{prop}})$ proposes a move from the current value $\boldsymbol{\theta}^{\text{cur}}$ to a proposal $\boldsymbol{\theta}^{\text{prop}}$.

If our target is $p(\boldsymbol{\theta})$, then the Markov chain satisfies the **detailed balance** condition with respect to $p(\cdot)$ if
\begin{align*}
K(\boldsymbol{\theta}^{\text{cur}}, \boldsymbol{\theta}^{\text{prop}})p(\boldsymbol{\theta}^{\text{cur}}) = K(\boldsymbol{\theta}^{\text{prop}}, \boldsymbol{\theta}^{\text{cur}})p(\boldsymbol{\theta}^{\text{prop}}).
\end{align*}
If a Markov chain satisfies the detailed balance with respect to $p(\cdot)$, then the latter is necessarily the invariant density of the Markov chain and the latter is reversible.


## Transition kernel of Metropolis--Hastings algorithm

:::{style="color: #ff585d; text-align: center"}

**Theoretical details provided for completeness**

:::

The Metropolis--Hastings algorithm has transition kernel for a move from $\boldsymbol{x}$ to a proposal $\boldsymbol{y}$
\begin{align*}
K(\boldsymbol{x}, \boldsymbol{y}) = \alpha(\boldsymbol{x}, \boldsymbol{y}) q(\boldsymbol{y} \mid \boldsymbol{x}) + \{1- r(\boldsymbol{x})\}\mathsf{I}(\boldsymbol{y}=\boldsymbol{x})
\end{align*}
where $r(\boldsymbol{x})=\int \alpha(\boldsymbol{x}, \boldsymbol{y}) q(\boldsymbol{y} \mid \boldsymbol{x})\mathrm{d} \boldsymbol{y}$ is the average probability of acceptance of a move from $\boldsymbol{x}$, $\mathsf{I}(\cdot = \boldsymbol{x})$ is a point mass at $\boldsymbol{x},$ and $\alpha(\cdot)$ is defined on the next slide.

The Metropolis--Hastings algorithm satisfies detailed balanced.

## Metropolis--Hastings algorithm 

Starting from an initial value $\boldsymbol{\theta}_0$:

1.  draw a proposal value $\boldsymbol{\theta}_t^{\star} \sim q(\boldsymbol{\theta} \mid \boldsymbol{\theta}_{t-1})$.
2.  Compute the acceptance ratio $$
    R = \frac{p(\boldsymbol{\theta}_t^{\star})}{p(\boldsymbol{\theta}_{t-1})}\frac{q(\boldsymbol{\theta}_{t-1} \mid \boldsymbol{\theta}_t^{\star} )}{q(\boldsymbol{\theta}_t^{\star} \mid \boldsymbol{\theta}_{t-1})}
    $$
3.  With probability $\alpha=\min\{R, 1\}$, accept the proposal and set $\boldsymbol{\theta}_t \gets \boldsymbol{\theta}_t^{\star}$, otherwise set the value to the previous state, $\boldsymbol{\theta}_t \gets \boldsymbol{\theta}_{t-1}$.


## Interpretation



- If $R>1$, the proposal has higher density and we always accept the move. 
- If we reject the move, the Markov chain stays at the current value, which induces autocorrelation.
- Since the acceptance probability depends only on the density through ratios, normalizing factors of $p$ and $q$ cancel out.


## Symmetric proposals and random walk

If the proposal is symmetric, the ratio of proposal densities is $$q(\boldsymbol{\theta}_{t-1} \mid \boldsymbol{\theta}_t^{\star} ) / q(\boldsymbol{\theta}_t^{\star} \mid \boldsymbol{\theta}_{t-1}) = 1.$$

Common examples include random walk proposals
$$\boldsymbol{\theta}_t^{\star} \gets \boldsymbol{\theta}_{t-1} + \tau Z, \qquad Z$$ where $Z$ is a mean zero, variance one random variable.

## Independent proposals

- If we pick instead a global proposal, we must ensure that $q$ samples in far regions (recall rejection sampling), otherwise ...
- Good proposals include heavy tailed distribution such as Student-$t$ with small degrees of freedom, centered at the maximum a posteriori $\widehat{\boldsymbol{\theta}}$ and with scale matrix $-\mathbf{H}^{-1}(\boldsymbol{\theta}_t^{\star})$, where $\mathbf{H}(\cdot)$ is the Hessian of the log posterior.


## Upworthy data example

We model the Poisson rates for headlines with questions or not. Our model is
\begin{align*}
Y_{i} &\sim \mathsf{Po}(n_i\lambda_i), \qquad (i=1,2)\\
\lambda_1 &= \exp(\beta + \kappa) \\
\lambda_2 &= \exp(\beta) \\
\beta & \sim \mathsf{No}(\log 0.01, 1.5) \\
\kappa &\sim \mathsf{No}(0, 1)
\end{align*}

## Implementation details: data and containers

In regression models, scale inputs if possible.

```{r}
#| eval: false
#| echo: true
#| # Load data
data(upworthy_question, package = "hecbayes")
# Compute sufficient statistics
data <- upworthy_question |>
  dplyr::group_by(question) |>
  dplyr::summarize(ntot = sum(impressions),
                   y = sum(clicks))
# Create containers for MCMC
niter <- 1e4L
chain <- matrix(0, nrow = niter, ncol = 2L)
colnames(chain) <- c("beta","kappa")
```


## Implementation details: log posterior function

Perform all calculations on the log scale to avoid numerical overflow! 

```{r}
#| eval: false
#| echo: true
# Code log posterior as sum of log likelihood and log prior
loglik <- function(par, counts = data$y, offset = data$ntot, ...){
  lambda <- exp(c(par[1] + log(offset[1]), par[1] + par[2] + log(offset[2])))
 sum(dpois(x = counts, lambda = lambda, log = TRUE))
}
# Note common signature of function
logprior <- function(par, ...){
  dnorm(x = par[1], mean = log(0.01), sd = 1.5, log = TRUE) +
    dnorm(x = par[2], log = TRUE)
}
logpost <- function(par, ...){
  loglik(par, ...) + logprior(par, ...)
}
```

## Implementation details: proposals

Use good starting values for your Markov chains, such as maximum a posteriori.

```{r}
#| eval: false
#| echo: true
# Compute maximum a posteriori (MAP)
map <- optim(
  par = c(-4, 0.07),
  fn = logpost,
  control = list(fnscale = -1),
  offset = data$ntot,
  counts = data$y,
  hessian = TRUE)
# Use MAP as starting value
cur <- map$par
# Compute logpost_cur - we can keep track of this to reduce calculations
logpost_cur <- logpost(cur)
# Proposal covariance
cov_map <- -2*solve(map$hessian)
chol <- chol(cov_map)
```

## Implementation details: Metropolis--Hastings algorithm

Use seed for reproducibility, do not compute posterior twice, compute log of acceptance ratio. 

```{r}
#| eval: false
#| echo: true
set.seed(80601)
naccept <- 0L
for(i in seq_len(niter)){
  # Multivariate normal proposal - symmetric random walk
  prop <- c(rnorm(n = 2) %*% chol + cur)
  logpost_prop <- logpost(prop)
  logR <- logpost_prop - logpost_cur
  if(logR > -rexp(1)){
    cur <- prop
    logpost_cur <- logpost_prop
    naccept <- naccept + 1L
  }
  chain[i,] <- cur
}
```

## Implementation details: analysis of output


```{r}
#| eval: false
#| echo: true
# Posterior summaries
summary(coda::as.mcmc(chain))
# Computing standard errors using batch means
sqrt(diag(mcmc::olbm(chain, batch.length = niter/40)))
```

```
1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

          Mean       SD  Naive SE Time-series SE
beta  -4.51268 0.001697 1.697e-05      6.176e-05
kappa  0.07075 0.002033 2.033e-05      9.741e-05

2. Quantiles for each variable:

          2.5%      25%      50%      75%    97.5%
beta  -4.51591 -4.51385 -4.51273 -4.51154 -4.50929
kappa  0.06673  0.06933  0.07077  0.07212  0.07463
```

## Standard errors for posterior means -- batch means

@Geyer:2011 recommends to segment the time series into batches

1. Break the chain of length $B$ (after burn in) in $K$ blocks of size $\approx K/B.$
2. Compute the sample mean of each segment.
3. Compute the standard deviation of the segments mean.
4. Rescale by $K^{-1/2}$ to get standard error of the global mean.

## Illustration of batch means



```{r}
#| label: fig-mcmc-batchmean
#| eval: true
#| echo: false
#| fig-cap: "Calculation of the standard error of the posterior mean using the batch method."
set.seed(123450)
chain <- as.numeric(arima.sim(model = list(ar = c(0.9)), n = 2000)) + 0.4
batchMean <- function(x, batchSize = 100){
  niter <- length(x)
    nbatch <- niter%/%batchSize
    niter <- nbatch * batchSize
    ibatch <- rep(1:nbatch, each = batchSize)[1:niter]
    batchMeans <- t(sapply(split(data.frame(x[1:niter]), ibatch),
        function(batch) apply(batch, 2, mean)))
    return(as.numeric(batchMeans))
}
ggplot() +
  geom_line(data = data.frame(t = 1:2000,
                         chain = chain),
       mapping = aes(x = t,
                     y = chain),
       alpha = 0.1) +
  geom_segment(data = data.frame(x0 = seq(1, 2000, by = 100),
                                 x1 = seq(100, 2000, by = 100),
                                 y = batchMean(chain, batchSize = 100)),
               mapping = aes(x = x0, y = y, yend = y, xend = x1),
               linetype = "dashed") +
  geom_hline(yintercept = mean(chain)) +
  labs(x = "iteration number", y = "") +
  theme_classic()
```

## Standard errors for posterior means -- autoregressive

We can also fit an high-order autoregressive process $\mathsf{AR}(p)$ and approximate the unconditional variance by that, and divide by $\sqrt{T}$.

- Standard methods (Yule--Walker equations, maximum likelihood, spectral estimation) apply.



## References

