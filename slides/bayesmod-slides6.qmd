---
title: "Bayesian modelling"
author: "LÃ©o Belzile"
subtitle: "Bayesian workflow and computational strategies"
date: today
date-format: "[Last compiled] dddd MMM D, YYYY"
eval: true
echo: true
cache: true
bibliography: MATH80601A.bib
format:
  revealjs:
    slide-number: true
    preview-links: auto
    theme: [simple, hecmontreal.scss]
    title-slide-attributes:
      data-background-color: "#ff585d"
    logo: "fig/logo_hec_montreal_bleu_web.png"
---


```{r}
#| include: false
#| eval: true
#| echo: false
hecbleu <- c("#002855")
fcols <- c(gris = "#888b8d",
           bleu = "#0072ce",
           aqua = "#00aec7",
           vert = "#26d07c",
           rouge = "#ff585d",
           rose = "#eb6fbd",
           jaune = "#f3d03e")
pcols <- c(gris = "#d9d9d6",
           bleu = "#92c1e9",
           agua = "#88dbdf",
           vert = "#8fe2b0",
           rouge = "#ffb1bb",
           rose = "#eab8e4",
           jaune = "#f2f0a1")
library(ggplot2)
theme_set(theme_classic())
library(patchwork)
knitr::opts_chunk$set(fig.retina = 3, collapse = TRUE)
options(digits = 3, width = 75)
```



## Visual diagnostic: trace plots

Display the Markov chain sample path as a function of the number of iterations.

- Run multiple chains to see if they converge to the same target.
   - if not, check starting values (compare log posterior) or parameter identifiability!
- Markov chains should look like a fat hairy caterpillar!
- `bayesplot` and `coda` have functionalities for plots (trace plot, trace rank, correlograms, marginal densities, etc.)


## Checking convergence with multiple chains


![Four healthy parallel chains for parameters.](fig/catterpillar_traceplots.png)

## Effective sample size

Are my chains long enough to compute reliable summaries?

Compute the sample size we would have with independent draws by taking
$$
\mathsf{ESS} = \frac{B}{\left\{1+2\sum_{t=1}^\infty \gamma_t\right\}}
$$ 
where $\gamma_t$ is the lag $t$ autocorrelation. 

The relative effective sample size is simply $\mathsf{ESS}/B$: small values indicate pathological or inefficient samplers. 

## How many samples?

We want our average estimate to be reliable!

- We probably need $\mathsf{ESS}$ to be several hundred 
- We can estimate the variance of the target to know the precision

- (related question: how many significant digits to report?)

In **R**, via `coda::effectiveSize()`

## Estimating the variance (block method)

1. Break the chain of length $B$ (after burn in) in $K$ blocks of size $\approx K/B$.
2. Compute the sample mean of each segment. These values form a Markov chain and should be approximately uncorrelated.
3. Compute the standard deviation of the segments mean. Rescale by $K^{-1/2}$ to get standard error of the global mean.

More efficient methods using overlapping blocks exists.

## Block means in pictures

```{r}
#| label: fig-mcmc-batchmean
#| eval: true
#| echo: false
#| fig-cap: "Calculation of the standard error of the posterior mean using the batch method."
set.seed(123450)
chain <- as.numeric(arima.sim(model = list(ar = c(0.9)), n = 2000)) + 0.4
batchMean <- function(x, batchSize = 100){
  niter <- length(x)
    nbatch <- niter%/%batchSize
    niter <- nbatch * batchSize
    ibatch <- rep(1:nbatch, each = batchSize)[1:niter]
    batchMeans <- t(sapply(split(data.frame(x[1:niter]), ibatch), 
        function(batch) apply(batch, 2, mean)))
    return(as.numeric(batchMeans))
}
ggplot() +
  geom_line(data = data.frame(t = 1:2000,
                         chain = chain),
       mapping = aes(x = t,
                     y = chain),
       alpha = 0.1) +
  geom_segment(data = data.frame(x0 = seq(1, 2000, by = 100),
                                 x1 = seq(100, 2000, by = 100),
                                 y = batchMean(chain, batchSize = 100)),
               mapping = aes(x = x0, y = y, yend = y, xend = x1), 
               linetype = "dashed") +
  geom_hline(yintercept = mean(chain)) +
  labs(x = "iteration number", y = "") +
  theme_classic()
```


## Cautionary warning about stationarity

Batch means only works if the chain is sampling from the stationary distribution! 

The previous result (and any estimate) will be unreliable and biased if the chain is not (yet) sampling from the posterior.

## Lack of stationarity


```{r}
#| eval: true
#| echo: false
#| cache: true
#| label: fig-badstart
#| fig-cap: "Traceplots of three Markov chains for the same target with different initial values for the first 500 iterations (left) and trace rank plot after discarding these (right). The latter is indicative of the speed of mixing."
set.seed(80601)
niter <- 2500
fakesamp <- rnorm(n = 20, mean = 1, sd = 2)
fn <- function(par){ sum(dnorm(fakesamp, mean = par, sd = 2, log = TRUE))}
chain1 <- matrix(nrow = niter, ncol = 1)
colnames(chain1) <- "beta"
chain2 <- chain3 <-  chain1
cur <- c(-50, 10, 0)
for(i in seq_len(niter)){
  chain1[i,1] <- mgp::mh.fun(cur = cur[1], lb = -Inf, ub = Inf, prior.fun = identity, lik.fun = fn, pcov = matrix(0.3), cond = FALSE, transform = FALSE)$cur
  chain2[i,1] <- mgp::mh.fun(cur = cur[2], lb = -Inf, ub = Inf, prior.fun = identity, lik.fun = fn, pcov = matrix(0.3), cond = FALSE, transform = FALSE)$cur
  chain3[i,1] <- mgp::mh.fun(cur = cur[3], lb = -Inf, ub = Inf, prior.fun = identity, lik.fun = fn, pcov = matrix(0.3), cond = FALSE, transform = FALSE)$cur
  cur <- c(chain1[i,1], chain2[i,1], chain3[i,1])
}
# coda::traceplot(coda::as.mcmc(chains_goldi))
bayesplot::color_scheme_set("darkgray")
mcmc_list <- coda::mcmc.list(
  coda::mcmc(chain1), 
  coda::mcmc(chain2), 
  coda::mcmc(chain3))
mcmc_list2 <- coda::mcmc.list(
  coda::mcmc(chain1[-(1:500),,drop = FALSE]), 
  coda::mcmc(chain2[-(1:500),,drop = FALSE]), 
  coda::mcmc(chain3[-(1:500),,drop = FALSE]))
g1 <- bayesplot::mcmc_trace(
  x = mcmc_list, 
  n_warmup = 0,window = c(1,500)) +
  labs(y = "") +
  theme(legend.position = "none")
g2 <- bayesplot::mcmc_rank_overlay(
  x = mcmc_list2) +
  labs(y = "") +
  theme(legend.position = "none")
g1 + g2
```

## Potential scale reduction statistic 

The Gelman--Rubin diagnostic, denoted $\widehat{R}$, is obtained by running multiple chains and considering the difference between within-chain and between-chains variances,

\begin{align*}
\widehat{R} = \left(\frac{\mathsf{Va}_{\text{within}}(B-1) + \mathsf{Va}_{\text{between}}}{B\mathsf{Va}_{\text{within}}}\right)^{1/2}
\end{align*}


Any value of $\widehat{R}$ larger 1 is indicative of problems of convergence.

## Bad chains


```{r}
#| eval: true
#| echo: false
#| label: fig-rhat
#| fig-cap: "Two pairs of Markov chains: the top ones seem stationary, but with different modes and  $\\widehat{R} \\approx 3.4$. The chains on the right hover around zero, but do not appear stable, with $\\widehat{R} \\approx 1.6$."
B <- 1000
set.seed(1234)
c1 <- arima.sim(model = list(ar = c(0.6,0.2)), 
                           rand.gen = rexp,
                           n = B) + -2
c2 <- arima.sim(model = list(ar = c(0.5,0.2)),
                           n = B) - 1
chains <- coda::mcmc.list(
  list(theta = coda::mcmc(c1),
       theta = coda::mcmc(c2)))
rhat1 <- coda::gelman.diag(chains)
# bayesplot::mcmc_trace(chains)

g1 <- ggplot(data = data.frame(
    time = rep(seq_len(B), length.out = 2*B),
    chain = c(c1, c2),
    group = factor(rep(c(1,2), each = B))),
  mapping = aes(x = time, y = chain, col = group)) +
  geom_line() +
  scale_color_manual(values = MetBrewer::met.brewer("Renoir", 3)[c(2:3)]) + 
  labs(x = "iteration number", y = "") + 
  theme_classic() +
  theme(legend.position = "none")

set.seed(1234)
c1b <- arima.sim(model = list(ar = c(0.6,0.2)), 
                rand.gen = rnorm,
                n = B) + seq(-2, 2, length.out = B)
c2b <- arima.sim(model = list(ar = c(0.5,0.2)),
                n = B) +  seq(2, -2, length.out = B)
chains <- coda::mcmc.list(
  list(theta = coda::mcmc(c1b),
       theta = coda::mcmc(c2b)))
rhat2 <- coda::gelman.diag(chains)
# bayesplot::mcmc_trace(chains)

g2 <- ggplot(data = data.frame(
  time = rep(seq_len(B), length.out = 2*B),
  chain = c(c1b, c2b),
  group = factor(rep(c(1,2), each = B))),
  mapping = aes(x = time, y = chain, col = group)) +
  geom_line() +
  scale_color_manual(values = MetBrewer::met.brewer("Renoir", 3)[c(2:3)]) + 
  labs(x = "iteration number", y = "") + 
  theme_classic() +
  theme(legend.position = "none")

g1 + g2
```


## Posterior predictive checks

1. For each of the $B$ draws from the posterior, simulate $n$ observations from the posterior predictive $p(\widetilde{\boldsymbol{y}} \mid \boldsymbol{y})$
2. For each replicate, compute a summary statistics (median, quantiles, std. dev., etc.) 
3. Compare it with the same summary computed for the sample $\boldsymbol{y}$.

## Posterior predictive checks

```{r}
#| eval: true
#| echo: false
#| label: fig-posterior-pred-check
#| fig-cap: "Posterior predictive checks for the standard deviation (top) and density of posterior draws (bottom) for hierarchical Poisson model with individual effects (left) and simpler model with only conditions (right)."
knitr::include_graphics("fig/fig-posterior-pred-check.png")
```

## Log pointwise predictive density

Consider the expected value of the log observation-wise log density with respect to the posterior distribution $p(\boldsymbol{\theta} \mid \boldsymbol{y})$, 
\begin{align*}
\mathsf{LPPD}_i = \mathsf{E}_{\boldsymbol{\theta} \mid \boldsymbol{y}} \left\{ \log p(y_i \mid \boldsymbol{\theta})\right\},
\end{align*}
 
The higher the value of $\mathsf{LPPD}_i$, the better the fit for that observation.

## Widely available information criterion 

To build an information criterion, we add a penalization factor that approximates the effective number of parameters in the model, with
\begin{align*}
n\mathsf{WAIC} = -\sum_{i=1}^n \mathsf{LPPD}_i + \sum_{i=1}^n \mathsf{Va}_{\boldsymbol{\theta} \mid \boldsymbol{y}}\{\log p(y_i \mid \boldsymbol{\theta})\}
\end{align*} 
where we use again the empirical variance to compute the rightmost term.

Smaller values of $\mathsf{WAIC}$ are better.

## Bayesian leave-one-out cross validation

In Bayesian setting, we can use the leave-one-out predictive density
$$p(y_i \mid \boldsymbol{y}_{-i})$$ as a measure of predictive accuracy. the 

We can use importance sampling to approximate the latter.

Requirement: need to keep track of the log likelihood of each observation for each posterior draw ($B \times n$ values).

## LOO-CV diagnostics

We can draw $B$ samples from  $p(\widetilde{y} \mid \boldsymbol{y}_{-i})$ and compute the rank of $y_i$.

Under perfect calibration, ranks should be uniform.

## Leave-one-out with quantile-quantile plots

```{r}
#| eval: true
#| echo: false
#| label: fig-posterior-loocv
#| fig-cap: "Quantile-quantile plots based on leave-one-out cross validation for model for the hierarchical Poisson model fitted to the Upworthy data with the individual random effects (left) and without (right)."
knitr::include_graphics("fig/fig-loocv-qqplots.png")
```




## References

