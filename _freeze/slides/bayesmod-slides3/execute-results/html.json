{
  "hash": "52bf7ed50d8cbb00fc4892297a15e7cd",
  "result": {
    "markdown": "---\ntitle: \"Simulation-based inference\"\nauthor: \"LÃ©o Belzile\"\nsubtitle: \"Priors\"\ndate: today\ndate-format: YYYY\neval: true\necho: true\ncache: true\nformat:\n  revealjs:\n    slide-number: true\n    preview-links: auto\n    theme: [simple, hecmontreal.scss]\n    title-slide-attributes:\n      data-background-color: \"#ff585d\"\n    logo: \"fig/logo_hec_montreal_bleu_web.png\"\n---\n\n\n\n\n## Bayesian inference beyond conjugate models\n\nHow to circumvent the problem of intractable posteriors?\n\n- simulation-based methods: accept-reject, Markov chain Monte Carlo, particle filters, etc.\n- deterministic methods: (integrated nested) Laplace approximations, variational Bayes, expectation propagation, etc.\n\nWe focus on the Monte Carlo methods in the sequel.\n\n## Objective of methods\n\nSuppose we can simulate $B$ i.i.d. variables with the same distribution, $X_b \\sim F$ $(b=1, \\ldots, B).$\n\nWe want to compute $\\mathsf{E}\\{g(X)\\}=\\mu_g$ for some functional $g(\\cdot)$\n\n- $g(x)=x$ (posterior mean)\n- $g(x) = \\mathsf{I}(x \\in A)$ (probability of event)\n- etc.\n\n## Monte Carlo methods\n\nWe substitute expected value by sample average \n$$\\widehat{\\mu}_g = \\frac{1}{B} \\sum_{b=1}^B g(X_b), \\qquad X_b \\sim F$$\n\n- law of large number guarantees convergence of $\\widehat{\\mu}_g \\to \\mu_g$ if the latter is finite.\n- central limit theorem applies: $$\\sqrt{B}(\\widehat{\\mu}_g - \\mu_g) \\sim \\mathsf{No}(0, \\sigma^2_g).$$\n\n\n## Ordinary Monte Carlo\n\nWe want to have an estimator as precise as possible.\n\n- but we can't control the variance of $g(X)$, say $\\sigma_g^2$\n- the more simulations $B$, the lower the variance of the mean. \n- sample average for i.i.d. data has variance $\\sigma^2_g/B$\n- to reduce the standard deviation by a factor 10, we need $100 \\times B$ draws!\n\n\nRemember: the answer is **random**.\n\n## Example: functionals of gamma distribution\n\n\n::: {.cell hash='bayesmod-slides3_cache/revealjs/fig-monte-carlo-path_beb78cbaecb0a399d989100d6cf65bb7'}\n::: {.cell-output-display}\n![Running mean trace plots for $g(x)=\\mathrm{I}(x<1)$ (left), $g(x)=x$ (middle) and $g(x)=1/x$ (right) for a Gamma distribution with shape 0.5 and rate 2, as a function of the Monte Carlo sample size.](bayesmod-slides3_files/figure-revealjs/fig-monte-carlo-path-1.png){#fig-monte-carlo-path width=960}\n:::\n:::\n\n\n## Simulation algorithms: inversion method\n\nIf $F$ is an absolutely continuous distribution function, then \n$$F(X) \\sim \\mathsf{U}(0,1).$$\nThe inversion method consists in applying the quantile function $F^{-1}$ to $U \\sim \\mathsf{U}(0,1)$, viz. $$F^{-1}(U) \\sim X.$$\n\n## Inversion method for truncated distributions\n\nConsider a random variable $Y$ with distribution function $F$.\n\nIf $X$ follows the same distribution as $Y$, but restricted over the interval $[a,b]$, then \n$$\\Pr(X \\leq x) = \\frac{F(x) - F(a)}{F(b)-F(a)}, \\qquad a \\leq x \\leq b,$$\n\nTherefore, $$F^{-1}[F(a) + \\{F(b)-F(a)\\}U] \\sim X$$\n\n\n\n## Simulation algorithms: accept-reject\n\n- **Target**: sample from density $p(x)$ (hard to sample from)\n- **Proposal**: find a density $q(x)$ with nested support, $\\mathrm{supp}(p) \\subset \\mathrm{supp}(q)$, such that \n$$\\frac{p(x)}{q(x)} \\leq C, \\quad C \\geq 1.$$\n\n\n:::{.callout-important}\n\n## Rejection sampling algorithm\n\n1. Generate $X$ from proposal with density $q(x)$.\n2. Compute the ratio $R \\gets p(X)/ q(X)$.\n3. If $R \\leq CU$ for $U \\sim \\mathsf{U}(0,1)$, return $X$, else go back to step 1.\n\n:::\n\n## Remarks on rejection sampling\n\n- Acceptance rate is $1/C$\n   - we need on average $C$ draws from $q$ to get one from $p$\n- $q$ must be more heavy-tailed than $p$\n   - e.g., $q(x)$ Student-$t$ for $p(x)$ Gaussian\n- $q$ should be cheap and easy to sample from!\n\n## Designing a good proposal density\n\nGood choices must satisfy the following constraints: \n\n- pick a family $q(x)$ so that $$C = \\mathrm{sup}_x \\frac{p(x)}{q(x)}$$ is as close to 1 as possible.\n- you can use numerical optimization with $f(x) =\\log p(x) - \\log q(x)$ to find the mode $x^\\star$ and the upper bound $C = \\exp f(x^\\star)$.\n\n## Example of accept-reject (1)\n\nConsider sampling $Y \\sim \\mathsf{No}(\\mu, \\sigma^2)$, but truncated in the interval $(a, b)$. The target density is\n\\begin{align*}\np(x; \\mu, \\sigma, a, b) = \\frac{1}{\\sigma}\\frac{\\phi\\left(\\frac{x-\\mu}{\\sigma}\\right)}{\\Phi(\\beta)-\\Phi(\\alpha)}.\n\\end{align*}\nfor $\\alpha= (a-\\mu)/\\sigma$ and $\\beta = (b-\\mu)/\\sigma$.\nwhere $\\phi(\\cdot), \\Phi(\\cdot)$ are respectively the density and distribution function of the standard Gaussian distribution.\n\n## Accept-reject (crude version)\n\n1. Simulate $X \\sim \\mathsf{No}(\\mu, \\sigma^2)$\n2. reject any draw if $X < a$ or $X> b$. \n\nThe acceptance rate is $C^{-1} = \\{\\Phi(\\beta) - \\Phi(\\alpha)\\}$\n\n\n::: {.cell hash='bayesmod-slides3_cache/revealjs/unnamed-chunk-3_ee2bc9c758d6fac57e82bb7716031bac'}\n\n```{.r .cell-code}\n# Standard Gaussian truncated on [0,1]\ncandidate <- rnorm(1e5)\ntrunc_samp <- candidate[candidate >= 0 & candidate <= 1]\n# Acceptance rate\nlength(trunc_samp)/1e5\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.34242\n```\n:::\n\n```{.r .cell-code}\n# Theoretical acceptance rate\npnorm(1)-pnorm(0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3413447\n```\n:::\n:::\n\n\n## Accept-reject for truncated Gaussian  {.smaller}\n\nSince the Gaussian is a location scale family, the inversion method gives\n\\begin{align*}\nX \\sim \\mu + \\sigma\\Phi^{-1}\\left[\\Phi(\\alpha) + \\{\\Phi(\\beta)-\\Phi(\\alpha)\\}U\\right]\n\\end{align*}\n\nWe however need to evaluate $\\Phi$ numerically (no closed-form expression).\n\nThe method fails for *rare event* simulation because the computer returns\n\n- $\\Phi(x) = 0$ for $x \\leq -39$\n- $\\Phi(x)=1$ for $x \\geq 8.3$,\n\nimplying that $a \\leq 8.3$ for this approach to work [@LEcuyer.Botev:2017].\n\n## Simulating tails of Gaussian variables {.smaller}\n\nWe consider simulation from a standard Gaussian truncated above $a>0$ [@Devroye:1986, p.381].\n\nWrite the density of the truncated Gaussian as $$f(x) = \\frac{\\exp(-x^2/2)}{\\int_{a}^{\\infty}\\exp(-z^2/2)\\mathrm{d} z}  =\\frac{\\exp(-x^2/2)}{c_1}.$$\n\nNote that, for $x \\geq a$, \n$$c_1f(x) \\leq \\frac{x}{a}\\exp\\left(-\\frac{x^2}{2}\\right)= a^{-1}\\exp\\left(-\\frac{a^2}{2}\\right)g(x);$$\nwhere $g(x)$ is the density of a Rayleigh variable shifted by $a$.^[The constant $C= \\exp(-a^2/2)(c_1a)^{-1}$ approaches 1 quickly as $a \\to \\infty$ (asymptotically optimality). ]\n\n## Accept-reject: truncated Gaussian with Rayleigh  {.smaller}\n\nThe shifted Rayleigh has distribution function $$G(x) = 1-\\exp\\{(a^2-x^2)/2\\}, x \\geq a.$$ \n\n\n\n\n:::{.callout-important}\n\n## Marsaglia algorithm\n1. Generate a shifted Rayleigh  above $a$, $X \\gets  \\{a^2 - 2\\log(U)\\}^{1/2}$ for $U \\sim \\mathsf{U}(0,1)$\n2. Accept $X$ if $XV \\leq a$, where $V \\sim \\mathsf{U}(0,1)$.\n:::\n\nFor sampling on $[a,b]$, propose from a Rayleigh truncated above at $b$ [@LEcuyer.Botev:2017].\n\n\n::: {.cell hash='bayesmod-slides3_cache/revealjs/marsaglia-algo_56f11c194038fbe5108d867343a91982'}\n\n```{.r .cell-code}\na <- 8.3\nniter <- 1000L\nX <- sqrt(a^2 + 2*rexp(niter))\nsamp <- X[runif(niter)*X <= a]\n```\n:::\n\n\n\n## Markov chains\n\nPlain ordinary Monte Carlo is great, but few algorithms are generic enough to be useful in complex high-dimensional problems.\n\nWe will instead typically build Markov chains that target an invariant stationary distribution. \n\n\n## Caveats?\n\nMarkov chain Monte Carlo methods generate **correlated** draws. \n\n**Questions**: \n\n1. can we use them as ordinary independent samples? \n2. what is the price to pay?\n\nWe need to do a little theoretical detour to answer these questions.\n\n## Stationarity and Markov property\n\n\nA stochastic process is **(weakly) stationary** if \n\n- the distribution of $\\{X_1, \\ldots, X_t\\}$ is the same as that of $\\{X_{n+1}, \\ldots X_{t+n}\\}$ for any value of $n$ and given $t$.\n\nA stochastic process is **Markov** if \n\n- it satisfies the Markov property: given the current state of the chain, the future only depends on the current state and not on the past.\n\n## Autoregressive process of order 1\n\nConsider a first-order autoregressive process, or $\\mathsf{AR}(1)$, \n\n$$Y_t = \\mu + \\phi(Y_{t-1} - \\mu) + \\varepsilon_t,$$ where \n\n- $\\phi$ is the lag-one correlation, \n- $\\mu$ the global mean\n- $\\varepsilon_t$ is an iid innovation with mean zero and variance $\\sigma^2$\n\nIf $|\\phi| < 1$, the process is stationary, otherwise variance increases with $t$\n\n## Variance of a stationary distribution\n\nFor a correlated sequence, the variance of the stationary distribution is \\begin{align*}\n\\tau^2 = \\mathsf{Va}(Y_t) + 2 \\sum_{k=1}^\\infty \\mathsf{Co}(Y_t, Y_{t-k}).\n\\end{align*}\n\n - for i.i.d. data, $\\tau^2 = \\mathsf{Va}(Y_t)$\n - for stationary $\\mathsf{AR}(1)$ process, we get $\\sigma^2/(1-\\phi^2)$ (geometric series)\n\n## Variance of sample average\n\nIntuitively, a sample of correlated observations carries less information than an independent sample of draws.\n\nWe want the variance of the sample average, which is\n\\begin{align*}\n\\mathsf{Va}\\left(\\overline{Y}_T\\right) = \\frac{1}{T}\\sum_{t=1}^T \\mathsf{Va}(Y_t) + \\frac{2}{T} \\sum_{t=1}^{T-1}\\sum_{s = t+1}^T \\mathsf{Co}(Y_t, Y_s).\n\\end{align*}\n\nIf the process is stationary, the covariances at lag $k$ are the same regardless of the time index and the unconditional variance is constant.\n\n## Variance of sample average, redux\n\nIf a central limit theorem applies, the limiting variance of the sample mean is \n\\begin{align*}\n\\lim_{T \\to \\infty} T\\mathsf{Va}\\left(\\overline{Y}_T\\right) = \\tau^2 \\left\\{1+2\\sum_{t=1}^\\infty \\gamma_t\\right\\}.\n\\end{align*}\nwhich is a function of \n\n- the unconditional variance $\\tau^2$\n- the lag-$k$ autocorrelation $\\mathsf{Cor}(Y_{t}, Y_{t+k})=\\gamma_k$\n\n## Variance of sample mean of AR(1)\n\nThe lag-$k$ correlation of the stationary autoregressive process of order 1 is $\\phi^k$, so $$T\\mathsf{Va}\\left(\\overline{Y}_T\\right)=\\sigma^2(1+\\phi)/(1-\\phi).$$\n\nFor an independent sample, we have $$T\\mathsf{Va}\\left(\\overline{Y}_T\\right)=\\sigma^2/(1-\\phi^2).$$ \n\n## Morale of the story {.center}\n\nThe price to pay for having correlated samples is \n\n:::{style=\"font-size: 2em; color: #ff585d; text-align: center\"}\n\n**inefficiency**\n\n:::\n\nThe higher the autocorrelation, the larger the variability of our estimators.\n\n\n\n## Inefficiency curve {.smaller}\n\n\n::: {.cell hash='bayesmod-slides3_cache/revealjs/fig-ar1-variance_04ea1f281d2a571d7e15ac7ce99b46c7'}\n::: {.cell-output-display}\n![Scaled asymptotic variance of the sample mean for AR(1) (dashed) and independent observations with the same marginal variance (full line). The plot on the right gives the variance ratio for positive correlations.](bayesmod-slides3_files/figure-revealjs/fig-ar1-variance-1.png){#fig-ar1-variance width=768}\n:::\n:::\n\n\n\nTo get the same precision for the mean of $\\mathsf{AR}(1)$ process with $\\phi \\approx 0.75$ than with i.i.d. data, we would need 9 times as many observations.\n\n\n## When can we use Markov chains?\n\nIf a Markov chain is irreducible and aperiodic, it has a unique stationary distribution.\n\n- irreducibility: means that the chain can move from anywhere to anywhere, so it doesn't get stuck in part of the space forever.\n- acyclic: cyclical chains loop around and visit periodically a state\n\nErgodic theorem is our guarantee of convergence.\n\n## Examples\n\nConsider discrete Markov chains over the integers $1, 2, 3$ with transition matrices\n\n$$\nP_1 = \\begin{pmatrix}\n0.5 & 0.3 & 0.2 \\\\\n0 & 0.4 & 0.6 \\\\\n0 & 0.5 & 0.5\n\\end{pmatrix}, \n\\quad \nP_2 = \\begin{pmatrix}\n0 & 0 & 1 \\\\\n1 & 0 & 0 \\\\\n0 & 1 & 0\n\\end{pmatrix}.\n$$\nChain 1 is reducible to $\\{2, 3\\}$, chain 2 is cyclical.\n\n## Convergence of Markov chains\n\n\n\n::: {.cell hash='bayesmod-slides3_cache/revealjs/fig-discrete-markov-chain_d2c689bb73b20371bdabeeb1c602f5e1'}\n::: {.cell-output-display}\n![Discrete Markov chain on integers from 1 to 5, with traceplot of 1000 first iterations (left) and running mean plots of sample proportion of each state visited (right).](bayesmod-slides3_files/figure-revealjs/fig-discrete-markov-chain-1.png){#fig-discrete-markov-chain width=960}\n:::\n:::\n\n\n## Markov chain Monte Carlo\n\nWe consider simulating from a distribution with associated density function $\\propto p(\\boldsymbol{\\theta})$.\n\n- known up to a normalizing factor not depending on $\\boldsymbol{\\theta}$.\n\nWe use $q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}^*)$ as transition kernel to generate proposals.\n\n\n## Metropolis--Hastings algorithm \n\nStarting from an initial value $\\boldsymbol{\\theta}_0$:\n\n1.  draw a proposal value $\\boldsymbol{\\theta}_t^{\\star} \\sim q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}_{t-1})$.\n2.  Compute the acceptance ratio $$\n    R = \\frac{p(\\boldsymbol{\\theta}_t^{\\star})}{p(\\boldsymbol{\\theta}_{t-1})}\\frac{q(\\boldsymbol{\\theta}_{t-1} \\mid \\boldsymbol{\\theta}_t^{\\star} )}{q(\\boldsymbol{\\theta}_t^{\\star} \\mid \\boldsymbol{\\theta}_{t-1})}\n    $$\n3.  With probability $\\max\\{R, 1\\}$, accept the proposal and set $\\boldsymbol{\\theta}_t \\gets \\boldsymbol{\\theta}_t^{\\star}$, otherwise set the value to the previous state, $\\boldsymbol{\\theta}_t \\gets \\boldsymbol{\\theta}_{t-1}$.\n\n## Interpretation\n\n- If $R>1$, the proposal has higher density and we always accept the move. If the ratio is less than one, the proposal is in a lower probability region.\n- If we reject the move, the Markov chain stays at the current value, which induces autocorrelation.\n- Since the acceptance probability depends only on the density through ratios, we can work with unnormalized density functions.\n\n\n## References\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}