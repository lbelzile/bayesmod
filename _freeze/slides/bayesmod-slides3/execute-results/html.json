{
  "hash": "54e64b3d1423f99cb6b2b9784c8fbf27",
  "result": {
    "markdown": "---\ntitle: \"Bayesian modelling\"\nauthor: \"LÃ©o Belzile\"\nsubtitle: \"Simulation-based inference\"\ndate: today\ndate-format: YYYY\neval: true\necho: true\ncache: true\nbibliography: MATH80601A.bib\nformat:\n  revealjs:\n    slide-number: true\n    preview-links: auto\n    theme: [simple, hecmontreal.scss]\n    title-slide-attributes:\n      data-background-color: \"#ff585d\"\n    logo: \"fig/logo_hec_montreal_bleu_web.png\"\n---\n\n```{include=FALSE}\n\nhecbleu <- c(\"#002855\")\nfcols <- c(gris = \"#888b8d\",\n           bleu = \"#0072ce\",\n           aqua = \"#00aec7\",\n           vert = \"#26d07c\",\n           rouge = \"#ff585d\",\n           rose = \"#eb6fbd\",\n           jaune = \"#f3d03e\")\npcols <- c(gris = \"#d9d9d6\",\n           bleu = \"#92c1e9\",\n           agua = \"#88dbdf\",\n           vert = \"#8fe2b0\",\n           rouge = \"#ffb1bb\",\n           rose = \"#eab8e4\",\n           jaune = \"#f2f0a1\")\nlibrary(ggplot2)\ntheme_set(theme_classic())\nlibrary(patchwork)\nknitr::opts_chunk$set(fig.retina = 3, collapse = TRUE)\noptions(digits = 3, width = 75)\n```\n\n\n## Bayesian inference beyond conjugate models\n\nHow to circumvent the problem of intractable posteriors?\n\n- simulation-based methods: accept-reject, Markov chain Monte Carlo, particle filters, etc.\n- deterministic methods: (integrated nested) Laplace approximations, variational Bayes, expectation propagation, etc.\n\nWe focus on the Monte Carlo methods in the sequel.\n\n## Objective of methods\n\nSuppose we can simulate $B$ i.i.d. variables with the same distribution, $X_b \\sim F$ $(b=1, \\ldots, B).$\n\nWe want to compute $\\mathsf{E}\\{g(X)\\}=\\mu_g$ for some functional $g(\\cdot)$\n\n- $g(x)=x$ (posterior mean)\n- $g(x) = \\mathsf{I}(x \\in A)$ (probability of event)\n- etc.\n\n## Monte Carlo methods\n\nWe substitute expected value by sample average \n$$\\widehat{\\mu}_g = \\frac{1}{B} \\sum_{b=1}^B g(X_b), \\qquad X_b \\sim F$$\n\n- law of large number guarantees convergence of $\\widehat{\\mu}_g \\to \\mu_g$ if the latter is finite.\n- central limit theorem applies: $$\\sqrt{B}(\\widehat{\\mu}_g - \\mu_g) \\sim \\mathsf{No}(0, \\sigma^2_g).$$\n\n\n## Ordinary Monte Carlo\n\nWe want to have an estimator as precise as possible.\n\n- but we can't control the variance of $g(X)$, say $\\sigma_g^2$\n- the more simulations $B$, the lower the variance of the mean. \n- sample average for i.i.d. data has variance $\\sigma^2_g/B$\n- to reduce the standard deviation by a factor 10, we need $100$ times more draws!\n\n\nRemember: the answer is **random**.\n\n## Example: functionals of gamma distribution\n\n\n::: {.cell hash='bayesmod-slides3_cache/revealjs/fig-monte-carlo-path_beb78cbaecb0a399d989100d6cf65bb7'}\n::: {.cell-output-display}\n![Running mean trace plots for $g(x)=\\mathrm{I}(x<1)$ (left), $g(x)=x$ (middle) and $g(x)=1/x$ (right) for a Gamma distribution with shape 0.5 and rate 2, as a function of the Monte Carlo sample size.](bayesmod-slides3_files/figure-revealjs/fig-monte-carlo-path-1.png){#fig-monte-carlo-path width=960}\n:::\n:::\n\n\n## Simulation algorithms: inversion method\n\nIf $F$ is an absolutely continuous distribution function, then \n$$F(X) \\sim \\mathsf{U}(0,1).$$\nThe inversion method consists in applying the quantile function $F^{-1}$ to $U \\sim \\mathsf{U}(0,1)$, viz. $$F^{-1}(U) \\sim X.$$\n\n## Inversion method for truncated distributions\n\nConsider a random variable $Y$ with distribution function $F$.\n\nIf $X$ follows the same distribution as $Y$, but restricted over the interval $[a,b]$, then \n$$\\Pr(X \\leq x) = \\frac{F(x) - F(a)}{F(b)-F(a)}, \\qquad a \\leq x \\leq b,$$\n\nTherefore, $$F^{-1}[F(a) + \\{F(b)-F(a)\\}U] \\sim X$$\n\n\n\n## Simulation algorithms: accept-reject\n\n- **Target**: sample from density $p(x)$ (hard to sample from)\n- **Proposal**: find a density $q(x)$ with nested support, $\\mathrm{supp}(p) \\subseteq \\mathrm{supp}(q)$, such that \n$$\\frac{p(x)}{q(x)} \\leq C, \\quad C \\geq 1.$$\n\n## Rejection sampling algorithm\n\n1. Generate $X$ from proposal with density $q(x)$.\n2. Compute the ratio $R \\gets p(X)/ q(X)$.\n3. If $CU \\leq R$ for $U \\sim \\mathsf{U}(0,1)$, return $X$, else go back to step 1.\n\n\n## Remarks on rejection sampling\n\n- Acceptance rate is $1/C$\n   - we need on average $C$ draws from $q$ to get one from $p$\n- $q$ must be more heavy-tailed than $p$\n   - e.g., $q(x)$ Student-$t$ for $p(x)$ Gaussian\n- $q$ should be cheap and easy to sample from!\n\n## Designing a good proposal density\n\nGood choices must satisfy the following constraints: \n\n- pick a family $q(x)$ so that $$C = \\mathrm{sup}_x \\frac{p(x)}{q(x)}$$ is as close to 1 as possible.\n- you can use numerical optimization with $f(x) =\\log p(x) - \\log q(x)$ to find the mode $x^\\star$ and the upper bound $C = \\exp f(x^\\star)$.\n\n## Example of accept-reject (1)\n\nConsider sampling $Y \\sim \\mathsf{No}(\\mu, \\sigma^2)$, but truncated in the interval $(a, b)$. The target density is\n\\begin{align*}\np(x; \\mu, \\sigma, a, b) = \\frac{1}{\\sigma}\\frac{\\phi\\left(\\frac{x-\\mu}{\\sigma}\\right)}{\\Phi(\\beta)-\\Phi(\\alpha)}.\n\\end{align*}\nfor $\\alpha= (a-\\mu)/\\sigma$ and $\\beta = (b-\\mu)/\\sigma$.\nwhere $\\phi(\\cdot), \\Phi(\\cdot)$ are respectively the density and distribution function of the standard Gaussian distribution.\n\n## Accept-reject (crude version)\n\n1. Simulate $X \\sim \\mathsf{No}(\\mu, \\sigma^2)$\n2. reject any draw if $X < a$ or $X> b$. \n\nThe acceptance rate is $C^{-1} = \\{\\Phi(\\beta) - \\Phi(\\alpha)\\}$\n\n\n::: {.cell hash='bayesmod-slides3_cache/revealjs/unnamed-chunk-2_d571ef37cc3664bf57c42bb223ddfcf8'}\n\n```{.r .cell-code}\n# Standard Gaussian truncated on [0,1]\ncandidate <- rnorm(1e5)\ntrunc_samp <- candidate[candidate >= 0 & candidate <= 1]\n# Acceptance rate\nlength(trunc_samp)/1e5\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.34242\n```\n:::\n\n```{.r .cell-code}\n# Theoretical acceptance rate\npnorm(1)-pnorm(0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3413447\n```\n:::\n:::\n\n\n## Accept-reject for truncated Gaussian  {.smaller}\n\nSince the Gaussian is a location scale family, the inversion method gives\n\\begin{align*}\nX \\sim \\mu + \\sigma\\Phi^{-1}\\left[\\Phi(\\alpha) + \\{\\Phi(\\beta)-\\Phi(\\alpha)\\}U\\right]\n\\end{align*}\n\nWe however need to evaluate $\\Phi$ numerically (no closed-form expression).\n\nThe method fails for *rare event* simulation because the computer returns\n\n- $\\Phi(x) = 0$ for $x \\leq -39$\n- $\\Phi(x)=1$ for $x \\geq 8.3$,\n\nimplying that $a \\leq 8.3$ for this approach to work [@LEcuyer.Botev:2017].\n\n## Simulating tails of Gaussian variables {.smaller}\n\nWe consider simulation from a standard Gaussian truncated above $a>0$ [@Devroye:1986, p.381].\n\nWrite the density of the truncated Gaussian as $$f(x) = \\frac{\\exp(-x^2/2)}{\\int_{a}^{\\infty}\\exp(-z^2/2)\\mathrm{d} z}  =\\frac{\\exp(-x^2/2)}{c_1}.$$\n\nNote that, for $x \\geq a$, \n$$c_1f(x) \\leq \\frac{x}{a}\\exp\\left(-\\frac{x^2}{2}\\right)= a^{-1}\\exp\\left(-\\frac{a^2}{2}\\right)g(x);$$\nwhere $g(x)$ is the density of a Rayleigh variable shifted by $a$.^[The constant $C= \\exp(-a^2/2)(c_1a)^{-1}$ approaches 1 quickly as $a \\to \\infty$ (asymptotically optimality). ]\n\n## Accept-reject: truncated Gaussian with Rayleigh  {.smaller}\n\nThe shifted Rayleigh has distribution function $$G(x) = 1-\\exp\\{(a^2-x^2)/2\\}, x \\geq a.$$ \n\n\n\n\n:::{.callout-important}\n\n## Marsaglia algorithm\n1. Generate a shifted Rayleigh  above $a$, $X \\gets  \\{a^2 - 2\\log(U)\\}^{1/2}$ for $U \\sim \\mathsf{U}(0,1)$\n2. Accept $X$ if $XV \\leq a$, where $V \\sim \\mathsf{U}(0,1)$.\n:::\n\nFor sampling on $[a,b]$, propose from a Rayleigh truncated above at $b$ [@LEcuyer.Botev:2017].\n\n\n::: {.cell hash='bayesmod-slides3_cache/revealjs/marsaglia-algo_56f11c194038fbe5108d867343a91982'}\n\n```{.r .cell-code}\na <- 8.3\nniter <- 1000L\nX <- sqrt(a^2 + 2*rexp(niter))\nsamp <- X[runif(niter)*X <= a]\n```\n:::\n\n\n\n## Markov chains\n\nPlain ordinary Monte Carlo is great, but few algorithms are generic enough to be useful in complex high-dimensional problems.\n\nWe will instead typically build Markov chains that target an invariant stationary distribution. \n\n\n## Caveats?\n\nMarkov chain Monte Carlo methods generate **correlated** draws. \n\n**Questions**: \n\n1. can we use them as ordinary independent samples? \n2. what is the price to pay?\n\nWe need to do a little theoretical detour to answer these questions.\n\n## Stationarity and Markov property\n\n\nA stochastic process is **(weakly) stationary** if \n\n- the distribution of $\\{X_1, \\ldots, X_t\\}$ is the same as that of $\\{X_{n+1}, \\ldots X_{t+n}\\}$ for any value of $n$ and given $t$.\n\nA stochastic process is **Markov** if \n\n- it satisfies the Markov property: given the current state of the chain, the future only depends on the current state and not on the past.\n\n## Autoregressive process of order 1\n\nConsider a first-order autoregressive process, or $\\mathsf{AR}(1)$, \n\n$$Y_t = \\mu + \\phi(Y_{t-1} - \\mu) + \\varepsilon_t,$$ where \n\n- $\\phi$ is the lag-one correlation, \n- $\\mu$ the global mean\n- $\\varepsilon_t$ is an iid innovation with mean zero and variance $\\sigma^2$\n\nIf $|\\phi| < 1$, the process is stationary, otherwise variance increases with $t$\n\n## Variance of a stationary distribution\n\nFor a correlated sequence, the variance of the stationary distribution is \\begin{align*}\n\\tau^2 = \\mathsf{Va}(Y_t) + 2 \\sum_{k=1}^\\infty \\mathsf{Co}(Y_t, Y_{t-k}).\n\\end{align*}\n\n - for i.i.d. data, $\\tau^2 = \\mathsf{Va}(Y_t)$\n - for stationary $\\mathsf{AR}(1)$ process, we get $\\sigma^2/(1-\\phi^2)$ (geometric series)\n\n## Variance of sample average\n\nIntuitively, a sample of correlated observations carries less information than an independent sample of draws.\n\nWe want the variance of the sample average, which is\n\\begin{align*}\n\\mathsf{Va}\\left(\\overline{Y}_T\\right) = \\frac{1}{T}\\sum_{t=1}^T \\mathsf{Va}(Y_t) + \\frac{2}{T} \\sum_{t=1}^{T-1}\\sum_{s = t+1}^T \\mathsf{Co}(Y_t, Y_s).\n\\end{align*}\n\nIf the process is stationary, the covariances at lag $k$ are the same regardless of the time index and the unconditional variance is constant.\n\n## Variance of sample average, redux\n\nIf a central limit theorem applies, the limiting variance of the sample mean simplifies to\n\\begin{align*}\n\\lim_{T \\to \\infty} T\\mathsf{Va}\\left(\\overline{Y}_T\\right) = \\tau^2 \\left\\{1+2\\sum_{t=1}^\\infty \\gamma_t\\right\\}.\n\\end{align*}\nwhich is a function of \n\n- the unconditional variance $\\tau^2$\n- the lag-$k$ autocorrelation $\\mathsf{Cor}(Y_{t}, Y_{t+k})=\\gamma_k$\n\n## Correlogram\n\n\n\n::: {.cell hash='bayesmod-slides3_cache/revealjs/fig-correlograms_41af73f56a6f54b6efcef14d8fd9865c'}\n::: {.cell-output-display}\n![Correlogram of two two Markov chains. These plots, often called acf or autocorrelation functions, show the lag-k sample autocorrelation against lag number.](bayesmod-slides3_files/figure-revealjs/fig-correlograms-1.png){#fig-correlograms width=960}\n:::\n:::\n\n\n## Variance of sample mean of AR(1)\n\nThe lag-$k$ correlation of the stationary autoregressive process of order 1 is $\\phi^k$, so $$T\\mathsf{Va}\\left(\\overline{Y}_T\\right)=\\sigma^2(1+\\phi)/(1-\\phi).$$\n\nFor an independent sample, we have $$T\\mathsf{Va}\\left(\\overline{Y}_T\\right)=\\sigma^2/(1-\\phi^2).$$ \n\n\n\n\n## Inefficiency curve {.smaller}\n\n\n::: {.cell hash='bayesmod-slides3_cache/revealjs/fig-ar1-variance_04ea1f281d2a571d7e15ac7ce99b46c7'}\n::: {.cell-output-display}\n![Scaled asymptotic variance of the sample mean for AR(1) (dashed) and independent observations with the same marginal variance (full line). The plot on the right gives the variance ratio for positive correlations.](bayesmod-slides3_files/figure-revealjs/fig-ar1-variance-1.png){#fig-ar1-variance width=768}\n:::\n:::\n\n\n\nTo get the same precision for the mean of $\\mathsf{AR}(1)$ process with $\\phi \\approx 0.75$ than with i.i.d. data, we would need 9 times as many observations.\n\n## Morale of the story {.center}\n\nThe price to pay for having correlated samples is \n\n:::{style=\"font-size: 2em; color: #ff585d; text-align: center\"}\n\n**inefficiency**\n\n:::\n\nThe higher the autocorrelation, the larger the variability of our estimators.\n\n## When can we use Markov chains?\n\nIf a Markov chain is irreducible and acyclic, it has a unique stationary distribution.\n\n- irreducibility: means that the chain can move from anywhere to anywhere, so it doesn't get stuck in part of the space forever.\n- acyclic: cyclical chains loop around and visit periodically a state\n\nErgodic theorem is our guarantee of convergence.\n\n## Examples\n\nConsider discrete Markov chains over the integers $1, 2, 3$ with transition matrices\n\n$$\nP_1 = \\begin{pmatrix}\n0.5 & 0.3 & 0.2 \\\\\n0 & 0.4 & 0.6 \\\\\n0 & 0.5 & 0.5\n\\end{pmatrix}, \n\\quad \nP_2 = \\begin{pmatrix}\n0 & 0 & 1 \\\\\n1 & 0 & 0 \\\\\n0 & 1 & 0\n\\end{pmatrix}.\n$$\nChain 1 is reducible to $\\{2, 3\\}$, chain 2 is cyclical.\n\n## Convergence of Markov chains\n\n\n\n::: {.cell hash='bayesmod-slides3_cache/revealjs/fig-discrete-markov-chain_d2c689bb73b20371bdabeeb1c602f5e1'}\n::: {.cell-output-display}\n![Discrete Markov chain on integers from 1 to 5, with traceplot of 1000 first iterations (left) and running mean plots of sample proportion of each state visited (right).](bayesmod-slides3_files/figure-revealjs/fig-discrete-markov-chain-1.png){#fig-discrete-markov-chain width=960}\n:::\n:::\n\n\n## Markov chain Monte Carlo\n\nWe consider simulating from a distribution with associated density function $\\propto p(\\boldsymbol{\\theta})$.\n\n- known up to a normalizing factor not depending on $\\boldsymbol{\\theta}$.\n\nWe use $q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}^*)$ as transition kernel to generate proposals.\n\n\n## Metropolis--Hastings algorithm \n\nStarting from an initial value $\\boldsymbol{\\theta}_0$:\n\n1.  draw a proposal value $\\boldsymbol{\\theta}_t^{\\star} \\sim q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}_{t-1})$.\n2.  Compute the acceptance ratio $$\n    R = \\frac{p(\\boldsymbol{\\theta}_t^{\\star})}{p(\\boldsymbol{\\theta}_{t-1})}\\frac{q(\\boldsymbol{\\theta}_{t-1} \\mid \\boldsymbol{\\theta}_t^{\\star} )}{q(\\boldsymbol{\\theta}_t^{\\star} \\mid \\boldsymbol{\\theta}_{t-1})}\n    $$\n3.  With probability $\\min\\{R, 1\\}$, accept the proposal and set $\\boldsymbol{\\theta}_t \\gets \\boldsymbol{\\theta}_t^{\\star}$, otherwise set the value to the previous state, $\\boldsymbol{\\theta}_t \\gets \\boldsymbol{\\theta}_{t-1}$.\n\n## Interpretation\n\n- If $R>1$, the proposal has higher density and we always accept the move. \n- If we reject the move, the Markov chain stays at the current value, which induces autocorrelation.\n- Since the acceptance probability depends only on the density through ratios, normalizing factors of $p$ and $q$ cancel out.\n\n\n## Symmetric proposals and random walk\n\nIf the proposal is symmetric, the ratio of proposal densities is $$q(\\boldsymbol{\\theta}_{t-1} \\mid \\boldsymbol{\\theta}_t^{\\star} ) / q(\\boldsymbol{\\theta}_t^{\\star} \\mid \\boldsymbol{\\theta}_{t-1}) = 1.$$\n\nCommon examples include random walk proposals\n$$\\boldsymbol{\\theta}_t^{\\star} \\gets \\boldsymbol{\\theta}_{t-1} + \\tau Z, \\qquad Z$$ where $Z$ is a mean zero, variance one random variable.\n\n## Independent proposals\n\n- If we pick instead a global proposal, we must ensure that $q$ samples in far regions (recall rejection sampling), otherwise ...\n- Good proposals include heavy tailed distribution such as Student-$t$ with small degrees of freedom, centered at the maximum a posteriori $\\widehat{\\boldsymbol{\\theta}}$ and with scale matrix $-\\mathbf{H}^{-1}(\\boldsymbol{\\theta}_t^{\\star})$, where $\\mathbf{H}(\\cdot)$ is the Hessian of the log posterior.\n\n\n## Upworthy data example\n\nWe model the Poisson rates for headlines with questions or not. Our model is\n\\begin{align*}\nY_{i} &\\sim \\mathsf{Po}(n_i\\lambda_i), \\qquad (i=1,2)\\\\\n\\lambda_1 &= \\exp(\\beta + \\kappa) \\\\\n\\lambda_2 &= \\exp(\\beta) \\\\\n\\beta & \\sim \\mathsf{No}(\\log 0.01, 1.5) \\\\\n\\kappa &\\sim \\mathsf{No}(0, 1)\n\\end{align*}\n\n## Implementation details: data and containers\n\nIn regression models, scale inputs if possible.\n\n\n::: {.cell hash='bayesmod-slides3_cache/revealjs/unnamed-chunk-7_e3a1875dad41d1a5ddb1cf30eb6b99d3'}\n\n```{.r .cell-code}\ndata(upworthy_question, package = \"hecbayes\")\n# Compute sufficient statistics\ndata <- upworthy_question |>\n  dplyr::group_by(question) |>\n  dplyr::summarize(ntot = sum(impressions),\n                   y = sum(clicks))\n# Create containers for MCMC\nniter <- 1e4L\nchain <- matrix(0, nrow = niter, ncol = 2L)\ncolnames(chain) <- c(\"beta\",\"kappa\")\n```\n:::\n\n\n\n## Implementation details: log posterior function\n\nPerform all calculations on the log scale to avoid numerical overflow! \n\n\n::: {.cell hash='bayesmod-slides3_cache/revealjs/unnamed-chunk-8_122383fef665c79710684b7a9ac1d3a7'}\n\n```{.r .cell-code}\n# Code log posterior as sum of log likelihood and log prior\nloglik <- function(par, counts = data$y, offset = data$ntot, ...){\n  lambda <- exp(c(par[1] + log(offset[1]), par[1] + par[2] + log(offset[2])))\n sum(dpois(x = counts, lambda = lambda, log = TRUE))\n}\n# Note common signature of function\nlogprior <- function(par, ...){\n  dnorm(x = par[1], mean = log(0.01), sd = 1.5, log = TRUE) +\n    dnorm(x = par[2], log = TRUE)\n}\nlogpost <- function(par, ...){\n  loglik(par, ...) + logprior(par, ...)\n}\n```\n:::\n\n\n## Implementation details: proposal variance and starting values.\n\nUse good starting values for your Markov chains, such as maximum a posteriori.\n\n\n::: {.cell hash='bayesmod-slides3_cache/revealjs/unnamed-chunk-9_8dfed4c93da45e3aa34135e516d4bc0a'}\n\n```{.r .cell-code}\n# Compute maximum a posteriori (MAP)\nmap <- optim(\n  par = c(-4, 0.07),\n  fn = logpost,\n  control = list(fnscale = -1),\n  offset = data$ntot,\n  counts = data$y,\n  hessian = TRUE)\n# Use MAP as starting value\ncur <- map$par\n# Compute logpost_cur - we can keep track of this to reduce calculations\nlogpost_cur <- logpost(cur)\n# Proposal covariance\ncov_map <- -2*solve(map$hessian)\nchol <- chol(cov_map)\n```\n:::\n\n\n## Implementation details: Metropolis--Hastings algorithm\n\nUse seed for reproducibility, do not compute posterior twice, compute log of acceptance ratio. \n\n\n::: {.cell hash='bayesmod-slides3_cache/revealjs/unnamed-chunk-10_15ead21e1a68f3ea27edb96bfb1f07ad'}\n\n```{.r .cell-code}\nset.seed(80601)\nnaccept <- 0L\nfor(i in seq_len(niter)){\n  # Multivariate normal proposal - symmetric random walk\n  prop <- c(rnorm(n = 2) %*% chol + cur)\n  logpost_prop <- logpost(prop)\n  logR <- logpost_prop - logpost_cur\n  if(logR > -rexp(1)){\n    cur <- prop\n    logpost_cur <- logpost_prop\n    naccept <- naccept + 1L\n  }\n  chain[i,] <- cur\n}\n```\n:::\n\n\n## Implementation details: analysis of output\n\nNeed specialized methods to compute standard errors of the posterior mean.\n\n\n::: {.cell hash='bayesmod-slides3_cache/revealjs/unnamed-chunk-11_47ae026f6deb946ef5e39b0ddaff3534'}\n\n```{.r .cell-code}\n# Posterior summaries\nsummary(coda::as.mcmc(chain))\n# Computing standard errors using batch means\nsqrt(diag(mcmc::olbm(chain, batch.length = niter/40)))\n```\n:::\n\n\n```\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean       SD  Naive SE Time-series SE\nbeta  -4.51268 0.001697 1.697e-05      6.176e-05\nkappa  0.07075 0.002033 2.033e-05      9.741e-05\n\n2. Quantiles for each variable:\n\n          2.5%      25%      50%      75%    97.5%\nbeta  -4.51591 -4.51385 -4.51273 -4.51154 -4.50929\nkappa  0.06673  0.06933  0.07077  0.07212  0.07463\n```\n\n## Standard errors of posterior mean\n\nA method recommended by @Geyer:2011 consists in running a long chain and\n\n1. Break the chain of length $B$ in $K$ blocks of size $\\approx K/B$.\n2. Compute the sample mean of each segment. These values form a Markov chain and should be approximately uncorrelated.\n3. Compute the standard deviation of the segments mean. Rescale by $K^{-1/2}$ to get standard error of global chain mean.\n\n\n\n## Pro tips: initial values\n\nBatch means only works if the chain is sampling from the stationary distribution! \n\nThe previous result (and any estimate) will be unreliable and biased if the chain is not sampling from the posterior.\n\nThis happens often with poor starting value. We are guaranteed to reach stationarity, but this may take more time than the number of steps $B$ we fixed.\n\nOne can discard initial draws during a **burn in** or warmup period, but you better use good starting value.\n\n## Visual diagnostic: trace plots\n\nDisplay the Markov chain sample path as a function of the number of iterations.\n\n\n\n\n::: {.cell hash='bayesmod-slides3_cache/revealjs/fig-badstart_725f86fd084f04370a0acf46639f8a5a'}\n::: {.cell-output-display}\n![Traceplots of three Markov chains for the same target with different initial values for the first 500 iterations (left) and trace rank plot after discarding these (right).](bayesmod-slides3_files/figure-revealjs/fig-badstart-1.png){#fig-badstart width=960}\n:::\n:::\n\n\n## Checking convergence with multiple chains\n\n- Run multiple chains to see if they converge to the same target.\n   - if not, check starting values (compare log posterior) or parameter identifiability!\n- Markov chains should look like a fat hairy caterpillar!\n- `bayesplot` and `coda` have functionalities for plots (trace plot, trace rank, correlograms, marginal densities, etc.)\n\n## Healthy Markov chains on display\n\nFour chains run in parallel.\n\n![](fig/catterpillar_traceplots.png)\n\n## Goldilock principle and proposal variance\n\nMixing of the chain requires just the right variance (not too small nor too large).\n\n\n::: {.cell hash='bayesmod-slides3_cache/revealjs/fig-goldilock-trace_36a30a181c42268d4f81328aadf6b3a1'}\n::: {.cell-output-display}\n![Example of traceplot with proposal variance that is too small (top), adequate (middle) and too large (bottom).](bayesmod-slides3_files/figure-revealjs/fig-goldilock-trace-1.png){#fig-goldilock-trace width=960}\n:::\n:::\n\n\n## Correlograms for Goldilock \n\n\n\n::: {.cell hash='bayesmod-slides3_cache/revealjs/fig-goldilock-correlogram_45284b546c3f0f82eb8296f7d2f08e55'}\n::: {.cell-output-display}\n![Correlogram for the three Markov chains.](bayesmod-slides3_files/figure-revealjs/fig-goldilock-correlogram-1.png){#fig-goldilock-correlogram width=960}\n:::\n:::\n\n\n\n## Tuning Markov chain Monte Carlo\n\n- Outside of starting values, the variance of the proposal has a huge impact on the asymptotic variance.\n- We can check this via the acceptance rate (how many proposals are accepted).\n- In 1D, rule of thumb is an acceptance rate of 0.44 is optimal, and this ratio decreases to 0.234 when $D \\geq 2$ [@Sherlock:2013] for random walk Metropolis--Hastings.\n- Adapt the variance during warmup by increasing/decreasing proposal variance (if acceptance rate is too large/small).\n\n## Block update or one parameter at a time?\n\nAs with any accept-reject, proposals become inefficient when the dimension $D$ increase: this is the curse of dimensionality.\n\n- updating parameters in turn increases acceptance rate (with clever proposals), but also leads to more autocorrelation between parameters\n- using orthogonal parametrization whenever possible (reparametrize the model to decorrelate parameters)\n- if you cannot, draw correlated proposals (using the chain history to inform the correlation, if necessary)\n\n\n## Parameter transformation\n\nParameters may be bounded, e.g. $\\theta_i \\in [a,b]$.\n\n- We can ignore this and simply discard proposals outside of the range, by setting the log posterior at $-\\infty$ outside $[a,b]$\n- We can do a transformation, e.g., $\\log \\theta_i$ if $\\theta_i > 0$ and perform a random walk on the uncontrained space: need Jacobians!\n- Another alternative is to use truncated proposals (especially with more complex algorithms like MALA)\n\n## Efficient proposals: MALA {.smaller}\n\nThe Metropolis-adjusted Langevin algorithm (MALA) uses a Gaussian random walk proposal $$\\boldsymbol{\\theta}^{\\star}_t \\sim \\mathsf{No}\\{\\mu(\\boldsymbol{\\theta}_{t-1}), \\tau^2\\mathbf{A})\\},$$ where $$\\mu(\\boldsymbol{\\theta}_{t-1})=\\boldsymbol{\\theta}_{t-1} + \\mathbf{A}\\eta \\nabla \\ell(\\boldsymbol{\\theta}_{t-1}),$$ and with variance $\\tau^2\\mathbf{A}$, for some mass matrix $\\boldsymbol{A}$, tuning parameter $\\tau>0$ and a damping factor $\\eta < 1$.\n\nWe need to compute the density for the reverse move with mean $\\mu(\\boldsymbol{\\theta}_{t}^\\star)$.^[This is akin to a Newton algorithm, so beware if far from the mode (where gradient can be large)!]\n\n## References\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}