{
  "hash": "330335ac06da534bcf473e7bc4cbf4ad",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Bayesian modelling\"\nauthor: \"LÃ©o Belzile\"\nsubtitle: \"Monte Carlo methods, Markov chains and the Metropolis--Hastings algorithm\"\ndate: today\ndate-format: \"[Last compiled] dddd MMM D, YYYY\"\neval: true\necho: true\ncache: true\nwidth: 1200\nheight: 900\nbibliography: MATH80601A.bib\nformat:\n  revealjs:\n    slide-number: true\n    html-math-method: mathjax\n    preview-links: auto\n    theme: [simple, hecmontreal.scss]\n    title-slide-attributes:\n      data-background-color: \"#ff585d\"\n    logo: \"fig/logo_hec_montreal_bleu_web.png\"\n---\n\n\n\n\n\n## Bayesian inference beyond conjugate models\n\nHow to circumvent the problem of intractable posteriors?\n\n- simulation-based methods: accept-reject, Markov chain Monte Carlo, particle filters, etc.\n- deterministic methods: (integrated nested) Laplace approximations, variational Bayes, expectation propagation, etc.\n\nWe focus on Monte Carlo methods.\n\n\n## Simulation algorithms: inversion method\n\nIf $F$ is an absolutely continuous distribution function, then \n$$F(X) \\sim \\mathsf{unif}(0,1).$$\nThe inversion method consists in applying the quantile function $F^{-1}$ to $U \\sim \\mathsf{unif}(0,1)$, viz. $$F^{-1}(U) \\sim X.$$\n\n\n\n## Inversion method for truncated distributions\n\nConsider a random variable $Y$ with distribution function $F$.\n\nIf $X$ follows the same distribution as $Y$, but restricted over the interval $[a,b]$, then\n$$\\Pr(X \\leq x) = \\frac{F(x) - F(a)}{F(b)-F(a)}, \\qquad a \\leq x \\leq b,$$\n\nTherefore, $$F^{-1}[F(a) + \\{F(b)-F(a)\\}U] \\sim X.$$\n\n\n## Fundamental theorem of simulation\n\nConsider a $d$-variate random vector $\\boldsymbol{X},$ independent of $U \\sim \\mathsf{unif}(0,1)$ and $c>0$.\nIf $(\\boldsymbol{X}, U)$ is uniformly distributed on the set\n\\begin{align*}\n\\mathcal{A}_{f}=\\{(\\boldsymbol{x}, u): 0 \\leq u \\leq  c f(\\boldsymbol{x})\\},\n\\end{align*}\nthen $\\boldsymbol{X}$ has density $f(\\boldsymbol{x}).$ \n<!--\nConversely, if $\\boldsymbol{X}$ has density $f(\\boldsymbol{x})$ and $U\\sim\\mathsf{unif}(0,1)$ independently, then $[\\boldsymbol{X}, cUf(\\boldsymbol{X})]$ is uniformly distributed on $\\mathcal{A}_f$\n-->\n\n- $f$ is the marginal density of $\\boldsymbol{X}$ since $f(\\boldsymbol{x}) = \\int_0^{f(\\boldsymbol{x})} \\mathrm{d} u.$\n- If we can simulate uniformly from $\\mathcal{A}_{f},$ then, we can discard the auxiliary variable $u.$ See @Devroye:1986, Theorem 3.1.\n\n## Fundamental theorem of simulation in picture\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Illustration of the fundamental theorem of simulation. All points in blue below the density curve belong to $\\mathcal{A}_f.$](bayesmod-slides4_files/figure-revealjs/fig-fundamental-theorem-1.png){#fig-fundamental-theorem width=960}\n:::\n:::\n\n\n\n\n## Simulation algorithms: accept-reject\n\n\n\n- **Target**: sample from density $p(x)$ (hard to sample from)\n- **Proposal**: find a density $q(x)$ with nested support, $\\mathrm{supp}(p) \\subseteq \\mathrm{supp}(q)$, such that for all $x \\in \\mathrm{supp}(p)$, \n$$\\frac{p(x)}{q(x)} \\leq C, \\quad C \\geq 1.$$\n*Uses the fundamental theorem of simulation by finding an enveloppe $Cq(x)$ that is over the density $p(x).$*\n\n## Rejection sampling algorithm\n\n1. Generate $X$ from proposal with density $q(x)$.\n2. Compute the ratio $R \\gets p(X)/ q(X)$.\n3. If $CU \\leq R$ for $U \\sim \\mathsf{unif}(0,1)$, return $X$, else go back to step 1.\n\n\n## Accept-reject illustration\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Target density (full) and scaled proposal density (dashed): the vertical segment at $x=1$ shows the percentage of acceptance for a uniform slice under the scaled proposal, giving an acceptance ratio of 0.58.](bayesmod-slides4_files/figure-revealjs/fig-acceptreject-1.png){#fig-acceptreject width=960}\n:::\n:::\n\n\n\n\n## Remarks on rejection sampling\n\n- Acceptance rate is $1/C$:\n   - we need on average $C$ draws from $q$ to get one from $p$.\n- $q$ must be more heavy-tailed than $p$\n   - e.g., $q(x)$ Student-$t$ for $p(x)$ Gaussian.\n- $q$ should be cheap and easy to sample from!\n\n## Designing a good proposal density\n\nGood choices must satisfy the following constraints: \n\n- pick a family $q(x)$ so that $$C = \\mathrm{argmax}_x \\frac{p(x)}{q(x)}$$ is as close to 1 as possible.\n- you can use numerical optimization with target $$f(x) =\\log p(x) - \\log q(x)$$ to find the mode $x^\\star$ and the upper bound $C = \\exp f(x^\\star).$\n\n## Truncated Gaussian via accept-reject\n\nConsider sampling $Y \\sim \\mathsf{Gauss}(\\mu, \\sigma^2)$, but truncated in the interval $(a, b)$. The target density is\n\\begin{align*}\np(x; \\mu, \\sigma, a, b) = \\frac{1}{\\sigma}\\frac{\\phi\\left(\\frac{x-\\mu}{\\sigma}\\right)}{\\Phi(\\beta)-\\Phi(\\alpha)}.\n\\end{align*}\nfor $\\alpha= (a-\\mu)/\\sigma$ and $\\beta = (b-\\mu)/\\sigma$.\nwhere $\\phi(\\cdot), \\Phi(\\cdot)$ are respectively the density and distribution function of the standard Gaussian distribution.\n\n## Accept-reject (crude version)\n\n1. Simulate $X \\sim \\mathsf{Gauss}(\\mu, \\sigma^2)$\n2. reject any draw if $X < a$ or $X> b$. \n\nThe acceptance rate is $C^{-1} = \\{\\Phi(\\beta) - \\Phi(\\alpha)\\}$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Standard Gaussian truncated on [0,1]\ncandidate <- rnorm(1e5)\ntrunc_samp <- candidate[candidate >= 0 & candidate <= 1]\n# Acceptance rate\nlength(trunc_samp)/1e5\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.34289\n```\n\n\n:::\n\n```{.r .cell-code}\n# Theoretical acceptance rate\npnorm(1)-pnorm(0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.3413447\n```\n\n\n:::\n:::\n\n\n\n## Accept-reject for truncated Gaussian  {.smaller}\n\nSince the Gaussian is a location scale family, the inversion method gives\n\\begin{align*}\nX \\sim \\mu + \\sigma\\Phi^{-1}\\left[\\Phi(\\alpha) + \\{\\Phi(\\beta)-\\Phi(\\alpha)\\}U\\right]\n\\end{align*}\n\nWe however need to evaluate $\\Phi$ numerically (no closed-form expression).\n\nThe method fails for *rare event* simulation because the computer returns\n\n- $\\Phi(x) = 0$ for $x \\leq -39$\n- $\\Phi(x)=1$ for $x \\geq 8.3$,\n\nimplying that $a \\leq 8.3$ for this approach to work [@LEcuyer.Botev:2017].\n\n## Simulating tails of Gaussian variables {.smaller}\n\nWe consider simulation from a standard Gaussian truncated above $a>0$\n\nWrite the density of the truncated Gaussian as  [@Devroye:1986, p.381]$$f(x) = \\frac{\\exp(-x^2/2)}{\\int_{a}^{\\infty}\\exp(-z^2/2)\\mathrm{d} z}  =\\frac{\\exp(-x^2/2)}{c_1}.$$\n\nNote that, for $x \\geq a$, \n$$c_1f(x) \\leq \\frac{x}{a}\\exp\\left(-\\frac{x^2}{2}\\right)= a^{-1}\\exp\\left(-\\frac{a^2}{2}\\right)g(x);$$\nwhere $g(x)$ is the density of a Rayleigh variable shifted by $a$.\n\n::: {style=\"font-size: 50%;\"}\n\nThe constant $C= \\exp(-a^2/2)(c_1a)^{-1}$ approaches 1 quickly as $a \\to \\infty$ (asymptotically optimality).\n\n\n:::\n\n## Accept-reject: truncated Gaussian with Rayleigh  {.smaller}\n\nThe shifted Rayleigh has distribution function $$G(x) = 1-\\exp\\{(a^2-x^2)/2\\}, x \\geq a.$$ \n\n\n\n\n:::{.callout-important}\n\n## Marsaglia algorithm\n1. Generate a shifted Rayleigh  above $a$, $X \\gets  \\{a^2 - 2\\log(U)\\}^{1/2}$ for $U \\sim \\mathsf{unif}(0,1)$\n2. Accept $X$ if $XV \\leq a$, where $V \\sim \\mathsf{unif}(0,1)$.\n:::\n\nFor sampling on $[a,b]$ with $a$ very large, propose from a Rayleigh truncated above at $b$ [@LEcuyer.Botev:2017].\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\na <- 8.3\nniter <- 1000L\nX <- sqrt(a^2 + 2*rexp(niter))\nsamp <- X[runif(niter)*X <= a]\n```\n:::\n\n\n\n\n\n\n## Markov chains\n\nPlain ordinary Monte Carlo is great, but few algorithms are generic enough to be useful in complex high-dimensional problems.\n\nWe will instead typically build Markov chains that target an invariant stationary distribution. \n\n\n## Caveats?\n\nMarkov chain Monte Carlo methods generate **correlated** draws. \n\n**Questions**: \n\n1. can we use them as ordinary independent samples? \n2. what is the price to pay?\n\nWe need to do a little theoretical detour to answer these questions.\n\n## Stationarity and Markov property\n\n\nA stochastic process is\n\n- **(strongly) stationary** if the distribution of $\\{X_1, \\ldots, X_t\\}$ is the same as that of $\\{X_{n+1}, \\ldots X_{t+n}\\}$ for any value of $n$ and given $t$.\n- **weakly stationary** if $\\mathsf{E}(X_t) = \\mu$ for all $t$, and $\\mathsf{Cov}(X_t, X_{t+h}) = \\gamma_h$ does not depend on $t$.\n- **Markov** if it satisfies the Markov property: given the current state of the chain, the future only depends on the current state and not on the past.\n\n::: {style=\"font-size: 65%;\"}\nStrong stationarity implies weak stationarity.\n:::\n\n## Autoregressive process of order 1\n\nConsider a first-order autoregressive process, or $\\mathsf{AR}(1)$, \n\n$$Y_t = \\mu + \\phi(Y_{t-1} - \\mu) + \\varepsilon_t,$$ where \n\n- $\\phi$ is the lag-one correlation, \n- $\\mu$ the global mean\n- $\\varepsilon_t$ is an iid innovation with mean zero and variance $\\sigma^2$\n\nIf $|\\phi| < 1$, the process is stationary, otherwise the variance increases with $t$.\n\n## Unconditional moments via tower law\n\nIf the process is weakly stationary, then $\\mathsf{E}_{Y_{t}}(Y_t)=\\mathsf{E}_{Y_{t-1}}(Y_{t-1})$\n\\begin{align*}\n\\mathsf{E}_{Y_{t}}(Y_t) &= \\mathsf{E}_{Y_{t-1}}\\left\\{\\mathsf{E}_{Y_{t} \\mid Y_{t-1}}(Y_t)\\right\\}\n\\\\&= \\mu(1-\\phi) + \\phi\\mathsf{E}_{Y_{t-1}}(Y_{t-1})\n\\end{align*}\nand so the unconditional mean is $\\mu$.\nFor the variance, we have\n\\begin{align*}\n\\mathsf{Va}_{Y_{t}}(Y_t) &= \\mathsf{E}_{Y_{t-1}}\\left\\{\\mathsf{Va}_{Y_{t} \\mid Y_{t-1}}(Y_t)\\right\\} + \\mathsf{Va}_{Y_{t-1}}\\left\\{\\mathsf{E}_{Y_{t} \\mid Y_{t-1}}(Y_t)\\right\\}\\\\\n& = \\sigma^2 + \\mathsf{Va}_{Y_{t-1}}\\left\\{\\mu + \\phi(Y_{t-1} - \\mu)\\right\\}\n\\\\&= \\sigma^2 + \\phi^2 \\mathsf{Va}_{Y_{t-1}}(Y_{t-1}).\n\\end{align*}\nand the unconditional variance is $\\mathsf{Va}_{Y_t}(Y_t) = \\sigma^2/(1-\\phi^2).$\n\n\n## Autocovariance and Markov property\n\nThe covariance at lag $k$, in terms of innovations, gives\n\\begin{align*}\n\\gamma_k = \\mathsf{Co}(Y_t, Y_{t-k}) = \\mathsf{Va}(\\phi Y_{t-1}, Y_{t-k}) + \\mathsf{Va}(\\varepsilon_t, Y_{t-k}) = \\phi \\gamma_{k-1}\n\\end{align*}\nsince $\\varepsilon_t$ is independent of the past. We thus find $$\\gamma_k = \\phi^k\\mathsf{Va}(Y_t).$$\n\n\nThe $\\mathsf{AR}(1)$ process is first-order Markov since the conditional distribution $p(Y_t \\mid Y_{t-1}, \\ldots, Y_{t-p})$ equals $p(Y_t \\mid Y_{t-1}).$\n\n## Variance of sample average\n\nIntuitively, a sample of correlated observations carries less information than an independent sample of draws.\n\nThe variance of the sample average is\n\\begin{align*}\n\\mathsf{Va}\\left(\\overline{Y}_T\\right) &= \\frac{1}{T^2}\\sum_{t=1}^T \\sum_{s=1}^T \\mathsf{Co}(Y_t, Y_s)\n\\\\&= \\frac{1}{T^2}\\sum_{t=1}^T \\mathsf{Va}(Y_t) + \\frac{2}{T^2} \\sum_{t=1}^{T-1}\\sum_{s = t+1}^T \\mathsf{Co}(Y_t, Y_s).\n\\end{align*}\nUnder independence and assuming stationarity, we get $\\mathsf{Va}\\left(\\overline{Y}_T\\right)=\\sigma^2/T.$\n\n\n## Variance of sample average, redux\n\nIf the second moments are finite, the scaled limiting variance of the sample mean simplifies to\n\\begin{align*}\n\\lim_{T \\to \\infty} T\\mathsf{Va}\\left(\\overline{Y}_T\\right) = \\tau^2 \\left\\{1+2\\sum_{t=1}^\\infty \\rho_t\\right\\}.\n\\end{align*}\nwhich is a function of \n\n- the unconditional variance $\\tau^2$\n- the lag-$k$ autocorrelation, $\\mathsf{Cor}(Y_{t}, Y_{t+k})=\\rho_k.$\n\n## Effective sample size\n\nThe effective sample size is, loosely speaking, the equivalent number of observations if the $B$ marginal posterior draws where independent and more formally\n$$\n\\mathsf{ESS} = \\frac{B}{\\left\\{1+2\\sum_{t=1}^\\infty \\rho_t\\right\\}}\n$$ \nwhere $\\rho_t$ is the lag $t$ correlation.\n\n## Effective sample size for AR(1)\n\nThe lag-$k$ correlation of the stationary autoregressive process of order 1 is $\\phi^k$, so\n$$1+2\\sum_{t=1}^\\infty \\rho_t = 1 + 2 \\left(\\frac{1}{1-\\phi}-1\\right) = \\frac{1+\\phi}{1-\\phi}.$$\n\n\n\n## Inefficiency curve for AR(1) {.smaller}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Left: scaled asymptotic variance of the sample mean for AR(1) (full line) and independent observations with unit marginal variance (dashed). Right: variance ratio for positive correlations for selected range.](bayesmod-slides4_files/figure-revealjs/fig-ar1-variance-1.png){#fig-ar1-variance width=768}\n:::\n:::\n\n\n\n\nTo get the same precision for the mean of $\\mathsf{AR}(1)$ process with $\\phi \\approx 0.75$ than with i.i.d. data, we would need 7 times as many observations.\n\n## Morale of the story \n\nThe price to pay for having correlated samples is \n\n:::{style=\"font-size: 2em; color: #ff585d; text-align: center\"}\n\n**inefficiency**\n\n:::\n\nThe higher the autocorrelation, the larger the variability of our estimators.\n\n\n## Correlogram\n\nWe can look at the autocorrelation function to check the efficiency.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Correlogram of two Markov chains. These plots, often called acf or autocorrelation functions, show the lag-k sample autocorrelation against lag number.](bayesmod-slides4_files/figure-revealjs/fig-correlograms-1.png){#fig-correlograms width=960}\n:::\n:::\n\n\n\n\n\n## Convergence of Markov chains\n\nIf a Markov chain is irreducible and acyclic, it has a unique stationary distribution.\n\n- **irreducibility**: means that the chain can move from anywhere to anywhere, so it doesn't get stuck in part of the space forever.\n- **acyclic**: cyclical chains loop around and visit periodically a state\n\n## Examples of cyclical or reducible chains\n\nConsider discrete Markov chains over the integers $1, 2, 3$ with transition matrices\n\n$$\nP_1 = \\begin{pmatrix}\n0.5 & 0.3 & 0.2 \\\\\n0 & 0.4 & 0.6 \\\\\n0 & 0.5 & 0.5\n\\end{pmatrix},\n\\quad\nP_2 = \\begin{pmatrix}\n0 & 0 & 1 \\\\\n1 & 0 & 0 \\\\\n0 & 1 & 0\n\\end{pmatrix}.\n$$\nChain 1 is reducible to $\\{2, 3\\}$, chain 2 is cyclical.\n\n\n\n## Law of large number (ergodic theorem)\n\nErgodicity means that two segments of a time series far enough apart act as independent.\n\nLet $\\{Y_t\\}$ is a weakly stationary sequence with mean $\\mathsf{E}(Y_t)=\\mu$ and $\\gamma_h = \\mathsf{Cov}(Y_t, Y_{t+h})$. Then, if the autocovariance series is convergent, meaning\n$$\\sum_{t=0}^\\infty |\\gamma_h| < \\infty,$$\nthen $\\{Y_t\\}$ is ergodic for the mean and $\\overline{Y} \\stackrel{\\mathrm{p}}{\\to} \\mu$.\n\n## Ergodicity and transformations\n\nThe ergodic theorem is a law of large numbers for stochastic processes that allows for serial dependence between observations, provided the latter is not too large.\n\nAny transformation $g(\\cdot)$ of a stationary and ergodic process $\\{Y_t\\}$ retains the properties, so $\\overline{g} = T^{-1} \\sum_{t=1}^T g(Y_t) \\to \\mathsf{E}\\{g(Y_t)\\}$ as $T \\to \\infty.$\n\nThe ergodic theorem holds even if the chain is cyclical.\n\n\n\n## Convergence and stationary distribution\n\nConsider a transition $P$ on $1, \\ldots, 5$ defined as $$\nP = \\begin{pmatrix}\n\\frac{2}{3} & \\frac{1}{3} &  0 & 0 & 0 \\\\\n\\frac{1}{6} & \\frac{2}{3} & \\frac{1}{6} & 0 & 0 \\\\\n0 & \\frac{1}{6} & \\frac{2}{3} & \\frac{1}{6} & 0 \\\\\n0 & 0 & \\frac{1}{6} & \\frac{2}{3} & \\frac{1}{6} \\\\\n0 & 0 & 0 &  \\frac{1}{3}  & \\frac{2}{3} \\\\\n\\end{pmatrix}\n$$ The stationary distribution is the value of the row vector $\\boldsymbol{p},$ such that $\\boldsymbol{p} = \\boldsymbol{p}\\mathbf{P}$ for transition matrix $\\mathbf{P}$: we get $\\boldsymbol{p}=(1,2,2,2,1)/8.$\n\n\n## Convergence of Markov chains\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Discrete Markov chain on integers from 1 to 5, with traceplot of 1000 first iterations (left) and running mean plots of sample proportion of each state visited (right).](bayesmod-slides4_files/figure-revealjs/fig-discrete-markov-chain-1.png){#fig-discrete-markov-chain width=960}\n:::\n:::\n\n\n\n## Markov chain Monte Carlo\n\nWe consider simulating from a distribution with associated density function proportional to $p(\\cdot)$\n\n- using an algorithm that generates a Markov chain ,\n- without requiring knowledge of the normalizing factor.\n\n\nWe use a conditional density $q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}^{\\text{cur}})$ to generate proposals from the current value $\\boldsymbol{\\theta}^{\\text{cur}}.$\n\n\n\n## Metropolis--Hastings algorithm \n\nStarting from an initial value $\\boldsymbol{\\theta}_0$: for $t=1, \\ldots, T$\n\n1.  draw a proposal value $\\boldsymbol{\\theta}_t^{\\star} \\sim q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}_{t-1})$.\n2.  Compute the acceptance ratio $$\n    R = \\frac{p(\\boldsymbol{\\theta}_t^{\\star})}{p(\\boldsymbol{\\theta}_{t-1})}\\frac{q(\\boldsymbol{\\theta}_{t-1} \\mid \\boldsymbol{\\theta}_t^{\\star} )}{q(\\boldsymbol{\\theta}_t^{\\star} \\mid \\boldsymbol{\\theta}_{t-1})}\n    $$\n3.  With probability $\\alpha=\\min\\{R, 1\\}$, accept the proposal and set $\\boldsymbol{\\theta}_t \\gets \\boldsymbol{\\theta}_t^{\\star}$, otherwise set the value to the previous state, $\\boldsymbol{\\theta}_t \\gets \\boldsymbol{\\theta}_{t-1}$.\n\n## Theory\n\nThe Metropolis--Hastings algorithm satisfies a technical condition (detailed balance) that ensures that the Markov chain generated is reversible. \n\n- Thus, any draw from the posterior will generate a new realization from the posterior. \n- Provided the starting value has non-zero probability under the posterior, the chain will converge to the stationarity distribution (albeit perhaps slowly).\n\n\n## Interpretation\n\n\n\n- If $R>1$, the proposal has higher density and we always accept the move. \n- If we reject the move, the Markov chain stays at the current value, which induces autocorrelation.\n- Since the acceptance probability depends only on the density through ratios, normalizing factors of $p$ and $q$ cancel out.\n\n\n## Symmetric proposals and random walk\n\nIf the proposal is symmetric, the ratio of proposal densities is $$q(\\boldsymbol{\\theta}_{t-1} \\mid \\boldsymbol{\\theta}_t^{\\star} ) / q(\\boldsymbol{\\theta}_t^{\\star} \\mid \\boldsymbol{\\theta}_{t-1}) = 1.$$\n\nCommon examples include random walk proposals\n$$\\boldsymbol{\\theta}_t^{\\star} \\gets \\boldsymbol{\\theta}_{t-1} + \\tau Z,$$ where $Z \\sim \\mathsf{Gauss}(0,1).$\n\n## Independent proposals\n\n- If we pick instead a global proposal, we must ensure that $q$ samples in far regions (recall rejection sampling), otherwise ...\n- Good proposals include heavy tailed distribution such as Student-$t$ with small degrees of freedom, \n\n- centered at the maximum a posteriori $\\widehat{\\boldsymbol{\\theta}}$ and \n- with scale matrix proportional to $-\\mathbf{H}^{-1}(\\boldsymbol{\\theta}_t^{\\star})$, where $\\mathbf{H}(\\cdot)$ is the Hessian of the (unnormalized) log posterior.\n\n\n## Upworthy data example\n\nWe model the Poisson rates for headlines with questions or not. Our model is\n\\begin{align*}\nY_{i} &\\sim \\mathsf{Poisson}(n_i\\lambda_i), \\qquad (i=1,2)\\\\\n\\lambda_1 &= \\exp(\\beta + \\kappa) \\\\\n\\lambda_2 &= \\exp(\\beta) \\\\\n\\beta & \\sim \\mathsf{Gauss}(\\log 0.01, 1.5) \\\\\n\\kappa &\\sim \\mathsf{Gauss}(0, 1)\n\\end{align*}\n\n## Implementation details: data and containers\n\nIn regression models, scale inputs if possible.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(upworthy_question, package = \"hecbayes\")\n# Compute sufficient statistics\ndata <- upworthy_question |>\n  dplyr::group_by(question) |>\n  dplyr::summarize(ntot = sum(impressions),\n                   y = sum(clicks))\n# Create containers for MCMC\nniter <- 1e4L\nchain <- matrix(0, nrow = niter, ncol = 2L)\ncolnames(chain) <- c(\"beta\",\"kappa\")\n```\n:::\n\n\n\n\n## Implementation details: log posterior function\n\nPerform all calculations on the log scale to avoid numerical overflow! \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Code log posterior as sum of log likelihood and log prior\nloglik <- function(par, counts = data$y, offset = data$ntot, ...){\n  lambda <- exp(c(par[1] + log(offset[1]), par[1] + par[2] + log(offset[2])))\n sum(dpois(x = counts, lambda = lambda, log = TRUE))\n}\n# Note common signature of function\nlogprior <- function(par, ...){\n  dnorm(x = par[1], mean = log(0.01), sd = 1.5, log = TRUE) +\n    dnorm(x = par[2], log = TRUE)\n}\nlogpost <- function(par, ...){\n  loglik(par, ...) + logprior(par, ...)\n}\n```\n:::\n\n\n\n## Implementation details: proposals\n\nUse good starting values for your Markov chains, such as maximum a posteriori.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compute maximum a posteriori (MAP)\nmap <- optim(\n  par = c(-4, 0.07),\n  fn = logpost,\n  control = list(fnscale = -1),\n  offset = data$ntot,\n  counts = data$y,\n  hessian = TRUE)\n# Use MAP as starting value\ncur <- map$par\n# Compute logpost_cur - we can keep track of this to reduce calculations\nlogpost_cur <- logpost(cur)\n# Proposal covariance\ncov_map <- -2*solve(map$hessian)\nchol <- chol(cov_map)\n```\n:::\n\n\n\n## Implementation details: Metropolis--Hastings algorithm\n\nUse seed for reproducibility, do not compute posterior twice, compute log of acceptance ratio. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(80601)\nnaccept <- 0L\nfor(i in seq_len(niter)){\n  # Multivariate normal proposal - symmetric random walk\n  prop <- c(rnorm(n = 2) %*% chol + cur)\n  logpost_prop <- logpost(prop)\n  logR <- logpost_prop - logpost_cur\n  if(logR > -rexp(1)){\n    cur <- prop\n    logpost_cur <- logpost_prop\n    naccept <- naccept + 1L\n  }\n  chain[i,] <- cur\n}\n```\n:::\n\n\n\n## Implementation details: analysis of output\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Posterior summaries\nsummary(coda::as.mcmc(chain))\n# Computing standard errors using batch means\nsqrt(diag(mcmc::olbm(chain, batch.length = niter/40)))\n```\n:::\n\n\n\n```\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean       SD  Naive SE Time-series SE\nbeta  -4.51268 0.001697 1.697e-05      6.176e-05\nkappa  0.07075 0.002033 2.033e-05      9.741e-05\n\n2. Quantiles for each variable:\n\n          2.5%      25%      50%      75%    97.5%\nbeta  -4.51591 -4.51385 -4.51273 -4.51154 -4.50929\nkappa  0.06673  0.06933  0.07077  0.07212  0.07463\n```\n\n## Standard errors for posterior means -- batch means\n\n@Geyer:2011 recommends to segment the time series into batches\n\n1. Break the chain of length $B$ (after burn in) in $K$ blocks of size $\\approx K/B.$\n2. Compute the sample mean of each segment.\n3. Compute the standard deviation of the segments mean.\n4. Rescale by $K^{-1/2}$ to get standard error of the global mean.\n\n## Illustration of batch means\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Calculation of the standard error of the posterior mean using the batch method.](bayesmod-slides4_files/figure-revealjs/fig-mcmc-batchmean-1.png){#fig-mcmc-batchmean width=960}\n:::\n:::\n\n\n\n## Standard errors for posterior means -- autoregressive\n\nWe can also fit an high-order autoregressive process $\\mathsf{AR}(p)$ and approximate the unconditional variance by that, and divide by $\\sqrt{T}$.\n\n- Standard methods (Yule--Walker equations, maximum likelihood, spectral estimation) apply.\n\n\n\n## References\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}