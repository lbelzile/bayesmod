{
  "hash": "950d9e5b1c7514973615ddbd6f554b80",
  "result": {
    "markdown": "---\ntitle: \"Bayesian modelling\"\nauthor: \"LÃ©o Belzile\"\nsubtitle: \"Markov chain Monte Carlo\"\ndate: today\ndate-format: YYYY\neval: true\necho: true\ncache: true\nbibliography: MATH80601A.bib\nformat:\n  revealjs:\n    slide-number: true\n    preview-links: auto\n    theme: [simple, hecmontreal.scss]\n    title-slide-attributes:\n      data-background-color: \"#ff585d\"\n    logo: \"fig/logo_hec_montreal_bleu_web.png\"\n---\n\n\n\n\n\n## Reminder: Metropolis--Hastings algorithm \n\nStarting from an initial value $\\boldsymbol{\\theta}_0$:\n\n1.  draw a proposal value $\\boldsymbol{\\theta}_t^{\\star} \\sim q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}_{t-1})$.\n2.  Compute the acceptance ratio $$\n    R = \\frac{p(\\boldsymbol{\\theta}_t^{\\star})}{p(\\boldsymbol{\\theta}_{t-1})}\\frac{q(\\boldsymbol{\\theta}_{t-1} \\mid \\boldsymbol{\\theta}_t^{\\star} )}{q(\\boldsymbol{\\theta}_t^{\\star} \\mid \\boldsymbol{\\theta}_{t-1})}\n    $$\n3.  With probability $\\min\\{R, 1\\}$, accept the proposal and set $\\boldsymbol{\\theta}_t \\gets \\boldsymbol{\\theta}_t^{\\star}$, otherwise set the value to the previous state, $\\boldsymbol{\\theta}_t \\gets \\boldsymbol{\\theta}_{t-1}$.\n\n## Calculations\n\n\nWe compute the log of the acceptance ratio, $\\ln R$, to avoid numerical overflow, with the log posterior difference\n$$\n\\ln \\left\\{\\frac{p(\\boldsymbol{\\theta}_t^{\\star})}{p(\\boldsymbol{\\theta}_{t-1})}\\right\\} = \\ell(\\boldsymbol{\\theta}_t^{\\star}) + \\ln p(\\boldsymbol{\\theta}_t^{\\star}) - \\ell(\\boldsymbol{\\theta}_{t-1}) - \\ln p(\\boldsymbol{\\theta}_{t-1}) \n$$\n\n\nCompare the value of $\\ln R$ (if less than zero) to $\\log(U)$, where $U \\sim \\mathsf{U}(0,1)$. \n\n\n## What proposal?\n\nThe *independence* Metropolis--Hastings uses a global proposal $q$ which does not depend on the current state (typically centered at the MAP)\n\nThis may be problematic with multimodal targets.\n\nThe Gaussian random walk takes $\\boldsymbol{\\theta}_t^{\\star} =\\boldsymbol{\\theta}_{t-1}+ \\sigma_\\text{p}Z$, where $Z \\sim \\mathsf{Norm}(0,1)$ and $\\sigma_\\text{p}$ is the proposal standard deviation. *Random walks* allow us to explore the space.\n\n\n\n## Burn in\n\nWe are guaranteed to reach stationarity with Metropolis--Hastings, but it may take a large number of iterations...\n\nOne should discard initial draws during a **burn in** or warmup period if the chain has not reached stationarity. Ideally, use good starting value to reduce waste.\n\nWe can also use the warmup period to adapt the variance of the proposal.\n\n## Goldilock principle and proposal variance\n\nMixing of the chain requires just the right variance (not too small nor too large).\n\n\n::: {.cell hash='bayesmod-slides4_cache/revealjs/fig-goldilock-trace_13973021f5c79e0c00dd83305113a0b4'}\n::: {.cell-output-display}\n![Example of traceplot with proposal variance that is too small (top), adequate (middle) and too large (bottom).](bayesmod-slides4_files/figure-revealjs/fig-goldilock-trace-1.png){#fig-goldilock-trace width=960}\n:::\n:::\n\n\n## Correlograms for Goldilock \n\n\n\n::: {.cell hash='bayesmod-slides4_cache/revealjs/fig-goldilock-correlogram_7879a9a1f59875896c5d6c23e6209737'}\n::: {.cell-output-display}\n![Correlogram for the three Markov chains.](bayesmod-slides4_files/figure-revealjs/fig-goldilock-correlogram-1.png){#fig-goldilock-correlogram width=960}\n:::\n:::\n\n\n\n## Tuning Markov chain Monte Carlo\n\n- Outside of starting values, the variance of the proposal has a huge impact on the asymptotic variance.\n- We can adapt the variance during warmup by increasing/decreasing proposal variance (if acceptance rate is too large/small).\n- We can check this via the acceptance rate (how many proposals are accepted).\n\n## Optimal acceptance rates \n\nThe following rules were derived for Gaussian targets under idealized situations.\n\n- In 1D, rule of thumb is an acceptance rate of $0.44$ is optimal, and this ratio decreases to $0.234$ when $D \\geq 2$ [@Sherlock:2013] for random walk Metropolis--Hastings.\n- Proposals for $D$-variate update should have proposal variance of roughly $(2.38^2/d)\\times \\boldsymbol{\\Sigma}$, where $\\boldsymbol{\\Sigma}$ is the posterior variance.\n- For MALA (see later), we get $0.574$ rather than $0.234$\n\n## Block update or one parameter at a time?\n\nAs with any accept-reject, proposals become inefficient when the dimension $D$ increase.\n\nThis is the **curse of dimensionality**.\n\nUpdating parameters in turn \n\n- increases acceptance rate (with clever proposals), \n- but also leads to more autocorrelation between parameters\n\n## Solutions for strongly correlated coefficients\n\n- Reparametrize the model to decorrelate variables (orthogonal parametrization).\n- Block updates: draw correlated parameters together \n   - using the chain history to learn the correlation, if necessary\n\n\n\n## Parameter transformation\n\nParameters may be bounded, e.g. $\\theta_i \\in [a,b]$.\n\n- We can ignore this and simply discard proposals outside of the range, by setting the log posterior at $-\\infty$ outside $[a,b]$\n- We can do a transformation, e.g., $\\log \\theta_i$ if $\\theta_i > 0$ and perform a random walk on the unconstrained space: don't forget Jacobians for $q(\\cdot)$!\n- Another alternative is to use truncated proposals (useful with more complex algorithms like MALA)\n\n\n## Efficient proposals: MALA {.smaller}\n\nThe Metropolis-adjusted Langevin algorithm (MALA) uses a Gaussian random walk proposal $$\\boldsymbol{\\theta}^{\\star}_t \\sim \\mathsf{Norm}\\{\\mu(\\boldsymbol{\\theta}_{t-1}), \\tau^2\\mathbf{A}\\},$$ with mean $$\\mu(\\boldsymbol{\\theta}_{t-1})=\\boldsymbol{\\theta}_{t-1} + \\mathbf{A}\\eta \\nabla \\log p(\\boldsymbol{\\theta}_{t-1} \\mid \\boldsymbol{y}),$$ and variance $\\tau^2\\mathbf{A}$, for some mass matrix $\\mathbf{A}$, tuning parameter $\\tau>0$. \n\nThe parameter $\\eta < 1$ is a learning rate. This is akin to a Newton algorithm, so beware if you are far from the mode (where the gradient is typically large)!\n\n\n## Higher order proposals\n\nFor a single parameter update $\\theta$, a Taylor series expansion of the log posterior around the current value suggests using as proposal density a Gaussian approximation with [@Rue.Held:2005]\n\n- mean $\\mu_{t-1} = \\theta_{t-1} - f'(\\theta_{t-1})/f''(\\theta_{t-1})$ and \n- precision $\\tau^{-2} = -f''(\\theta_{t-1})$\n\nWe need $f''(\\theta_{t-1})$ to be negative!\n\nThis gives **local adaption** relative to MALA (global variance).\n\n## Higher order and moves\n\nFor MALA and cie., we need to compute the density of the proposal also for the reverse move for the expansion starting from the proposal $\\mu(\\boldsymbol{\\theta}_{t}^\\star)$.\n\nThese methods are more efficient than random walk Metropolis--Hastings, but they require the gradient and the hessian (can be obtained analytically using autodiff, or numerically).\n\n## Modelling individual headlines of **Upworthy** example\n\nThe number of conversions `nclick` is binomial with sample size $n_i=$`nimpression`.\n\nSince $n_i$ is large, the sample average `nclick`/`nimpression` is approximately Gaussian, so write\n\n\\begin{align*}\nY_i &\\sim \\mathsf{Norm}(\\mu, \\sigma^2/n_i)\\\\\n\\mu &\\sim \\mathsf{TruncNorm}(0.01, 0.1^2, 0, 1) \\\\\n\\sigma &\\sim \\mathsf{Exp}(0.7)\n\\end{align*}\n\n## MALA: data set-up\n\n\n::: {.cell hash='bayesmod-slides4_cache/revealjs/unnamed-chunk-4_7eba174801635e224480f130e976539b'}\n\n```{.r .cell-code}\ndata(upworthy_question, package = \"hecbayes\")\n# Select data for a single question\nqdata <- upworthy_question |>\n  dplyr::filter(question == \"yes\") |>\n  dplyr::mutate(y = clicks/impressions,\n                no = impressions)\n```\n:::\n\n\n## MALA: define functions\n\n::: {.cell hash='bayesmod-slides4_cache/revealjs/unnamed-chunk-5_35591bd1c2ce4698935467286ab51f43'}\n\n```{.r .cell-code}\n# Create functions with the same signature (...) for the algorithm\nlogpost <- function(par, data, ...){\n  mu <- par[1]; sigma <- par[2]\n  no <- data$no\n  y <- data$y\n  if(isTRUE(any(sigma <= 0, mu < 0, mu > 1))){\n    return(-Inf)\n  }\n  dnorm(x = mu, mean = 0.01, sd = 0.1, log = TRUE) +\n  dexp(sigma, rate = 0.7, log = TRUE) + \n  sum(dnorm(x = y, mean = mu, sd = sigma/sqrt(no), log = TRUE))\n}\n```\n:::\n\n\n## MALA: compute gradient of log posterior\n\n\n::: {.cell hash='bayesmod-slides4_cache/revealjs/unnamed-chunk-6_8bfc327b2ae70e75ea0ed471e7e0ca24'}\n\n```{.r .cell-code}\nlogpost_grad <- function(par, data, ...){\n   no <- data$no\n  y <- data$y\n  mu <- par[1]; sigma <- par[2]\n  c(sum(no*(y-mu))/sigma^2 -(mu - 0.01)/0.01,\n    -length(y)/sigma + sum(no*(y-mu)^2)/sigma^3 -0.7\n  )\n}\n```\n:::\n\n\n\n## MALA: compute maximum a posteriori\n\n\n::: {.cell hash='bayesmod-slides4_cache/revealjs/unnamed-chunk-7_139f4cc694ce30bd7a2ce8ed838072dc'}\n\n```{.r .cell-code}\n# Starting values - MAP\nmap <- optim(\n  par = c(mean(qdata$y), 0.5),\n  fn = function(x){-logpost(x, data = qdata)},\n  gr = function(x){-logpost_grad(x, data = qdata)},  \n  hessian = TRUE,\n  method = \"BFGS\")\n# Check convergence \nlogpost_grad(map$par, data = qdata)\n```\n:::\n\n\n## MALA: starting values and mass matrix\n\n\n::: {.cell hash='bayesmod-slides4_cache/revealjs/unnamed-chunk-8_c39a55d94f33bcd175275d4211c97c42'}\n\n```{.r .cell-code}\n# Set initial parameter values\ncurr <- map$par \n# Compute a mass matrix\nAmat <- solve(map$hessian)\n# Cholesky root - for random number generation\ncholA <- chol(Amat)\n```\n:::\n\n\n## MALA: containers and setup\n\n\n::: {.cell hash='bayesmod-slides4_cache/revealjs/unnamed-chunk-9_98cd90b2e9ed0ec448d11467f6636d19'}\n\n```{.r .cell-code}\n# Create containers for MCMC\nB <- 1e4L # number of iterations\nwarmup <- 1e3L # adaptation period\nnpar <- 2L\nprop_sd <- rep(1, npar) # tuning parameter\nchains <- matrix(nrow = B, ncol = npar)\ndamping <- 0.8\nacceptance <- attempts <- 0 \ncolnames(chains) <- names(curr) <- c(\"mu\",\"sigma\")\n# Proposal variance proportional to inverse hessian at MAP\nprop_var <- diag(prop_sd) %*% Amat %*% diag(prop_sd)\n```\n:::\n\n\n## MALA: sample proposal with Newton step\n\n\n::: {.cell hash='bayesmod-slides4_cache/revealjs/unnamed-chunk-10_fce87b329e7da03bd14c78f11a16002f'}\n\n```{.r .cell-code}\nfor(i in seq_len(B + warmup)){\n  ind <- pmax(1, i - warmup)\n  # Compute the proposal mean for the Newton step\n  prop_mean <- c(curr + damping * \n     Amat %*% logpost_grad(curr, data = qdata))\n  # prop <- prop_sd * c(rnorm(npar) %*% cholA) + prop_mean\n  prop <- c(mvtnorm::rmvnorm(\n    n = 1,\n    mean = prop_mean, \n    sigma = prop_var))\n#  [...]\n```\n:::\n\n\n## MALA: reverse step\n\n\n::: {.cell hash='bayesmod-slides4_cache/revealjs/unnamed-chunk-11_37679430a47948ae68ee81a6e7fa9fe0'}\n\n```{.r .cell-code}\n  # Compute the reverse step\n  curr_mean <- c(prop + damping * \n     Amat %*% logpost_grad(prop, data = qdata))\n  # log of ratio of bivariate Gaussian densities\n  logmh <- mvtnorm::dmvnorm(\n    x = curr, mean = prop_mean, \n    sigma = prop_var, \n    log = TRUE) - \n    mvtnorm::dmvnorm(\n      x = prop, \n      mean = curr_mean, \n      sigma = prop_var, \n      log = TRUE) + \n  logpost(prop, data = qdata) - \n    logpost(curr, data = qdata)\n```\n:::\n\n\n## MALA: Metropolis--Hastings ratio\n\n\n::: {.cell hash='bayesmod-slides4_cache/revealjs/unnamed-chunk-12_1c2a4fa55860cfd7e37c44668c39d737'}\n\n```{.r .cell-code}\n  if(logmh > log(runif(1))){\n    curr <- prop\n    acceptance <- acceptance + 1L\n  }\n  attempts <- attempts + 1L\n  # Save current value\n  chains[ind,] <- curr\n```\n:::\n\n\n## MALA: adaptation\n\n\n::: {.cell hash='bayesmod-slides4_cache/revealjs/unnamed-chunk-13_2d99f6b8817e2af2729133b6a6d77576'}\n\n```{.r .cell-code}\n  if(i %% 100 & i < warmup){\n    # Check acceptance rate and increase/decrease variance\n    out <- hecbayes::adaptive(\n      attempts = attempts, # counter for number of attempts\n      acceptance = acceptance, \n      sd.p = prop_sd, #current proposal standard deviation\n      target = 0.574) # target acceptance rate\n    prop_sd <- out$sd # overwrite current std.dev\n    acceptance <- out$acc # if we change std. dev, this is set to zero\n    attempts <- out$att # idem, otherwise unchanged\n    prop_var <- diag(prop_sd) %*% Amat %*% diag(prop_sd)\n  }\n} # End of MCMC for loop\n```\n:::\n\n\n\n\n## Gibbs sampling\n\nThe Gibbs sampling algorithm builds a Markov chain by iterating through a sequence of conditional distributions. \n\n\n\n::: {.cell hash='bayesmod-slides4_cache/revealjs/fig-Gibbs-steps_2a01e9c63e5a2b0c6c25c821540bd523'}\n::: {.cell-output-display}\n![Sampling trajectory for a bivariate target using Gibbs sampling.](bayesmod-slides4_files/figure-revealjs/fig-Gibbs-steps-1.png){#fig-Gibbs-steps width=960}\n:::\n:::\n\n\n\n## Gibbs sampler\n\nSplit the parameter vector $\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta} \\subseteq \\mathbb{R}^p$ into $m \\leq p$ blocks, $$\\boldsymbol{\\theta}^{[j]}\\quad j=1, \\ldots, m$$\nsuch that, conditional on the remaining components of the parameter vector $\\boldsymbol{\\theta}^{-[j]}$, the conditional posterior $$p(\\boldsymbol{\\theta}^{[j]} \\mid \\boldsymbol{\\theta}^{-[j]}, \\boldsymbol{y})$$\nis from a known distribution from which we can easily simulate.\n\n## Gibbs sampling update\n\nAt iteration $t$, we can update each block in turn: note that the $k$th block uses the partially updated state\n\\begin{align*}\n\\boldsymbol{\\theta}^{-[k]\\star} = (\\boldsymbol{\\theta}_{t}^{[1]}, \\ldots, \\boldsymbol{\\theta}_{t}^{[k-1]},\\boldsymbol{\\theta}_{t-1}^{[k+1]}, \\boldsymbol{\\theta}_{t-1}^{[m]})\n\\end{align*}\nwhich corresponds to the current value of the parameter vector after the updates. \n\n## Notes on Gibbs sampling\n\n- Special case of Metropolis--Hastings with conditional density as proposal $q$. \n- The benefit is that all proposals get accepted, $R=1$!\n- No tuning parameter, but parametrization matters.\n- Automatic acceptance does not equal efficiency.\n\nTo check the validity of the Gibbs sampler, see the methods proposed in @Geweke:2004.\n\n\n## Efficiency of Gibbs sampling\n\nAs the dimension of the parameter space increases, and as the correlation between components becomes larger, the efficiency of the Gibbs sampler degrades\n\n\n::: {.cell hash='bayesmod-slides4_cache/revealjs/fig-gibbs-normal_014e8e6b03be44b6878cbc585f27422f'}\n::: {.cell-output-display}\n![Trace plots (top) and correlograms (bottom) for the first component of a Gibbs sampler with $d=20$ equicorrelated Gaussian variates with correlation $\\rho=0.9$ (left) and $d=3$ with equicorrelation $\\rho=0.5$ (right).](bayesmod-slides4_files/figure-revealjs/fig-gibbs-normal-1.png){#fig-gibbs-normal width=960}\n:::\n:::\n\n\n## Gibbs sampling requires work!\n\n- You need to determine all of the relevant conditional distributions, which often relies on setting conditionally conjugate priors. \n- In large models with multiple layers, full conditionals may only depend on a handful of parameters (via directed acyclic graph and moral graph of the model; not covered).\n\n\n## Example of Gibbs sampling\n\nConsider independent and identically distributed observations, with\n\\begin{align*}\nY_i &\\sim \\mathsf{Norm}(\\mu, \\tau), \\qquad i=1, \\ldots, n) \n\\\\\\mu &\\sim \\mathsf{Norm}(\\nu, \\omega)\\\\\n\\tau &\\sim \\mathsf{InvGamma}(\\alpha, \\beta)\n\\end{align*}\n\nThe joint posterior is not available in closed form, but the independent priors for the mean and variance of the observations are conditionally conjugate.\n\n## Joint posterior for Gibbs sample\n\nWrite the posterior density as usual,\n\\begin{align*}\n&p(\\mu, \\tau \\mid \\boldsymbol{y}) \\propto \\tau^{-\\alpha-1}\\exp(-\\beta/\\tau)\\\\ &\\quad \\times \\tau^{-n/2}\\exp\\left\\{-\\frac{1}{2\\tau}\\left(\\sum_{i=1}^n y_i^2 - 2\\mu \\sum_{i=1}^n y_i+n\\mu^2 \\right)\\right\\}\\\\&\\quad \\times \\exp\\left\\{-\\frac{(\\mu-\\nu)^2}{2\\omega}\\right\\} \n\\end{align*}\n\n## Recognizing distributions from posterior\n\nConsider the conditional densities of each parameter in turn (up to proportionality):\n\\begin{align*}\np(\\mu \\mid \\tau, \\boldsymbol{y}) &\\propto \\exp\\left\\{-\\frac{1}{2} \\left( \\frac{\\mu^2-2\\mu\\overline{y}}{\\tau/n} + \\frac{\\mu^2-2\\nu \\mu}{\\omega}\\right)\\right\\}\\\\\np(\\tau \\mid \\mu, \\boldsymbol{y}) & \\propto \\tau^{-n/2-\\alpha-1}\\exp\\left[-\\frac{\\left\\{\\frac{\\sum_{i=1}^n (y_i-\\mu)^2}{2} + \\beta \\right\\}}{\\tau}\\right]\n\\end{align*}\n\n## Gibs sample\nWe can simulate in turn \n\\begin{align*}\n\\mu_t \\mid \\tau_{t-1}, \\boldsymbol{y} &\\sim \\mathsf{Norm}\\left(\\frac{n\\overline{y}\\omega+\\tau \\nu}{\\tau + n\\omega}, \\frac{\\omega \\tau}{\\tau + n\\omega}\\right)\\\\\n\\tau_t \\mid \\mu_t, \\boldsymbol{y} &\\sim \\mathsf{InvGamma}\\left\\{\\frac{n}{2}+\\alpha, \\frac{\\sum_{i=1}^n (y_i-\\mu)^2}{2} + \\beta\\right\\}.\n\\end{align*}\n\n\n## Data augmentation and auxiliary variables\n\n\nWhen the likelihood $p(\\boldsymbol{y}; \\boldsymbol{\\theta})$ is intractable or costly to evaluate (e.g., mixtures, missing data, censoring), auxiliary variables are introduced to simplify calculations.\n\n\nConsider auxiliary variables $\\boldsymbol{u} \\in \\mathbb{R}^k$ such that \n$$\\int_{\\mathbb{R}^k} p(\\boldsymbol{u}, \\boldsymbol{\\theta}\\mid \\boldsymbol{y}) \\mathrm{d} \\boldsymbol{u} = p(\\boldsymbol{\\theta}\\mid \\boldsymbol{y}),$$\ni.e., the marginal distribution is that of interest, but evaluation of $p(\\boldsymbol{u}, \\boldsymbol{\\theta}; \\boldsymbol{y})$ is cheaper. \n\n## Bayesian augmentation \n\nThe data augmentation algorithm  [@Tanner.Wong:1987] consists in running a Markov chain on the augmented state space $(\\Theta, \\mathbb{R}^k)$, simulating in turn from the conditionals \n\n- $p(\\boldsymbol{u}\\mid \\boldsymbol{\\theta}, \\boldsymbol{y})$ and\n- $p(\\boldsymbol{\\theta}\\mid \\boldsymbol{u}, \\boldsymbol{y})$ \n\nFor more details and examples, see @vanDyk.Meng:2001 and @Hobert:2011.\n\n## Data augmentation: probit example\n\nConsider independent binary responses $\\boldsymbol{Y}_i$,  with\n\\begin{align*}\np_i = \\Pr(Y_i=1) = \\Phi(\\beta_0 + \\beta_1 \\mathrm{X}_{i1} + \\cdots + \\beta_p\\mathrm{X}_{ip}),\n\\end{align*}\nwhere $\\Phi$ is the distribution function of the standard Gaussian distribution. The likelihood of the probit model is \n$$L(\\boldsymbol{\\beta}; \\boldsymbol{y}) = \\prod_{i=1}^n p_i^{y_i}(1-p_i)^{1-y_i},$$\nand this prevents easy simulation. \n\n\n## Probit augmentation\n\nWe can consider a data augmentation scheme where $Y_i = \\mathsf{I}(Z_i > 0)$, where $Z_i \\sim \\mathsf{Norm}(\\mathbf{x}_i\\boldsymbol{\\beta}, 1)$, where $\\mathbf{x}_i$ is the $i$th row of the design matrix.\n\nThe augmented data likelihood is\n\\begin{align*}\np(\\boldsymbol{z}, \\boldsymbol{y} \\mid \\boldsymbol{\\beta}) &\\propto \\exp\\left\\{-\\frac{1}{2}(\\boldsymbol{z} - \\mathbf{X}\\boldsymbol{\\beta})^\\top(\\boldsymbol{z} - \\mathbf{X}\\boldsymbol{\\beta})\\right\\} \\\\&\\quad \\times \\prod_{i=1}^n \\mathsf{I}(z_i > 0)^{y_i}\\mathsf{I}(z_i \\le 0)^{1-y_i}\n\\end{align*}\n\n## Conditional distributions for probit regression\n\n\\begin{align*}\n\\boldsymbol{\\beta} \\mid \\boldsymbol{z}, \\boldsymbol{y} &\\sim \\mathsf{Norm}\\left\\{\\widehat{\\boldsymbol{\\beta}}, (\\mathbf{X}^\\top\\mathbf{X})^{-1}\\right\\}\\\\\nZ_i \\mid y_i, \\boldsymbol{\\beta} &\\sim \\begin{cases}\n\\mathsf{TruncNorm}(\\mathbf{x}_i\\boldsymbol{\\beta}, -\\infty, 0) & y_i =0 \\\\\n\\mathsf{TruncNorm}(\\mathbf{x}_i\\boldsymbol{\\beta}, 0, \\infty) & y_i =1.\n\\end{cases}\n\\end{align*}\nwith $\\widehat{\\boldsymbol{\\beta}}=(\\mathbf{X}^\\top\\mathbf{X})^{-1}\\mathbf{X}^\\top\\boldsymbol{z}$ the ordinary least square estimator.\n\n## Data augmentation with scale mixture of Gaussian\n\nThe Laplace distribution with mean $\\mu$ and scale $\\sigma$, which has density\n\\begin{align*}\nf(x; \\mu, \\sigma) = \\frac{1}{2\\sigma}\\exp\\left(-\\frac{|x-\\mu|}{\\sigma}\\right),\n\\end{align*}\ncan be expressed as a scale mixture of Gaussians, where $Y \\mid \\tau \\sim \\mathsf{La}(\\mu, \\tau)$ is equivalent to $Z \\mid \\tau \\sim \\mathsf{Norm}(\\mu, \\tau)$ and $\\tau \\sim \\mathsf{Exp}\\{(2\\sigma)^{-1}\\}$.\n\n## Joint posterior for Laplace model\n\nWith $p(\\mu, \\sigma) \\propto \\sigma^{-1}$, the joint posterior for the i.i.d. sample is\n\\begin{align*}\np(\\boldsymbol{\\tau}, \\mu, \\sigma \\mid \\boldsymbol{y}) &\\propto \\left(\\prod_{i=1}^n \\tau_i\\right)^{-1/2}\\exp\\left\\{-\\frac{1}{2}\\sum_{i=1}^n \\frac{(y_i-\\mu)^2}{\\tau_i}\\right\\} \\\\&\\quad \\times \\frac{1}{\\sigma^{n+1}}\\exp\\left(-\\frac{1}{2\\sigma}\\sum_{i=1}^n \\tau_i\\right)\n\\end{align*}\n \n\n## Conditional distributions\n\nThe conditionals for $\\mu \\mid \\cdots$ and $\\sigma \\mid \\cdots$ are, as usual, Gaussian and inverse gamma, respectively. The variances, $\\tau_j$, are conditionally independent of one another, with \n\\begin{align*}\np(\\tau_j \\mid \\mu, \\sigma, y_j) &\\propto \\tau_j^{-1/2}\\exp\\left\\{-\\frac{1}{2}\\frac{(y_j-\\mu)^2}{\\tau_j} -\\frac{1}{2} \\frac{\\tau_j}{\\sigma}\\right\\}\n\\end{align*}\n\n## Inverse transformation\n\nWith the change of variable $\\xi_j=1/\\tau_j$, we have\n\\begin{align*}\np(\\xi_j \\mid \\mu, \\sigma, y_j) &\\propto \\xi_j^{-3/2}\\exp\\left\\{-\\frac{1}{2\\sigma}\\frac{\\xi_j(y_j-\\mu)^2}{\\sigma} -\\frac{1}{2} \\frac{1}{\\xi_j}\\right\\}\\\\\n\\end{align*}\nand we recognize the Wald (or inverse Gaussian) density, where $\\xi_i \\sim \\mathsf{Wald}(\\nu_i, \\lambda)$ with $\\nu_i=\\{\\sigma/(y_i-\\mu)^2\\}^{1/2}$ and $\\lambda=\\sigma^{-1}$.\n\n\n## Bayesian LASSO \n\n@Park.Casella:2008 use this hierarchical construction to defined the Bayesian LASSO. With a model matrix $\\mathbf{X}$ whose columns are standardized to have mean zero and unit standard deviation, we may write\n\\begin{align*}\n\\boldsymbol{Y} \\mid \\mu, \\boldsymbol{\\beta}, \\sigma^2 &\\sim  \\mathsf{Norm}_n(\\mu \\boldsymbol{1}_n + \\mathbf{X}\\boldsymbol{\\beta}, \\sigma \\mathbf{I}_n)\\\\\n\\beta_j \\mid \\sigma, \\tau &\\sim \\mathsf{Norm}(0, \\sigma\\tau)\\\\\n\\tau &\\sim \\mathsf{Exp}(\\lambda/2)\n\\end{align*}\n\n## Comment about Bayesian LASSO\n\n- If we set an improper prior $p(\\mu, \\sigma) \\propto \\sigma^{-1}$, the resulting conditional distributions are all available and thus the model is amenable to Gibbs sampling.\n- The Bayesian LASSO places a Laplace penalty on the regression coefficients, with lower values of $\\lambda$ yielding more shrinkage. \n- Contrary to the frequentist setting, none of the posterior draws of $\\boldsymbol{\\beta}$ are exactly zero.\n\n\n## Visual diagnostic: trace plots\n\nDisplay the Markov chain sample path as a function of the number of iterations.\n\n- Run multiple chains to see if they converge to the same target.\n   - if not, check starting values (compare log posterior) or parameter identifiability!\n- Markov chains should look like a fat hairy caterpillar!\n- `bayesplot` and `coda` have functionalities for plots (trace plot, trace rank, correlograms, marginal densities, etc.)\n\n\n## Checking convergence with multiple chains\n\n\n![Four healthy parallel chains for parameters.](fig/catterpillar_traceplots.png)\n\n## Effective sample size\n\nAre my chains long enough to compute reliable summaries?\n\nCompute the sample size we would have with independent draws by taking\n$$\n\\mathsf{ESS} = \\frac{B}{\\left\\{1+2\\sum_{t=1}^\\infty \\gamma_t\\right\\}}\n$$ \nwhere $\\gamma_t$ is the lag $t$ autocorrelation. \n\nThe relative effective sample size is simply $\\mathsf{ESS}/B$: small values indicate pathological or inefficient samplers. \n\n## How many samples?\n\nWe want our average estimate to be reliable!\n\n- We probably need $\\mathsf{ESS}$ to be several hundred \n- We can estimate the variance of the target to know the precision\n\n- (related question: how many significant digits to report?)\n\nIn **R**, via `coda::effectiveSize()`\n\n## Estimating the variance (block method)\n\n1. Break the chain of length $B$ (after burn in) in $K$ blocks of size $\\approx K/B$.\n2. Compute the sample mean of each segment. These values form a Markov chain and should be approximately uncorrelated.\n3. Compute the standard deviation of the segments mean. Rescale by $K^{-1/2}$ to get standard error of the global mean.\n\nMore efficient methods using overlapping blocks exists.\n\n## Block means in pictures\n\n\n::: {.cell hash='bayesmod-slides4_cache/revealjs/fig-mcmc-batchmean_ad6d4b358ec6d1d13660ca7964e162ae'}\n::: {.cell-output-display}\n![Calculation of the standard error of the posterior mean using the batch method.](bayesmod-slides4_files/figure-revealjs/fig-mcmc-batchmean-1.png){#fig-mcmc-batchmean width=960}\n:::\n:::\n\n\n\n## Cautionary warning about stationarity\n\nBatch means only works if the chain is sampling from the stationary distribution! \n\nThe previous result (and any estimate) will be unreliable and biased if the chain is not (yet) sampling from the posterior.\n\n## Lack of stationarity\n\n\n\n::: {.cell hash='bayesmod-slides4_cache/revealjs/fig-badstart_257e578f5eedd4b4be1f5fc7c317e689'}\n::: {.cell-output-display}\n![Traceplots of three Markov chains for the same target with different initial values for the first 500 iterations (left) and trace rank plot after discarding these (right). The latter is indicative of the speed of mixing.](bayesmod-slides4_files/figure-revealjs/fig-badstart-1.png){#fig-badstart width=960}\n:::\n:::\n\n\n## Potential scale reduction statistic \n\nThe Gelman--Rubin diagnostic, denoted $\\widehat{R}$, is obtained by running multiple chains and considering the difference between within-chain and between-chains variances,\n\n\\begin{align*}\n\\widehat{R} = \\left(\\frac{\\mathsf{Va}_{\\text{within}}(B-1) + \\mathsf{Va}_{\\text{between}}}{B\\mathsf{Va}_{\\text{within}}}\\right)^{1/2}\n\\end{align*}\n\n\nAny value of $\\widehat{R}$ larger 1 is indicative of problems of convergence.\n\n## Bad chains\n\n\n\n::: {.cell hash='bayesmod-slides4_cache/revealjs/fig-rhat_060bbd4bfc11f61db5b7687d06982fff'}\n::: {.cell-output-display}\n![Two pairs of Markov chains: the top ones seem stationary, but with different modes and  $\\widehat{R} \\approx 3.4$. The chains on the right hover around zero, but do not appear stable, with $\\widehat{R} \\approx 1.6$.](bayesmod-slides4_files/figure-revealjs/fig-rhat-1.png){#fig-rhat width=960}\n:::\n:::\n\n\n\n## Posterior predictive checks\n\n1. For each of the $B$ draws from the posterior, simulate $n$ observations from the posterior predictive $p(\\widetilde{\\boldsymbol{y}} \\mid \\boldsymbol{y})$\n2. For each replicate, compute a summary statistics (median, quantiles, std. dev., etc.) \n3. Compare it with the same summary computed for the sample $\\boldsymbol{y}$.\n\n## Posterior predictive checks\n\n\n::: {.cell hash='bayesmod-slides4_cache/revealjs/fig-posterior-pred-check_f9ea4d5c6c625a550eb307daba865703'}\n::: {.cell-output-display}\n![Posterior predictive checks for the standard deviation (top) and density of posterior draws (bottom) for hierarchical Poisson model with individual effects (left) and simpler model with only conditions (right).](fig/fig-posterior-pred-check.png){#fig-posterior-pred-check width=672}\n:::\n:::\n\n\n## Log pointwise predictive density\n\nConsider the expected value of the log observation-wise log density with respect to the posterior distribution $p(\\boldsymbol{\\theta} \\mid \\boldsymbol{y})$, \n\\begin{align*}\n\\mathsf{LPPD}_i = \\mathsf{E}_{\\boldsymbol{\\theta} \\mid \\boldsymbol{y}} \\left\\{ \\log p(y_i \\mid \\boldsymbol{\\theta})\\right\\},\n\\end{align*}\n \nThe higher the value of $\\mathsf{LPPD}_i$, the better the fit for that observation.\n\n## Widely available information criterion \n\nTo build an information criterion, we add a penalization factor that approximates the effective number of parameters in the model, with\n\\begin{align*}\nn\\mathsf{WAIC} = -\\sum_{i=1}^n \\mathsf{LPPD}_i + \\sum_{i=1}^n \\mathsf{Va}_{\\boldsymbol{\\theta} \\mid \\boldsymbol{y}}\\{\\log p(y_i \\mid \\boldsymbol{\\theta})\\}\n\\end{align*} \nwhere we use again the empirical variance to compute the rightmost term.\n\nSmaller values of $\\mathsf{WAIC}$ are better.\n\n## Bayesian leave-one-out cross validation\n\nIn Bayesian setting, we can use the leave-one-out predictive density\n$$p(y_i \\mid \\boldsymbol{y}_{-i})$$ as a measure of predictive accuracy. the \n\nWe can use importance sampling to approximate the latter.\n\nRequirement: need to keep track of the log likelihood of each observation for each posterior draw ($B \\times n$ values).\n\n## LOO-CV diagnostics\n\nWe can draw $B$ samples from  $p(\\widetilde{y} \\mid \\boldsymbol{y}_{-i})$ and compute the rank of $y_i$.\n\nUnder perfect calibration, ranks should be uniform.\n\n## Leave-one-out with quantile-quantile plots\n\n\n::: {.cell hash='bayesmod-slides4_cache/revealjs/fig-posterior-loocv_e3e7de28567c7771b3b9d18b515c1c55'}\n::: {.cell-output-display}\n![Quantile-quantile plots based on leave-one-out cross validation for model for the hierarchical Poisson model fitted to the Upworthy data with the individual random effects (left) and without (right).](fig/fig-loocv-qqplots.png){#fig-posterior-loocv width=672}\n:::\n:::\n\n\n\n\n\n## References\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}