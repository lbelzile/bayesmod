{
  "hash": "5b3407909f84982146d5565121425252",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Bayesian modelling\"\nauthor: \"LÃ©o Belzile\"\nsubtitle: \"Markov chain Monte Carlo\"\ndate: today\ndate-format: YYYY\neval: true\necho: true\ncache: true\nbibliography: MATH80601A.bib\nformat:\n  revealjs:\n    slide-number: true\n    preview-links: auto\n    theme: [simple, hecmontreal.scss]\n    title-slide-attributes:\n      data-background-color: \"#ff585d\"\n    logo: \"fig/logo_hec_montreal_bleu_web.png\"\n---\n\n\n\n\n\n## Bayesian inference beyond conjugate models\n\nHow to circumvent the problem of intractable posteriors?\n\n- simulation-based methods: accept-reject, Markov chain Monte Carlo, particle filters, etc.\n- deterministic methods: (integrated nested) Laplace approximations, variational Bayes, expectation propagation, etc.\n\nWe focus on Monte Carlo methods.\n\n\n## Markov chains\n\nPlain ordinary Monte Carlo is great, but few algorithms are generic enough to be useful in complex high-dimensional problems.\n\nWe will instead typically build Markov chains that target an invariant stationary distribution. \n\n\n## Caveats?\n\nMarkov chain Monte Carlo methods generate **correlated** draws. \n\n**Questions**: \n\n1. can we use them as ordinary independent samples? \n2. what is the price to pay?\n\nWe need to do a little theoretical detour to answer these questions.\n\n## Stationarity and Markov property\n\n\nA stochastic process is **(weakly) stationary** if \n\n- the distribution of $\\{X_1, \\ldots, X_t\\}$ is the same as that of $\\{X_{n+1}, \\ldots X_{t+n}\\}$ for any value of $n$ and given $t$.\n\nA stochastic process is **Markov** if \n\n- it satisfies the Markov property: given the current state of the chain, the future only depends on the current state and not on the past.\n\n## Autoregressive process of order 1\n\nConsider a first-order autoregressive process, or $\\mathsf{AR}(1)$, \n\n$$Y_t = \\mu + \\phi(Y_{t-1} - \\mu) + \\varepsilon_t,$$ where \n\n- $\\phi$ is the lag-one correlation, \n- $\\mu$ the global mean\n- $\\varepsilon_t$ is an iid innovation with mean zero and variance $\\sigma^2$\n\nIf $|\\phi| < 1$, the process is stationary, otherwise variance increases with $t$\n\n## Variance of a stationary distribution\n\nFor a correlated sequence, the variance of the stationary distribution is \\begin{align*}\n\\tau^2 = \\mathsf{Va}(Y_t) + 2 \\sum_{k=1}^\\infty \\mathsf{Co}(Y_t, Y_{t-k}).\n\\end{align*}\n\n - for i.i.d. data, $\\tau^2 = \\mathsf{Va}(Y_t)$\n - for stationary $\\mathsf{AR}(1)$ process, we get $\\sigma^2/(1-\\phi^2)$ (geometric series)\n\n## Variance of sample average\n\nIntuitively, a sample of correlated observations carries less information than an independent sample of draws.\n\nWe want the variance of the sample average, which is\n\\begin{align*}\n\\mathsf{Va}\\left(\\overline{Y}_T\\right) = \\frac{1}{T}\\sum_{t=1}^T \\mathsf{Va}(Y_t) + \\frac{2}{T} \\sum_{t=1}^{T-1}\\sum_{s = t+1}^T \\mathsf{Co}(Y_t, Y_s).\n\\end{align*}\n\nIf the process is stationary, the covariances at lag $k$ are the same regardless of the time index and the unconditional variance is constant.\n\n## Variance of sample average, redux\n\nIf a central limit theorem applies, the limiting variance of the sample mean simplifies to\n\\begin{align*}\n\\lim_{T \\to \\infty} T\\mathsf{Va}\\left(\\overline{Y}_T\\right) = \\tau^2 \\left\\{1+2\\sum_{t=1}^\\infty \\gamma_t\\right\\}.\n\\end{align*}\nwhich is a function of \n\n- the unconditional variance $\\tau^2$\n- the lag-$k$ autocorrelation $\\mathsf{Cor}(Y_{t}, Y_{t+k})=\\gamma_k$\n\n## Correlogram\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Correlogram of two two Markov chains. These plots, often called acf or autocorrelation functions, show the lag-k sample autocorrelation against lag number.](bayesmod-slides4_files/figure-revealjs/fig-correlograms-1.png){#fig-correlograms width=960}\n:::\n:::\n\n\n\n## Variance of sample mean of AR(1)\n\nThe lag-$k$ correlation of the stationary autoregressive process of order 1 is $\\phi^k$, so $$T\\mathsf{Va}\\left(\\overline{Y}_T\\right)=\\sigma^2(1+\\phi)/(1-\\phi).$$\n\nFor an independent sample, we have $$T\\mathsf{Va}\\left(\\overline{Y}_T\\right)=\\sigma^2/(1-\\phi^2).$$ \n\n\n\n\n## Inefficiency curve for AR(1) {.smaller}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Left: scaled asymptotic variance of the sample mean for AR(1) (full line) and independent observations with the same marginal variance (dashed). Right: variance ratio for positive correlations.](bayesmod-slides4_files/figure-revealjs/fig-ar1-variance-1.png){#fig-ar1-variance width=768}\n:::\n:::\n\n\n\n\nTo get the same precision for the mean of $\\mathsf{AR}(1)$ process with $\\phi \\approx 0.75$ than with i.i.d. data, we would need 9 times as many observations.\n\n## Morale of the story \n\nThe price to pay for having correlated samples is \n\n:::{style=\"font-size: 2em; color: #ff585d; text-align: center\"}\n\n**inefficiency**\n\n:::\n\nThe higher the autocorrelation, the larger the variability of our estimators.\n\n## When can we use Markov chains?\n\nIf a Markov chain is irreducible and acyclic, it has a unique stationary distribution.\n\n- irreducibility: means that the chain can move from anywhere to anywhere, so it doesn't get stuck in part of the space forever.\n- acyclic: cyclical chains loop around and visit periodically a state\n\nErgodic theorem is our guarantee of convergence.\n\n## Examples\n\nConsider discrete Markov chains over the integers $1, 2, 3$ with transition matrices\n\n$$\nP_1 = \\begin{pmatrix}\n0.5 & 0.3 & 0.2 \\\\\n0 & 0.4 & 0.6 \\\\\n0 & 0.5 & 0.5\n\\end{pmatrix}, \n\\quad \nP_2 = \\begin{pmatrix}\n0 & 0 & 1 \\\\\n1 & 0 & 0 \\\\\n0 & 1 & 0\n\\end{pmatrix}.\n$$\nChain 1 is reducible to $\\{2, 3\\}$, chain 2 is cyclical.\n\n## Convergence of Markov chains\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Discrete Markov chain on integers from 1 to 5, with traceplot of 1000 first iterations (left) and running mean plots of sample proportion of each state visited (right).](bayesmod-slides4_files/figure-revealjs/fig-discrete-markov-chain-1.png){#fig-discrete-markov-chain width=960}\n:::\n:::\n\n\n\n## Markov chain Monte Carlo\n\nWe consider simulating from a distribution with associated density function $\\propto p(\\boldsymbol{\\theta})$.\n\n- known up to a normalizing factor not depending on $\\boldsymbol{\\theta}$.\n\nWe use $q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}^*)$ as transition kernel to generate proposals.\n\n\n## Metropolis--Hastings algorithm \n\nStarting from an initial value $\\boldsymbol{\\theta}_0$:\n\n1.  draw a proposal value $\\boldsymbol{\\theta}_t^{\\star} \\sim q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}_{t-1})$.\n2.  Compute the acceptance ratio $$\n    R = \\frac{p(\\boldsymbol{\\theta}_t^{\\star})}{p(\\boldsymbol{\\theta}_{t-1})}\\frac{q(\\boldsymbol{\\theta}_{t-1} \\mid \\boldsymbol{\\theta}_t^{\\star} )}{q(\\boldsymbol{\\theta}_t^{\\star} \\mid \\boldsymbol{\\theta}_{t-1})}\n    $$\n3.  With probability $\\min\\{R, 1\\}$, accept the proposal and set $\\boldsymbol{\\theta}_t \\gets \\boldsymbol{\\theta}_t^{\\star}$, otherwise set the value to the previous state, $\\boldsymbol{\\theta}_t \\gets \\boldsymbol{\\theta}_{t-1}$.\n\n## Interpretation\n\n- If $R>1$, the proposal has higher density and we always accept the move. \n- If we reject the move, the Markov chain stays at the current value, which induces autocorrelation.\n- Since the acceptance probability depends only on the density through ratios, normalizing factors of $p$ and $q$ cancel out.\n\n\n## Symmetric proposals and random walk\n\nIf the proposal is symmetric, the ratio of proposal densities is $$q(\\boldsymbol{\\theta}_{t-1} \\mid \\boldsymbol{\\theta}_t^{\\star} ) / q(\\boldsymbol{\\theta}_t^{\\star} \\mid \\boldsymbol{\\theta}_{t-1}) = 1.$$\n\nCommon examples include random walk proposals\n$$\\boldsymbol{\\theta}_t^{\\star} \\gets \\boldsymbol{\\theta}_{t-1} + \\tau Z, \\qquad Z$$ where $Z$ is a mean zero, variance one random variable.\n\n## Independent proposals\n\n- If we pick instead a global proposal, we must ensure that $q$ samples in far regions (recall rejection sampling), otherwise ...\n- Good proposals include heavy tailed distribution such as Student-$t$ with small degrees of freedom, centered at the maximum a posteriori $\\widehat{\\boldsymbol{\\theta}}$ and with scale matrix $-\\mathbf{H}^{-1}(\\boldsymbol{\\theta}_t^{\\star})$, where $\\mathbf{H}(\\cdot)$ is the Hessian of the log posterior.\n\n\n## Upworthy data example\n\nWe model the Poisson rates for headlines with questions or not. Our model is\n\\begin{align*}\nY_{i} &\\sim \\mathsf{Po}(n_i\\lambda_i), \\qquad (i=1,2)\\\\\n\\lambda_1 &= \\exp(\\beta + \\kappa) \\\\\n\\lambda_2 &= \\exp(\\beta) \\\\\n\\beta & \\sim \\mathsf{No}(\\log 0.01, 1.5) \\\\\n\\kappa &\\sim \\mathsf{No}(0, 1)\n\\end{align*}\n\n## Implementation details: data and containers\n\nIn regression models, scale inputs if possible.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(upworthy_question, package = \"hecbayes\")\n# Compute sufficient statistics\ndata <- upworthy_question |>\n  dplyr::group_by(question) |>\n  dplyr::summarize(ntot = sum(impressions),\n                   y = sum(clicks))\n# Create containers for MCMC\nniter <- 1e4L\nchain <- matrix(0, nrow = niter, ncol = 2L)\ncolnames(chain) <- c(\"beta\",\"kappa\")\n```\n:::\n\n\n\n\n## Implementation details: log posterior function\n\nPerform all calculations on the log scale to avoid numerical overflow! \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Code log posterior as sum of log likelihood and log prior\nloglik <- function(par, counts = data$y, offset = data$ntot, ...){\n  lambda <- exp(c(par[1] + log(offset[1]), par[1] + par[2] + log(offset[2])))\n sum(dpois(x = counts, lambda = lambda, log = TRUE))\n}\n# Note common signature of function\nlogprior <- function(par, ...){\n  dnorm(x = par[1], mean = log(0.01), sd = 1.5, log = TRUE) +\n    dnorm(x = par[2], log = TRUE)\n}\nlogpost <- function(par, ...){\n  loglik(par, ...) + logprior(par, ...)\n}\n```\n:::\n\n\n\n## Implementation details: proposals\n\nUse good starting values for your Markov chains, such as maximum a posteriori.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compute maximum a posteriori (MAP)\nmap <- optim(\n  par = c(-4, 0.07),\n  fn = logpost,\n  control = list(fnscale = -1),\n  offset = data$ntot,\n  counts = data$y,\n  hessian = TRUE)\n# Use MAP as starting value\ncur <- map$par\n# Compute logpost_cur - we can keep track of this to reduce calculations\nlogpost_cur <- logpost(cur)\n# Proposal covariance\ncov_map <- -2*solve(map$hessian)\nchol <- chol(cov_map)\n```\n:::\n\n\n\n## Implementation details: Metropolis--Hastings algorithm\n\nUse seed for reproducibility, do not compute posterior twice, compute log of acceptance ratio. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(80601)\nnaccept <- 0L\nfor(i in seq_len(niter)){\n  # Multivariate normal proposal - symmetric random walk\n  prop <- c(rnorm(n = 2) %*% chol + cur)\n  logpost_prop <- logpost(prop)\n  logR <- logpost_prop - logpost_cur\n  if(logR > -rexp(1)){\n    cur <- prop\n    logpost_cur <- logpost_prop\n    naccept <- naccept + 1L\n  }\n  chain[i,] <- cur\n}\n```\n:::\n\n\n\n## Implementation details: analysis of output\n\nNeed specialized methods to compute standard errors of the posterior mean.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Posterior summaries\nsummary(coda::as.mcmc(chain))\n# Computing standard errors using batch means\nsqrt(diag(mcmc::olbm(chain, batch.length = niter/40)))\n```\n:::\n\n\n\n```\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean       SD  Naive SE Time-series SE\nbeta  -4.51268 0.001697 1.697e-05      6.176e-05\nkappa  0.07075 0.002033 2.033e-05      9.741e-05\n\n2. Quantiles for each variable:\n\n          2.5%      25%      50%      75%    97.5%\nbeta  -4.51591 -4.51385 -4.51273 -4.51154 -4.50929\nkappa  0.06673  0.06933  0.07077  0.07212  0.07463\n```\n\n\n## References\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}