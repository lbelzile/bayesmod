{
  "hash": "a32f8f679aefec20df89ebb6f095f706",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Bayesian modelling\"\nauthor: \"LÃ©o Belzile\"\nsubtitle: \"Markov chain Monte Carlo: Gibbs sampling\"\ndate: today\ndate-format: \"[Last compiled] dddd MMM D, YYYY\"\neval: true\necho: true\ncache: true\nbibliography: MATH80601A.bib\nformat:\n  revealjs:\n    slide-number: true\n    preview-links: auto\n    theme: [simple, hecmontreal.scss]\n    title-slide-attributes:\n      data-background-color: \"#ff585d\"\n    logo: \"fig/logo_hec_montreal_bleu_web.png\"\n---\n\n\n\n\n\n\n## Reminder: Metropolis--Hastings algorithm \n\nStarting from an initial value $\\boldsymbol{\\theta}_0$:\n\n1.  draw a proposal value $\\boldsymbol{\\theta}_t^{\\star} \\sim q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}_{t-1})$.\n2.  Compute the acceptance ratio $$\n    R = \\frac{p(\\boldsymbol{\\theta}_t^{\\star})}{p(\\boldsymbol{\\theta}_{t-1})}\\frac{q(\\boldsymbol{\\theta}_{t-1} \\mid \\boldsymbol{\\theta}_t^{\\star} )}{q(\\boldsymbol{\\theta}_t^{\\star} \\mid \\boldsymbol{\\theta}_{t-1})}\n    $$\n3.  With probability $\\min\\{R, 1\\}$, accept the proposal and set $\\boldsymbol{\\theta}_t \\gets \\boldsymbol{\\theta}_t^{\\star}$, otherwise set the value to the previous state, $\\boldsymbol{\\theta}_t \\gets \\boldsymbol{\\theta}_{t-1}$.\n\n## Calculations\n\n\nWe compute the log of the acceptance ratio, $\\ln R$, to avoid numerical overflow, with the log posterior difference\n$$\n\\ln \\left\\{\\frac{p(\\boldsymbol{\\theta}_t^{\\star})}{p(\\boldsymbol{\\theta}_{t-1})}\\right\\} = \\ell(\\boldsymbol{\\theta}_t^{\\star}) + \\ln p(\\boldsymbol{\\theta}_t^{\\star}) - \\ell(\\boldsymbol{\\theta}_{t-1}) - \\ln p(\\boldsymbol{\\theta}_{t-1}) \n$$\n\n\nCompare the value of $\\ln R$ (if less than zero) to $\\log(U)$, where $U \\sim \\mathsf{unif}(0,1)$. \n\n\n## What proposal?\n\nThe *independence* Metropolis--Hastings uses a global proposal $q$ which does not depend on the current state (typically centered at the MAP)\n\nThis may be problematic with multimodal targets.\n\nThe Gaussian random walk takes $\\boldsymbol{\\theta}_t^{\\star} =\\boldsymbol{\\theta}_{t-1}+ \\sigma_\\text{p}Z$, where $Z \\sim \\mathsf{Gauss}(0,1)$ and $\\sigma_\\text{p}$ is the proposal standard deviation. *Random walks* allow us to explore the space.\n\n\n\n## Burn in\n\nWe are guaranteed to reach stationarity with Metropolis--Hastings, but it may take a large number of iterations...\n\nOne should discard initial draws during a **burn in** or warmup period if the chain has not reached stationarity. Ideally, use good starting value to reduce waste.\n\nWe can also use the warmup period to adapt the variance of the proposal.\n\n## Goldilock principle and proposal variance\n\nMixing of the chain requires just the right variance (not too small nor too large).\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Example of traceplot with proposal variance that is too small (top), adequate (middle) and too large (bottom).](bayesmod-slides5_files/figure-revealjs/fig-goldilock-trace-1.png){#fig-goldilock-trace width=960}\n:::\n:::\n\n\n\n## Correlograms for Goldilock \n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Correlogram for the three Markov chains.](bayesmod-slides5_files/figure-revealjs/fig-goldilock-correlogram-1.png){#fig-goldilock-correlogram width=960}\n:::\n:::\n\n\n\n\n## Tuning Markov chain Monte Carlo\n\n- Outside of starting values, the variance of the proposal has a huge impact on the asymptotic variance.\n- We can adapt the variance during warmup by increasing/decreasing proposal variance (if acceptance rate is too large/small).\n- We can check this via the acceptance rate (how many proposals are accepted).\n\n## Optimal acceptance rates \n\nThe following rules were derived for Gaussian targets under idealized situations.\n\n- In 1D, rule of thumb is an acceptance rate of $0.44$ is optimal, and this ratio decreases to $0.234$ when $D \\geq 2$ [@Sherlock:2013] for random walk Metropolis--Hastings.\n- Proposals for $D$-variate update should have proposal variance of roughly $(2.38^2/d)\\times \\boldsymbol{\\Sigma}$, where $\\boldsymbol{\\Sigma}$ is the posterior variance.\n- For MALA (see later), we get $0.574$ rather than $0.234$\n\n## Block update or one parameter at a time?\n\nAs with any accept-reject, proposals become inefficient when the dimension $D$ increase.\n\nThis is the **curse of dimensionality**.\n\nUpdating parameters in turn \n\n- increases acceptance rate (with clever proposals), \n- but also leads to more autocorrelation between parameters\n\n## Solutions for strongly correlated coefficients\n\n- Reparametrize the model to decorrelate variables (orthogonal parametrization).\n- Block updates: draw correlated parameters together \n   - using the chain history to learn the correlation, if necessary\n\n\n\n## Parameter transformation\n\nParameters may be bounded, e.g. $\\theta_i \\in [a,b]$.\n\n- We can ignore this and simply discard proposals outside of the range, by setting the log posterior at $-\\infty$ outside $[a,b]$\n- We can do a transformation, e.g., $\\log \\theta_i$ if $\\theta_i > 0$ and perform a random walk on the unconstrained space: don't forget Jacobians for $q(\\cdot)$!\n- Another alternative is to use truncated proposals (useful with more complex algorithms like MALA)\n\n\n## Efficient proposals: MALA {.smaller}\n\nThe Metropolis-adjusted Langevin algorithm (MALA) uses a Gaussian random walk proposal $$\\boldsymbol{\\theta}^{\\star}_t \\sim \\mathsf{Gauss}\\{\\mu(\\boldsymbol{\\theta}_{t-1}), \\tau^2\\mathbf{A}\\},$$ with mean $$\\mu(\\boldsymbol{\\theta}_{t-1})=\\boldsymbol{\\theta}_{t-1} + \\mathbf{A}\\eta \\nabla \\log p(\\boldsymbol{\\theta}_{t-1} \\mid \\boldsymbol{y}),$$ and variance $\\tau^2\\mathbf{A}$, for some mass matrix $\\mathbf{A}$, tuning parameter $\\tau>0$. \n\nThe parameter $\\eta < 1$ is a learning rate. This is akin to a Newton algorithm, so beware if you are far from the mode (where the gradient is typically large)!\n\n\n## Higher order proposals\n\nFor a single parameter update $\\theta$, a Taylor series expansion of the log posterior around the current value suggests using as proposal density a Gaussian approximation with [@Rue.Held:2005]\n\n- mean $\\mu_{t-1} = \\theta_{t-1} - f'(\\theta_{t-1})/f''(\\theta_{t-1})$ and \n- precision $\\tau^{-2} = -f''(\\theta_{t-1})$\n\nWe need $f''(\\theta_{t-1})$ to be negative!\n\nThis gives **local adaption** relative to MALA (global variance).\n\n## Higher order and moves\n\nFor MALA and cie., we need to compute the density of the proposal also for the reverse move for the expansion starting from the proposal $\\mu(\\boldsymbol{\\theta}_{t}^\\star)$.\n\nThese methods are more efficient than random walk Metropolis--Hastings, but they require the gradient and the hessian (can be obtained analytically using autodiff, or numerically).\n\n## Modelling individual headlines of **Upworthy** example\n\nThe number of conversions `nclick` is binomial with sample size $n_i=$`nimpression`.\n\nSince $n_i$ is large, the sample average `nclick`/`nimpression` is approximately Gaussian, so write\n\n\\begin{align*}\nY_i &\\sim \\mathsf{Gauss}(\\mu, \\sigma^2/n_i)\\\\\n\\mu &\\sim \\mathsf{trunc. Gauss}(0.01, 0.1^2, 0, 1) \\\\\n\\sigma &\\sim \\mathsf{expo}(0.7)\n\\end{align*}\n\n## MALA: data set-up\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(upworthy_question, package = \"hecbayes\")\n# Select data for a single question\nqdata <- upworthy_question |>\n  dplyr::filter(question == \"yes\") |>\n  dplyr::mutate(y = clicks/impressions,\n                no = impressions)\n```\n:::\n\n\n\n## MALA: define functions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create functions with the same signature (...) for the algorithm\nlogpost <- function(par, data, ...){\n  mu <- par[1]; sigma <- par[2]\n  no <- data$no\n  y <- data$y\n  if(isTRUE(any(sigma <= 0, mu < 0, mu > 1))){\n    return(-Inf)\n  }\n  dnorm(x = mu, mean = 0.01, sd = 0.1, log = TRUE) +\n  dexp(sigma, rate = 0.7, log = TRUE) + \n  sum(dnorm(x = y, mean = mu, sd = sigma/sqrt(no), log = TRUE))\n}\n```\n:::\n\n\n\n## MALA: compute gradient of log posterior\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlogpost_grad <- function(par, data, ...){\n   no <- data$no\n  y <- data$y\n  mu <- par[1]; sigma <- par[2]\n  c(sum(no*(y-mu))/sigma^2 -(mu - 0.01)/0.01,\n    -length(y)/sigma + sum(no*(y-mu)^2)/sigma^3 -0.7\n  )\n}\n```\n:::\n\n\n\n\n## MALA: compute maximum a posteriori\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Starting values - MAP\nmap <- optim(\n  par = c(mean(qdata$y), 0.5),\n  fn = function(x){-logpost(x, data = qdata)},\n  gr = function(x){-logpost_grad(x, data = qdata)},  \n  hessian = TRUE,\n  method = \"BFGS\")\n# Check convergence \nlogpost_grad(map$par, data = qdata)\n```\n:::\n\n\n\n## MALA: starting values and mass matrix\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set initial parameter values\ncurr <- map$par \n# Compute a mass matrix\nAmat <- solve(map$hessian)\n# Cholesky root - for random number generation\ncholA <- chol(Amat)\n```\n:::\n\n\n\n## MALA: containers and setup\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create containers for MCMC\nB <- 1e4L # number of iterations\nwarmup <- 1e3L # adaptation period\nnpar <- 2L\nprop_sd <- rep(1, npar) # tuning parameter\nchains <- matrix(nrow = B, ncol = npar)\ndamping <- 0.8\nacceptance <- attempts <- 0 \ncolnames(chains) <- names(curr) <- c(\"mu\",\"sigma\")\n# Proposal variance proportional to inverse hessian at MAP\nprop_var <- diag(prop_sd) %*% Amat %*% diag(prop_sd)\n```\n:::\n\n\n\n## MALA: sample proposal with Newton step\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor(i in seq_len(B + warmup)){\n  ind <- pmax(1, i - warmup)\n  # Compute the proposal mean for the Newton step\n  prop_mean <- c(curr + damping * \n     Amat %*% logpost_grad(curr, data = qdata))\n  # prop <- prop_sd * c(rnorm(npar) %*% cholA) + prop_mean\n  prop <- c(mvtnorm::rmvnorm(\n    n = 1,\n    mean = prop_mean, \n    sigma = prop_var))\n#  [...]\n```\n:::\n\n\n\n## MALA: reverse step\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  # Compute the reverse step\n  curr_mean <- c(prop + damping * \n     Amat %*% logpost_grad(prop, data = qdata))\n  # log of ratio of bivariate Gaussian densities\n  logmh <- mvtnorm::dmvnorm(\n    x = curr, mean = prop_mean, \n    sigma = prop_var, \n    log = TRUE) - \n    mvtnorm::dmvnorm(\n      x = prop, \n      mean = curr_mean, \n      sigma = prop_var, \n      log = TRUE) + \n  logpost(prop, data = qdata) - \n    logpost(curr, data = qdata)\n```\n:::\n\n\n\n## MALA: Metropolis--Hastings ratio\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  if(logmh > log(runif(1))){\n    curr <- prop\n    acceptance <- acceptance + 1L\n  }\n  attempts <- attempts + 1L\n  # Save current value\n  chains[ind,] <- curr\n```\n:::\n\n\n\n## MALA: adaptation\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  if(i %% 100 & i < warmup){\n    # Check acceptance rate and increase/decrease variance\n    out <- hecbayes::adaptive(\n      attempts = attempts, # counter for number of attempts\n      acceptance = acceptance, \n      sd.p = prop_sd, #current proposal standard deviation\n      target = 0.574) # target acceptance rate\n    prop_sd <- out$sd # overwrite current std.dev\n    acceptance <- out$acc # if we change std. dev, this is set to zero\n    attempts <- out$att # idem, otherwise unchanged\n    prop_var <- diag(prop_sd) %*% Amat %*% diag(prop_sd)\n  }\n} # End of MCMC for loop\n```\n:::\n\n\n\n\n\n## Gibbs sampling\n\nThe Gibbs sampling algorithm builds a Markov chain by iterating through a sequence of conditional distributions. \n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Sampling trajectory for a bivariate target using Gibbs sampling.](bayesmod-slides5_files/figure-revealjs/fig-Gibbs-steps-1.png){#fig-Gibbs-steps width=960}\n:::\n:::\n\n\n\n\n## Gibbs sampler\n\nSplit the parameter vector $\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta} \\subseteq \\mathbb{R}^p$ into $m \\leq p$ blocks, $$\\boldsymbol{\\theta}^{[j]}\\quad j=1, \\ldots, m$$\nsuch that, conditional on the remaining components of the parameter vector $\\boldsymbol{\\theta}^{-[j]}$, the conditional posterior $$p(\\boldsymbol{\\theta}^{[j]} \\mid \\boldsymbol{\\theta}^{-[j]}, \\boldsymbol{y})$$\nis from a known distribution from which we can easily simulate.\n\n## Gibbs sampling update\n\nAt iteration $t$, we can update each block in turn: note that the $k$th block uses the partially updated state\n\\begin{align*}\n\\boldsymbol{\\theta}^{-[k]\\star} = (\\boldsymbol{\\theta}_{t}^{[1]}, \\ldots, \\boldsymbol{\\theta}_{t}^{[k-1]},\\boldsymbol{\\theta}_{t-1}^{[k+1]}, \\boldsymbol{\\theta}_{t-1}^{[m]})\n\\end{align*}\nwhich corresponds to the current value of the parameter vector after the updates. \n\n## Notes on Gibbs sampling\n\n- Special case of Metropolis--Hastings with conditional density as proposal $q$. \n- The benefit is that all proposals get accepted, $R=1$!\n- No tuning parameter, but parametrization matters.\n- Automatic acceptance does not equal efficiency.\n\nTo check the validity of the Gibbs sampler, see the methods proposed in @Geweke:2004.\n\n\n## Efficiency of Gibbs sampling\n\nAs the dimension of the parameter space increases, and as the correlation between components becomes larger, the efficiency of the Gibbs sampler degrades\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Trace plots (top) and correlograms (bottom) for the first component of a Gibbs sampler with $d=20$ equicorrelated Gaussian variates with correlation $\\rho=0.9$ (left) and $d=3$ with equicorrelation $\\rho=0.5$ (right).](bayesmod-slides5_files/figure-revealjs/fig-gibbs-normal-1.png){#fig-gibbs-normal width=960}\n:::\n:::\n\n\n\n## Gibbs sampling requires work!\n\n- You need to determine all of the relevant conditional distributions, which often relies on setting conditionally conjugate priors. \n- In large models with multiple layers, full conditionals may only depend on a handful of parameters (via directed acyclic graph and moral graph of the model; not covered).\n\n\n## Example of Gibbs sampling\n\nConsider independent and identically distributed observations, with\n\\begin{align*}\nY_i &\\sim \\mathsf{Gauss}(\\mu, \\tau), \\qquad i=1, \\ldots, n) \n\\\\\\mu &\\sim \\mathsf{Gauss}(\\nu, \\omega)\\\\\n\\tau &\\sim \\mathsf{inv. gamma}(\\alpha, \\beta)\n\\end{align*}\n\nThe joint posterior is not available in closed form, but the independent priors for the mean and variance of the observations are conditionally conjugate.\n\n## Joint posterior for Gibbs sample\n\nWrite the posterior density as usual,\n\\begin{align*}\n&p(\\mu, \\tau \\mid \\boldsymbol{y}) \\propto \\tau^{-\\alpha-1}\\exp(-\\beta/\\tau)\\\\ &\\quad \\times \\tau^{-n/2}\\exp\\left\\{-\\frac{1}{2\\tau}\\left(\\sum_{i=1}^n y_i^2 - 2\\mu \\sum_{i=1}^n y_i+n\\mu^2 \\right)\\right\\}\\\\&\\quad \\times \\exp\\left\\{-\\frac{(\\mu-\\nu)^2}{2\\omega}\\right\\} \n\\end{align*}\n\n## Recognizing distributions from posterior\n\nConsider the conditional densities of each parameter in turn (up to proportionality):\n\\begin{align*}\np(\\mu \\mid \\tau, \\boldsymbol{y}) &\\propto \\exp\\left\\{-\\frac{1}{2} \\left( \\frac{\\mu^2-2\\mu\\overline{y}}{\\tau/n} + \\frac{\\mu^2-2\\nu \\mu}{\\omega}\\right)\\right\\}\\\\\np(\\tau \\mid \\mu, \\boldsymbol{y}) & \\propto \\tau^{-n/2-\\alpha-1}\\exp\\left[-\\frac{\\left\\{\\frac{\\sum_{i=1}^n (y_i-\\mu)^2}{2} + \\beta \\right\\}}{\\tau}\\right]\n\\end{align*}\n\n## Gibs sample\nWe can simulate in turn \n\\begin{align*}\n\\mu_t \\mid \\tau_{t-1}, \\boldsymbol{y} &\\sim \\mathsf{Gauss}\\left(\\frac{n\\overline{y}\\omega+\\tau \\nu}{\\tau + n\\omega}, \\frac{\\omega \\tau}{\\tau + n\\omega}\\right)\\\\\n\\tau_t \\mid \\mu_t, \\boldsymbol{y} &\\sim \\mathsf{inv. gamma}\\left\\{\\frac{n}{2}+\\alpha, \\frac{\\sum_{i=1}^n (y_i-\\mu)^2}{2} + \\beta\\right\\}.\n\\end{align*}\n\n\n## Data augmentation and auxiliary variables\n\n\nWhen the likelihood $p(\\boldsymbol{y}; \\boldsymbol{\\theta})$ is intractable or costly to evaluate (e.g., mixtures, missing data, censoring), auxiliary variables are introduced to simplify calculations.\n\n\nConsider auxiliary variables $\\boldsymbol{U} \\in \\mathbb{R}^k$ such that \n$$\\int_{\\mathbb{R}^k} p(\\boldsymbol{U}, \\boldsymbol{\\theta}\\mid \\boldsymbol{y}) \\mathrm{d} \\boldsymbol{U} = p(\\boldsymbol{\\theta}\\mid \\boldsymbol{y}),$$\ni.e., the marginal distribution is that of interest, but evaluation of $p(\\boldsymbol{U}, \\boldsymbol{\\theta}; \\boldsymbol{y})$ is cheaper. \n\n## Bayesian augmentation \n\nThe data augmentation algorithm  [@Tanner.Wong:1987] consists in running a Markov chain on the augmented state space $(\\Theta, \\mathbb{R}^k)$, simulating in turn from the conditionals \n\n- $p(\\boldsymbol{U}\\mid \\boldsymbol{\\theta}, \\boldsymbol{y})$ and\n- $p(\\boldsymbol{\\theta}\\mid \\boldsymbol{U}, \\boldsymbol{y})$ \n\nFor more details and examples, see @vanDyk.Meng:2001 and @Hobert:2011.\n\n## Data augmentation: probit example\n\nConsider independent binary responses $\\boldsymbol{Y}_i$,  with\n\\begin{align*}\np_i = \\Pr(Y_i=1) = \\Phi(\\beta_0 + \\beta_1 \\mathrm{X}_{i1} + \\cdots + \\beta_p\\mathrm{X}_{ip}),\n\\end{align*}\nwhere $\\Phi$ is the distribution function of the standard Gaussian distribution. The likelihood of the probit model is \n$$L(\\boldsymbol{\\beta}; \\boldsymbol{y}) = \\prod_{i=1}^n p_i^{y_i}(1-p_i)^{1-y_i},$$\nand this prevents easy simulation. \n\n\n## Probit augmentation\n\nWe can consider a data augmentation scheme where $Y_i = \\mathrm{I}(Z_i > 0)$, where $Z_i \\sim \\mathsf{Gauss}(\\mathbf{x}_i\\boldsymbol{\\beta}, 1)$, where $\\mathbf{x}_i$ is the $i$th row of the design matrix.\n\nThe augmented data likelihood is\n\\begin{align*}\np(\\boldsymbol{z}, \\boldsymbol{y} \\mid \\boldsymbol{\\beta}) &\\propto \\exp\\left\\{-\\frac{1}{2}(\\boldsymbol{z} - \\mathbf{X}\\boldsymbol{\\beta})^\\top(\\boldsymbol{z} - \\mathbf{X}\\boldsymbol{\\beta})\\right\\} \\\\&\\quad \\times \\prod_{i=1}^n \\mathrm{I}(z_i > 0)^{y_i}\\mathrm{I}(z_i \\le 0)^{1-y_i}\n\\end{align*}\n\n## Conditional distributions for probit regression\n\n\\begin{align*}\n\\boldsymbol{\\beta} \\mid \\boldsymbol{z}, \\boldsymbol{y} &\\sim \\mathsf{Gauss}\\left\\{\\widehat{\\boldsymbol{\\beta}}, (\\mathbf{X}^\\top\\mathbf{X})^{-1}\\right\\}\\\\\nZ_i \\mid y_i, \\boldsymbol{\\beta} &\\sim \\begin{cases}\n\\mathsf{trunc. Gauss}(\\mathbf{x}_i\\boldsymbol{\\beta}, -\\infty, 0) & y_i =0 \\\\\n\\mathsf{trunc. Gauss}(\\mathbf{x}_i\\boldsymbol{\\beta}, 0, \\infty) & y_i =1.\n\\end{cases}\n\\end{align*}\nwith $\\widehat{\\boldsymbol{\\beta}}=(\\mathbf{X}^\\top\\mathbf{X})^{-1}\\mathbf{X}^\\top\\boldsymbol{z}$ the ordinary least square estimator.\n\n## Data augmentation with scale mixture of Gaussian\n\nThe Laplace distribution with mean $\\mu$ and scale $\\sigma$ has density\n\\begin{align*}\nf(x; \\mu, \\sigma) = \\frac{1}{2\\sigma}\\exp\\left(-\\frac{|x-\\mu|}{\\sigma}\\right),\n\\end{align*}\nand can be expressed as a scale mixture of Gaussians, where $Y \\mid \\tau \\sim \\mathsf{Laplace}(\\mu, \\tau)$ is equivalent to $Z \\mid \\tau \\sim \\mathsf{Gauss}(\\mu, \\tau)$ and $\\tau \\sim \\mathsf{expo}\\{(2\\sigma)^{-1}\\}$.\n\n## Joint posterior for Laplace model\n\nWith $p(\\mu, \\sigma) \\propto \\sigma^{-1}$, the joint posterior for the i.i.d. sample is\n\\begin{align*}\np(\\boldsymbol{\\tau}, \\mu, \\sigma \\mid \\boldsymbol{y}) &\\propto \\left(\\prod_{i=1}^n \\tau_i\\right)^{-1/2}\\exp\\left\\{-\\frac{1}{2}\\sum_{i=1}^n \\frac{(y_i-\\mu)^2}{\\tau_i}\\right\\} \\\\&\\quad \\times \\frac{1}{\\sigma^{n+1}}\\exp\\left(-\\frac{1}{2\\sigma}\\sum_{i=1}^n \\tau_i\\right)\n\\end{align*}\n \n\n## Conditional distributions\n\nThe conditionals for $\\mu \\mid \\cdots$ and $\\sigma \\mid \\cdots$ are, as usual, Gaussian and inverse gamma, respectively. The variances, $\\tau_j$, are conditionally independent of one another, with \n\\begin{align*}\np(\\tau_j \\mid \\mu, \\sigma, y_j) &\\propto \\tau_j^{-1/2}\\exp\\left\\{-\\frac{1}{2}\\frac{(y_j-\\mu)^2}{\\tau_j} -\\frac{1}{2} \\frac{\\tau_j}{\\sigma}\\right\\}\n\\end{align*}\n\n## Inverse transformation\n\nWith the change of variable $\\xi_j=1/\\tau_j$, we have\n\\begin{align*}\np(\\xi_j \\mid \\mu, \\sigma, y_j) &\\propto \\xi_j^{-3/2}\\exp\\left\\{-\\frac{1}{2\\sigma}\\frac{\\xi_j(y_j-\\mu)^2}{\\sigma} -\\frac{1}{2} \\frac{1}{\\xi_j}\\right\\}\\\\\n\\end{align*}\nand we recognize the Wald (or inverse Gaussian) density, where $\\xi_i \\sim \\mathsf{Wald}(\\nu_i, \\lambda)$ with $\\nu_i=\\{\\sigma/(y_i-\\mu)^2\\}^{1/2}$ and $\\lambda=\\sigma^{-1}$.\n\n\n## Bayesian LASSO \n\n@Park.Casella:2008 use this hierarchical construction to defined the Bayesian LASSO. With a model matrix $\\mathbf{X}$ whose columns are standardized to have mean zero and unit standard deviation, we may write\n\\begin{align*}\n\\boldsymbol{Y} \\mid \\mu, \\boldsymbol{\\beta}, \\sigma^2 &\\sim  \\mathsf{Gauss}_n(\\mu \\boldsymbol{1}_n + \\mathbf{X}\\boldsymbol{\\beta}, \\sigma \\mathbf{I}_n)\\\\\n\\beta_j \\mid \\sigma, \\tau &\\sim \\mathsf{Gauss}(0, \\sigma\\tau)\\\\\n\\tau &\\sim \\mathsf{expo}(\\lambda/2)\n\\end{align*}\n\n## Comment about Bayesian LASSO\n\n- If we set an improper prior $p(\\mu, \\sigma) \\propto \\sigma^{-1}$, the resulting conditional distributions are all available and thus the model is amenable to Gibbs sampling.\n- The Bayesian LASSO places a Laplace penalty on the regression coefficients, with lower values of $\\lambda$ yielding more shrinkage. \n- Contrary to the frequentist setting, none of the posterior draws of $\\boldsymbol{\\beta}$ are exactly zero.\n\n## Summary\n\n- Gibbs sampling is a special case of Metropolis--Hastings algorithm that leads to acceptance\n- We need to get the conditional distribution\n\n\n## References\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}