{
  "hash": "36008c7939d2c8224fadd86bb54ae2f4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Solution 3\"\ndraft: false\n---\n\n\n\n\n## Exercise 3.1\n\nConsider a simple random sample of size $n$ from the Wald distribution, with density\n\\begin{align*}\nf(y; \\nu, \\lambda) = \\left(\\frac{\\lambda}{2\\pi y^{3}}\\right)^{1/2} \\exp\\left\\{ - \\frac{\\lambda (y-\\nu)^2}{2\\nu^2y}\\right\\}\\mathrm{I}(y > 0)\n\\end{align*}\nfor location $\\nu >0$ and shape $\\tau>0$. \n\na. Show that the joint prior\n$$ p(\\lambda) \\sim \\mathsf{gamma}(\\alpha, \\beta), \\quad p(1/\\nu \\mid \\lambda) \\sim  \\mathsf{Gauss}(\\mu, \\tau^{-1}\\lambda^{-1}),$$ the product of a gamma and a reciprocal Gaussian, is conjugate for the Wald distribution parameters.\nb. Derive the parameters of the posterior distribution and provide an interpretation of the prior parameters. *Hint*: write down the posterior parameters as a weighted average of data-dependent quantities and prior parameters.\nc. Derive the marginal posterior $p(\\lambda)$.\n\n\n\n::: {.solution}\n\na. To show conjugacy, we must prove that the posterior is of the same family. Multiplying the likelihood with the joint prior and expanding the squares in the exponential terms, we get\n\\begin{align*}\np(\\lambda, \\nu \\mid \\boldsymbol{y}) &\\propto \\frac{\\lambda^{(n+1)/2+\\alpha-1}}{\\nu^2}\\exp(-\\lambda \\beta) \\exp\\left[ -\\frac{\\lambda}{2}\\left\\{\\frac{\\tau}{\\nu^{2}}-2\\frac{\\tau\\mu}{\\nu} + \\tau\\mu^2 +\\frac{t_1(\\boldsymbol{y})}{\\nu^2} -  \\frac{2n}{\\nu} + t_2(\\boldsymbol{y})\\right\\}\\right] \\\\& \\propto \\frac{\\lambda^{(n+1)/2+\\alpha-1}}{\\nu^2}\\exp(-\\lambda \\beta) \\exp\\left[ -\\frac{\\lambda}{2}\\left\\{\\frac{\\tau + t_1(\\boldsymbol{y})}{\\nu^2} - 2\\frac{\\tau\\mu+n}{\\nu} + \\tau\\mu^2 + t_2(\\boldsymbol{y})\\right\\} \\right]\n\\\\& \\propto \\frac{\\lambda^{(n+1)/2+\\alpha-1}}{\\nu^2}\\exp\\left[-\\lambda \\left\\{\\beta + \\frac{c_3-c_1c_2^2}{2}\\right\\}\\right] \\exp\\left\\{ -\\frac{\\lambda c_1}{2}\\left(\\nu^{-1} - c_2\\right)^2\\right\\} \n\\end{align*}\nwhere $c_1=\\{\\tau + t_1(\\boldsymbol{y})\\}$, $c_2 =(\\tau\\mu+n)/c_1$ and $c_3 =\\tau\\mu^2 + t_2(\\boldsymbol{y})$.\n\nb. We see that the joint posterior as the product of two densities, say $q(\\lambda \\mid \\boldsymbol{y})p(1/\\nu \\mid \\lambda)$; $q(\\lambda \\mid \\boldsymbol{y})$ is the density of a gamma distribution with shape $a = (n+1)/2+\\alpha$ and rate $b=\\beta + (c_3-c_1c_2^2)/2$, whereas the other is a reciprocal Gaussian with mean parameter $c_2$ and precision $\\lambda c_1$. $\\mathsf{gamma}\\left\\{(n+1)/2+\\alpha\\right\\}$\n\nc. To get the marginal $p(\\lambda \\mid \\boldsymbol{y})$, we need to integrate with respect to $\\nu$. Making the change of variable $\\mu = 1/\\nu$, we recover a Gaussian kernel\n\\begin{align*}\np(\\lambda \\mid \\boldsymbol{y}) &= \\lambda^{a-1}\\exp(-b\\lambda)\\int_{\\mathbb{R}}\\exp\\left\\{ -\\frac{\\lambda c_1}{2}\\left(\\mu - c_2\\right)^2\\right\\}  \\mathrm{d} \\mu \n\\\\&\\propto \\lambda^{a-1}\\exp(-b\\lambda) \\lambda^{-1/2}\n\\end{align*}\nso we conclude that, marginally, $\\lambda \\sim \\mathsf{gamma}(n+ \\alpha, b)$.\n\n:::\n\n## Exercise 3.2\n\nConsider the Rayleigh distribution with scale $\\sigma>0$. It's density is\n$$f(y; \\sigma) = \\frac{y}{\\sigma^2} \\exp\\left(-\\frac{y^2}{2\\sigma^2}\\right)\\mathrm{I}(y \\geq 0).$$\n\nDerive the Fisher information matrix and use it to obtain Jeffrey's prior for $\\sigma$. Determine whether the prior is proper.\n\n\n::: {.solution}\n\nThe log likelihood for a sample of size one is \n\\begin{align*}\n\\ell(\\sigma) = \\log(y) - 2\\log(\\sigma) - \\frac{y^2}{2\\sigma^2}\n\\end{align*}\nand the negative of the Hessian is \n\\begin{align*}\n\\jmath(\\sigma) = -\\frac{\\partial^2 \\ell(\\sigma)}{\\partial \\sigma^2} = -\\frac{2}{\\sigma^2} + \\frac{3y^2}{\\sigma^4}\n\\end{align*}\nTo compute the Fisher information, we need the second moment of the Rayleigh distribution,\n\\begin{align*}\n\\mathsf{E}(Y^2) &= \\int_0^\\infty \\frac{y^3}{\\sigma^2}\\exp\\left(-\\frac{y^2}{2\\sigma^2}\\right)\\mathrm{d} y\\\\&= 2\\sigma^2 \\int_0^\\infty u \\exp(-u) \\mathrm{d} u\n\\\\&= 2\\sigma^2\n\\end{align*}\nwhere we made the change of variable $u= 0.5y^2\\sigma^{-2}$, $\\mathrm{d} u = y\\sigma^{-2}\\mathrm{d} y$ and recovered the expected value of a unit exponential distribution.\n\nThe Fisher information is $\\imath(\\sigma) = \\mathsf{E}\\{\\jmath(\\sigma)\\}=-2/\\sigma^2 + 6/\\sigma^2 = 3/\\sigma^2$. Jeffrey's prior for the scale, $p(\\sigma) =|\\imath(\\sigma)|^{1/2}$, is proportional to $\\sigma^{-1}$ and thus improper.\n\n:::\n\n\n## Exercise 3.3\n\nConsider a binomial model with an unknown probability of successes $\\theta \\in [0,1]$ model. Suppose your prior guess for $\\theta$ has mean $0.1$ and standard deviation $0.2$\n\nUsing moment matching, return values for the parameters of the conjugate beta prior corresponding to your opinion.\n\n\nPlot the resulting beta prior and compare it with a truncated Gaussian distribution on the unit interval with location $\\mu=0.1$ and scale $\\sigma=0.2$.^[Note that the parameters of the truncated Gaussian distribution do not correspond to moments!]\n\n\n::: {.solution}\n\nThe beta distribution has expected value $\\alpha/(\\alpha+\\beta)$ and variance $\\alpha\\beta(\\alpha+\\beta)^{-2}(\\alpha+\\beta+1)^{-1}$.\n\nSince the system of equations is nonlinear, we need to solve numerically to find the two unknown value of the parameters or else simply substitute $\\beta = \\alpha (1-\\mu)/\\mu$ in the equation for the variance.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbeta_moments <- function(par, mean, variance){\n  alpha <- par[1]\n  beta <- par[2]\n  c(alpha/(alpha+beta) - mean,\n    alpha*beta/(alpha+beta)^2/(alpha+beta+1) - variance)\n}\n# Numerical root finding algorithm\n# We need to give good starting values\nrootSolve::multiroot(f = beta_moments,\n                     start = c(0.1, 0.8),\n                     positive = TRUE,\n                     mean = 0.1, \n                     variance = 0.04)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$root\n[1] 0.125 1.125\n\n$f.root\n[1] 5.504125e-12 4.298423e-12\n\n$iter\n[1] 5\n\n$estim.precis\n[1] 4.901274e-12\n```\n\n\n:::\n\n```{.r .cell-code}\nalpha <- uniroot(f = function(alpha, mean = 0.1, variance = 0.04){\n  beta <- alpha*(1-mean)/mean\n  alpha*beta/(alpha+beta)^2/(alpha+beta+1) - variance}, \n  interval = c(1e-4, 1))$root\nbeta <- alpha*(1-0.1)/0.1\nc(alpha = alpha, beta = beta)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nalpha  beta \n0.125 1.125 \n```\n\n\n:::\n:::\n\n\n\n\nand we find $\\alpha = 0.125$ and $\\beta=1.125$.\n\nLet $a = -\\mu/\\sigma$ and $b = (1-\\mu)/\\sigma$ denote the standardized lower and upper bounds, respectively. The density of the truncated Gaussian with location $\\mu$ and scale $\\sigma$ on the unit interval is\n\\begin{align*}\nf(x; \\mu, \\sigma) = \\frac{1}{\\sigma}\\frac{\\phi\\left(\\frac{x - \\mu}{\\sigma}\\right)}{\\Phi(b) - \\Phi(a)},\n\\end{align*}\nwhere $\\phi$ is the density of a standard Gaussian $\\mathsf{Gauss}(0,1)$ and $\\Phi$ the corresponding distribution function.\n\n<!--\nand we can easily obtain the formulae for the first two moments (e.g., Wikipedia). Let $a = -\\mu/\\sigma$ and $b = (1-\\mu)/\\sigma$ denote the centered bounds; then\n\\begin{align*}\n\\mathsf{E}(Y) &= \\mu - \\sigma\\frac{\\phi(b) - \\phi(a) }{\\Phi(b) - \\Phi(a)} \\\\\n\\mathsf{Va}(Y) & = \\sigma\\left[1 - \\frac{b\\phi(b) - \\phi(a)}{\\Phi(b) - \\Phi(a)} - \\left\\{\\frac{\\phi(b) - \\phi(a) }{\\Phi(b) - \\Phi(a)}\\right\\}^2\\right]\n\\end{align*}\nwe have reasonable guess for starting values\n\n-->\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Beta (full line) and truncated Gaussian (dashed line) prior densities.](03-solution_files/figure-html/fig-priors-match-1.png){#fig-priors-match width=672}\n:::\n:::\n\n\n\n\nThe beta distribution, while matching the moments, is implying very low chance of success with a mode at zero. By contrast, the truncated Gaussian (which does not have mean $\\mu$ and variance $\\sigma^2$) has the mode at $\\mu=0.1$. Which one is preferable depends on the context; we could also match the parameters of the truncated Gaussian.\n\n:::\n\n\n<!-- ## Exercise 3.4 -->\n\n<!-- Reproduce the analysis of Example 3.5 (Should you phrase your headline as a question?) of the [course notes](https://lbelzile.github.io/MATH80601A/priors.html#exm-poisson-upworthy-question) using the `upworthy_question` data from the [`hecbayes` package](https://github.com/lbelzile/hecbayes). -->\n\n\n\n<!-- :::{.solution} -->\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n<!-- ::: -->\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}