{
  "hash": "c456bbcf97acf6cfb61a26cf891ca3f6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Solution 9\"\n---\n\n\n\n\n\n## Exercise 9.1\n\nWe consider the accuracy of the Gaussian approximation to the posterior of a Bernoulli likelihood $Y_i \\sim \\mathsf{binom}(1, \\theta)$ with $y =\\sum_{i=1}^n y_i = \\lfloor 0.1n\\rfloor$ successes out of $n$ trials, i.e., if 10% of the realizations are successes. To do so,\n\n\na. Obtain a closed-form expression maximum a posteriori and the hessian of the log posterior for a conjugate $\\mathsf{beta}(a,b)$ prior.\nb. Plug in the approximation with a $\\theta \\sim \\mathsf{beta}(1/2, 1/2)$ prior for $n\\in\\{10, 100, 1000\\}$ and plot the Gaussian approximation along with the true posterior.\nc. Repeat this with $\\vartheta = \\log(\\theta) - \\log(1-\\theta)$, using a change of variable. Is the approximation better for small $n$? Discuss.\nd. Compute the marginal likelihood and compare the approximation with the true value.\n\n:::{.solution}\n\na. Consider the beta kernel $k(\\theta) = \\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}$ for $\\alpha, \\beta>0.$ \nThe unnormalized log posterior to optimize and the negative of it's Hessian matrix are\n\\begin{align*}\n\\log k(\\theta) &\\propto (\\alpha-1)\\log \\theta + (\\beta-1) \\log (1-\\theta),\\\\\n\\frac{\\partial \\log k(\\theta)}{\\partial \\theta} &\\propto \\frac{\\alpha-1}{\\theta} - \\frac{\\beta-1}{1-\\theta},\\\\\n-\\frac{\\partial^2 \\log k(\\theta)}{\\partial \\theta^2} &= \\frac{\\alpha-1}{\\theta^2} + \\frac{\\beta-1}{(1-\\theta)^2}.\n\\end{align*}\nBy equating the gradient to zero, we find that the posterior mode is $\\widehat{\\theta} = (\\alpha-1)/(\\alpha+\\beta-2)$ if $\\alpha>1, \\beta>1.$ \n\n:::\n## Exercise 9.2\n\nConsider a simple random sample from a Bernoulli of size $n$ with $y$ successes and a $\\mathsf{beta}(a, b)$ conjugate prior. Compute the Laplace approximation to the posterior mean for samples of size $n=10, 20, 50, 100$ and $y/n \\in \\{0.1, 0.25, 0.5,1\\}$ and $a=b=1.$\n\n\n:::{.solution}\n\n<!--Example 8.3 of Bove and Held (2020) -->\nWe can apply Laplace's approximation and write\n\\begin{align*}\n \\mathsf{E}_{{\\Theta} \\mid {Y}}(\\theta) &=  \\frac{\\int g({\\theta}) p({y} \\mid {\\theta}) p( {\\theta}) \\mathrm{d} {\\theta}}{\\int p({y} \\mid {\\theta})p({\\theta}) \\mathrm{d} {\\theta}}\n\\end{align*}\n\nThe Hessian evaluated at the mode gives $\\mathbf{H}=(\\alpha+\\beta-2)^3/\\{(\\alpha-1)(\\beta-1)\\}.$ To simplify notation, take $\\alpha = y+a$ and $\\beta = n-y+b$: the Laplace approximation is therefore\n\\begin{align*}\n \\widehat{\\mathsf{E}}_{{\\Theta} \\mid {Y}}(\\theta)&= \\left( \\frac{(\\alpha + \\beta-2)^{3}}{(\\alpha-1)(\\beta-1)}\\frac{\\alpha(\\beta-1)}{(\\alpha + \\beta-1)^{3}}\\right)^{1/2} \\widehat{\\theta}_g \\left( \\frac{\\widehat{\\theta}_g}{\\widehat{\\theta}_{\\mathrm{MAP}}}\\right)^{\\alpha-1} \\left( \\frac{1-\\widehat{\\theta}_g}{1-\\widehat{\\theta}_{\\mathrm{MAP}}}\\right)^{\\beta-1} \n \\\\& =\n\\frac{\\alpha^{\\alpha+1/2}}{(\\alpha-1)^{\\alpha-1/2}}\\frac{(\\alpha + \\beta-2)^{\\alpha + \\beta-1/2}}{(\\alpha + \\beta-1)^{\\alpha + \\beta+1/2}}\n \\end{align*}\nand taking $a=b=1$, we retrieve\n\\begin{align*}\n\\widehat{\\mathsf{E}}_{{\\Theta} \\mid {Y}}(\\theta)  = \\frac{(y+1)^{y+3/2}n^{n+3/2}}{(y+1/2)^{y+1/2}(n+1)^{n+5/2}}.\n\\end{align*}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Posterior mean of beta-binomial\nlap_post_mean <- function(alpha, beta){\n  exp((alpha+0.5)*log(alpha) - (alpha-0.5)*log(alpha-1) + \n        (alpha + beta - 0.5)*log(alpha + beta -2) - \n        (alpha + beta + 0.5)*log(alpha +  beta - 1))\n}\nns <- c(10L, 20L, 50L, 100L)\nyfrac <- c(0.1, 0.25, 0.5,1)\napprox <- array(dim = c(4,4,2), dimnames = list(n = ns, \"y/n\" = yfrac, approx = c(\"laplace\",\"exact\")))\nfor(i in seq_along(ns)){\n  for(j in seq_along(yfrac)){\n    alpha <- ns[i]*yfrac[j] + 1\n    beta <- ns[i]*(1-yfrac[j]) + 1\n approx[i,j,] <-  c(lap_post_mean(alpha, beta), alpha/(alpha+beta)) \n  }\n}\napprox\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n, , approx = laplace\n\n     y/n\nn           0.1      0.25       0.5         1\n  10  0.1718567 0.2917720 0.4968663 0.9090909\n  20  0.1378987 0.2728091 0.4991449 0.9523810\n  50  0.1156562 0.2596352 0.4998555 0.9803922\n  100 0.1079133 0.2549075 0.4999632 0.9900990\n\n, , approx = exact\n\n     y/n\nn           0.1      0.25 0.5         1\n  10  0.1666667 0.2916667 0.5 0.9166667\n  20  0.1363636 0.2727273 0.5 0.9545455\n  50  0.1153846 0.2596154 0.5 0.9807692\n  100 0.1078431 0.2549020 0.5 0.9901961\n```\n\n\n:::\n\n```{.r .cell-code}\n# Percentage relative error\nround(100*(approx[,,1]-approx[,,2])/approx[,,2], 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     y/n\nn       0.1  0.25    0.5      1\n  10  3.114 0.036 -0.627 -0.826\n  20  1.126 0.030 -0.171 -0.227\n  50  0.235 0.008 -0.029 -0.038\n  100 0.065 0.002 -0.007 -0.010\n```\n\n\n:::\n:::\n\n\n\n:::\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}