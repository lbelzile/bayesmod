{
  "hash": "bd1d67554f09c5de2e10f5d5b73338b7",
  "result": {
    "markdown": "---\ntitle: \"Solution 2\"\n---\n\n\n## Exercise 2.1\n\nConsider a simple random sample of size $n$ from the Wald distribution, with density\n\\begin{align*}\nf(y; \\nu, \\lambda) = \\left(\\frac{\\lambda}{2\\pi y^{3}}\\right)^{1/2} \\exp\\left\\{ - \\frac{\\lambda (y-\\nu)^2}{2\\nu^2y}\\right\\}\\mathrm{I}(y > 0)\n\\end{align*}\nfor location $\\nu >0$ and shape $\\tau>0$. \n\na. Write down the likelihood and show the posterior only depends on the data through the sufficient statistics $\\sum_{i=1}^n y_i$ and $\\sum_{i=1} y_i^{-1}$.\nb. Show that the joint prior\n$$ p(\\lambda) \\sim \\mathsf{Ga}(\\alpha, \\beta), \\quad p(1/\\nu \\mid \\lambda) \\sim  \\mathsf{No}(\\mu, \\tau^{-1}\\lambda^{-1}),$$ the product of a gamma and a reciprocal Gaussian, is conjugate for the Wald distribution parameters.\nc. Derive the parameters of the posterior distribution and provide an interpretation of the prior parameters. *Hint*: write down the posterior parameters as a weighted average of data-dependent quantities and prior parameters.\nd. Derive the marginal posterior $p(\\lambda)$.\n\n\n\n::: {.solution}\nThe log likelihood for an independent and identically distributed sample is\n\\begin{align*}\n\\ell(\\nu, \\lambda) = \\frac{n}{2} \\ln(\\lambda) - \\frac{3}{2} \\sum_{i=1}^n \\ln(y_i) - \\frac{\\lambda}{2\\nu^2} \\sum_{i=1}^n (y_i - 2\\nu + \\nu^2/y_i)\n\\end{align*}\nand we readily see that the model is an exponential family with sufficient statistics $t_1(\\boldsymbol{y}) = \\sum_{i=1}^n y_i$ and $t_2(\\boldsymbol{y}) = \\sum_{i=1}^n y_i^{-1}$.\n\nThe joint prior is of the form\n\\begin{align*}\np(\\lambda, \\nu) &\\propto \\lambda^{\\alpha-1}\\exp(-\\lambda \\beta) \\\\\np(\\nu \\mid \\lambda) & \\propto \\frac{(\\lambda \\tau)^{1/2}}{\\nu^2}\\exp\\left\\{-\\frac{\\lambda\\tau }{2}(\\nu^{-1}-\\mu)^2\\right\\},\n\\end{align*}\nwhere the last step follows from a change of variable.\nTo show conjugacy, we must prove that the posterior is of the same family. Multiplying the likelihood with the joint prior and expanding the squares in the exponential terms, we get\n\\begin{align*}\np(\\lambda, \\nu \\mid \\boldsymbol{y}) &\\propto \\frac{\\lambda^{(n+1)/2+\\alpha-1}}{\\nu^2}\\exp(-\\lambda \\beta) \\exp\\left[ -\\frac{\\lambda}{2}\\left\\{\\frac{\\tau}{\\nu^{2}}-2\\frac{\\tau\\mu}{\\nu} + \\tau\\mu^2 +\\frac{t_1(\\boldsymbol{y})}{\\nu^2} -  \\frac{2n}{\\nu} + t_2(\\boldsymbol{y})\\right\\}\\right] \\\\& \\propto \\frac{\\lambda^{(n+1)/2+\\alpha-1}}{\\nu^2}\\exp(-\\lambda \\beta) \\exp\\left[ -\\frac{\\lambda}{2}\\left\\{\\frac{\\tau + t_1(\\boldsymbol{y})}{\\nu^2} - 2\\frac{\\tau\\mu+n}{\\nu} + \\tau\\mu^2 + t_2(\\boldsymbol{y})\\right\\} \\right]\n\\\\& \\propto \\frac{\\lambda^{(n+1)/2+\\alpha-1}}{\\nu^2}\\exp\\left[-\\lambda \\left\\{\\beta + \\frac{c_3-c_1c_2^2}{2}\\right\\}\\right] \\exp\\left\\{ -\\frac{\\lambda c_1}{2}\\left(\\frac{1}{\\nu^2} - \\frac{2c_2}{\\nu} + c_2^2\\right)\\right\\} \n\\end{align*}\nwhere $c_1=\\{\\tau + t_1(\\boldsymbol{y})\\}$, $c_2 =(\\tau\\mu+n)/c_1$ and $c_3 =\\tau\\mu^2 + t_2(\\boldsymbol{y})$.\n\nTO BE CONTINUED\n\n:::\n\n## Exercise 2.2\n\nConsider the Rayleigh distribution with scale $\\sigma>0$. It's density is\n$$f(y; \\sigma) = \\frac{y}{\\sigma^2} \\exp\\left(-\\frac{y^2}{2\\sigma^2}\\right)\\mathrm{I}(x \\geq 0).$$\n\nDerive the Fisher information matrix and use it to obtain Jeffrey's prior for $\\sigma$. Determine whether the prior is proper.\n\n\n::: {.solution}\n\nThe log likelihood for a sample of size one is \n\\begin{align*}\n\\ell(\\sigma) = \\log(y) - 2\\log(\\sigma) - \\frac{y^2}{2\\sigma^2}\n\\end{align*}\nand the negative of the Hessian is \n\\begin{align*}\n\\jmath(\\sigma) = -\\frac{\\partial \\ell(\\sigma)}{\\partial \\sigma} = -\\frac{2}{\\sigma^2} + \\frac{3y^2}{\\sigma^4}\n\\end{align*}\nTo compute the Fisher information, we need the second moment of the Rayleigh distribution,\n\\begin{align*}\n\\mathsf{E}(Y^2) &= \\int_0^\\infty \\frac{y^3}{\\sigma^2}\\exp\\left(-\\frac{y^2}{2\\sigma^2}\\right)\\mathrm{d} y\\\\&= 2\\sigma^2 \\int_0^\\infty u \\exp(-u) \\mathrm{d} u\n\\\\&= 2\\sigma^2\n\\end{align*}\nwhere we made the change of variable $u= 0.5y^2\\sigma^{-2}$, $\\mathrm{d} u = y\\sigma^{-2}\\mathrm{d} y$ and recovered the expected value of a unit exponential distribution.\n\nThe Fisher information is $\\imath(\\sigma) = \\mathsf{E}\\{\\jmath(\\sigma)\\}=-2/\\sigma^2 + 6/\\sigma^2 = 3/\\sigma^2$. Jeffrey's prior for the scale, $p(\\sigma) =|\\imath(\\sigma)|^{1/2}$, is proportional to $\\sigma^{-1}$ and thus improper.\n\n:::\n\n\n## Exercise 2.3\n\nConsider a binomial model with an unknown probability of successes $\\theta \\in [0,1]$ model. Suppose your prior guess for $\\theta$ has mean $0.1$ and standard deviation $0.2$\n\nUsing moment matching, return values for the parameters of the conjugate beta prior corresponding to your opinion.\n\n\nPlot the resulting beta prior and compare it with a truncated Gaussian distribution on the unit interval with location $\\mu=0.1$ and scale $\\sigma=0.2$.^[Note that the parameters of the truncated Gaussian distribution do not correspond to moments!]\n\n\n::: {.solution}\n\nThe beta distribution has expected value $\\alpha/(\\alpha+\\beta)$ and variance $\\alpha\\beta(\\alpha+\\beta)^{-2}(\\alpha+\\beta+1)^{-1}$.\n\nSince the system of equations is nonlinear, we need to solve numerically to find the two unknown value of the parameters or else simply substitute $\\beta = \\alpha (1-\\mu)/\\mu$ in the equation for the variance.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbeta_moments <- function(par, mean, variance){\n  alpha <- par[1]\n  beta <- par[2]\n  c(alpha/(alpha+beta) - mean,\n    alpha*beta/(alpha+beta)^2/(alpha+beta+1) - variance)\n}\n# Numerical root finding algorithm\n# We need to give good starting values\nrootSolve::multiroot(f = beta_moments,\n                     start = c(0.1, 0.8),\n                     positive = TRUE,\n                     mean = 0.1, \n                     variance = 0.04)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$root\n[1] 0.125 1.125\n\n$f.root\n[1] 5.504125e-12 4.298423e-12\n\n$iter\n[1] 5\n\n$estim.precis\n[1] 4.901274e-12\n```\n:::\n\n```{.r .cell-code}\nalpha <- uniroot(f = function(alpha, mean = 0.1, variance = 0.04){\n  beta <- alpha*(1-mean)/mean\n  alpha*beta/(alpha+beta)^2/(alpha+beta+1) - variance}, \n  interval = c(1e-4, 1))$root\nbeta <- alpha*(1-0.1)/0.1\nc(alpha = alpha, beta = beta)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nalpha  beta \n0.125 1.125 \n```\n:::\n:::\n\n\nand we find $\\alpha = 0.125$ and $\\beta=1.125$.\n\nLet $a = -\\mu/\\sigma$ and $b = (1-\\mu)/\\sigma$ denote the standardized lower and upper bounds, respectively. The density of the truncated Gaussian with location $\\mu$ and scale $\\sigma$ on the unit interval is\n\\begin{align*}\nf(x; \\mu, \\sigma) = \\frac{1}{\\sigma}\\frac{\\phi\\left(\\frac{x - \\mu}{\\sigma}\\right)}{\\Phi(b) - \\Phi(a)},\n\\end{align*}\nwhere $\\phi$ is the density of a standard Gaussian $\\mathsf{No}(0,1)$ and $\\Phi$ the corresponding distribution function.\n\n<!--\nand we can easily obtain the formulae for the first two moments (e.g., Wikipedia). Let $a = -\\mu/\\sigma$ and $b = (1-\\mu)/\\sigma$ denote the centered bounds; then\n\\begin{align*}\n\\mathsf{E}(Y) &= \\mu - \\sigma\\frac{\\phi(b) - \\phi(a) }{\\Phi(b) - \\Phi(a)} \\\\\n\\mathsf{Va}(Y) & = \\sigma\\left[1 - \\frac{b\\phi(b) - \\phi(a)}{\\Phi(b) - \\Phi(a)} - \\left\\{\\frac{\\phi(b) - \\phi(a) }{\\Phi(b) - \\Phi(a)}\\right\\}^2\\right]\n\\end{align*}\nwe have reasonable guess for starting values\n\n-->\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Beta (full line) and truncated Gaussian (dashed line) prior densities.](02-solution_files/figure-html/fig-priors-match-1.png){#fig-priors-match width=672}\n:::\n:::\n\n\nThe beta distribution, while matching the moments, is implying very low chance of success with a mode at zero. By contrast, the truncated Gaussian (which does not have mean $\\mu$ and variance $\\sigma^2$) has the mode at $\\mu=0.1$. Which one is preferable depends on the context; we could also match the parameters of the truncated Gaussian.\n\n:::\n\n## Exercise 2.4\n\nReplicate the analysis of Example 2.6 (Should you phrase your headline as a question?) of the [course notes](https://lbelzile.github.io/MATH80601A/priors.html) using the `upworthy_question` data from the [`hecbayes` package](https://github.com/lbelzile/hecbayes).\n\n\n:::{.solution}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(upworthy_question, package = \"hecbayes\")\n# Prior parameters\nalpha <- 2.5 # shape\nbeta <- 0.04 # rate\n\n# Pool data from all questions (only total counts matter)\nsummary_stats <- upworthy_question |>\n  dplyr::group_by(question) |>\n  dplyr::summarize(\n    total_impressions = sum(impressions),\n    total_clicks = sum(clicks)) |>\n  dplyr::ungroup() |>\n  as.vector()\n# Extract total number of successes out of trials\n# Impressions here serve as count\nn_yes <- summary_stats$total_impressions[1]\ny_yes <- summary_stats$total_clicks[1]\nn_no <-  summary_stats$total_impressions[2]\ny_no <- summary_stats$total_clicks[2]\n# Generate posterior sample draws\n# Since likelihood and priors are independent, \n# so are the posteriors for the rates. \n# We can draw independently from each.\nset.seed(1234)\npost_data_upworthy_question <- \n  data.frame( \n  yes = rgamma(n = 1e4, shape = alpha + y_yes, rate = beta + n_yes),\n  no = rgamma(n = 1e4,  shape = alpha + y_no, rate = beta + n_no))\n# Plot the histogram of the ratio of rates (question / no question)\nggplot(data = post_data_upworthy_question,\n  mapping = aes(x = yes/no)) +\n  geom_histogram() +\n  labs(x = \"rate ratio\", y = \"\",\n       caption = expression(lambda[\"yes\"]/lambda[\"no\"])) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.05))) +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](02-solution_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Compute the posterior mean for the quantity\npost_mean <- with(post_data_upworthy_question, mean(yes/no))\npost_mean\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9317745\n```\n:::\n:::\n\n\n:::\n",
    "supporting": [
      "02-solution_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}